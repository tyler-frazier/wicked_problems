<!DOCTYPE HTML>
<html lang="en" class="sidebar-visible no-js light">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Population and Development Data Science</title>
        
        <meta name="robots" content="noindex" />
        

        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link href="https://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800" rel="stylesheet" type="text/css">
        <link href="https://fonts.googleapis.com/css?family=Source+Code+Pro:500" rel="stylesheet" type="text/css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->
        

        
    </head>
    <body>
        <!-- Provide site root to javascript -->
        <script type="text/javascript">
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "light" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script type="text/javascript">
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script type="text/javascript">
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script type="text/javascript">
            var html = document.querySelector('html');
            var sidebar = 'hidden';
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div id="sidebar-scrollbox" class="sidebar-scrollbox">
                <ol class="chapter"><li class="expanded affix "><a href="book.html">About this book</a></li><li class="expanded affix "><a href="author.html">About the author</a></li><li class="expanded "><a href="courses.html"><strong aria-hidden="true">1.</strong> Teaching and Syllabuses</a></li><li><ol class="section"><li class="expanded "><a href="expect.html"><strong aria-hidden="true">1.1.</strong> Expectations and Assessment</a></li><li class="expanded "><a href="data310.html"><strong aria-hidden="true">1.2.</strong> DATA 310 Applied Machine Learning</a></li><li class="expanded "><a href="data441.html"><strong aria-hidden="true">1.3.</strong> DATA 441 Agent-Based Modeling</a></li><li class="expanded "><a href="data150.html"><strong aria-hidden="true">1.4.</strong> DATA 150 Evolving Solutions</a></li><li class="expanded "><a href="data100.html"><strong aria-hidden="true">1.5.</strong> DATA 100 Wicked Problems</a></li></ol></li><li class="expanded "><a href="getting_started.html"><strong aria-hidden="true">2.</strong> Student Preparations</a></li><li><ol class="section"><li class="expanded "><a href="gitstart.html"><strong aria-hidden="true">2.1.</strong> Getting Started with GitHub</a></li><li class="expanded "><a href="rstart.html"><strong aria-hidden="true">2.2.</strong> Getting Started with R &amp; RStudio</a></li><li class="expanded "><a href="jupyterstart.html"><strong aria-hidden="true">2.3.</strong> Getting Started with JupyterHub</a></li><li class="expanded "><a href="colabstart.html"><strong aria-hidden="true">2.4.</strong> Getting Started with Google Colab</a></li></ol></li><li class="expanded "><a href="datause.html"><strong aria-hidden="true">3.</strong> Data Use for Human and Community Scale Processes</a></li><li><ol class="section"><li class="expanded "><a href="describe.html"><strong aria-hidden="true">3.1.</strong> Spatial Population Description</a></li><li class="expanded "><a href="model.html"><strong aria-hidden="true">3.2.</strong> Spatial Population Modelling</a></li></ol></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                
                <div id="menu-bar" class="menu-bar">
                    <div id="menu-bar-sticky-container">
                        <div class="left-buttons">
                            <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                                <i class="fa fa-bars"></i>
                            </button>
                            <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                                <i class="fa fa-paint-brush"></i>
                            </button>
                            <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                                <li role="none"><button role="menuitem" class="theme" id="light">Light (default)</button></li>
                                <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                                <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                                <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                                <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                            </ul>
                            
                            <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                                <i class="fa fa-search"></i>
                            </button>
                            
                        </div>

                        <h1 class="menu-title">Population and Development Data Science</h1>

                        <div class="right-buttons">
                            <a href="print.html" title="Print this book" aria-label="Print this book">
                                <i id="print-button" class="fa fa-print"></i>
                            </a>
                            
                        </div>
                    </div>
                </div>

                
                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" name="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>
                

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script type="text/javascript">
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1><a class="header" href="#about-this-book" id="about-this-book">About this book</a></h1>
<p><em>Population and Development Data Science</em> by Tyler James Frazier is published here as an integral resource used to teach courses at William &amp; Mary as well as to advance student research associated with the author's work.  This book serves as an introduction to data science from the perspective of the social sciences while reaching out towards the life and natural sciences.  <em>Population and Development Data Science</em> offers the student and practicioner an introductory pathway to improved data use, literacy, visualization and communication.  The reader is invited to use data to describe human and community scale, development patterns and processes.  The popular interpretative programming languages python and R are introduced to describe, analyze, model, simulate and communicate results from a number of different exploratory investigations into geospatial human development processes.  Using these example exploratory investigations, the reader is offered a map towards conducting their own research on any dimension of human development, at any scale, and at any location on earth.</p>
<p>To cite this book in publications, please use the following.</p>
<p>Frazier, Tyler James. (2020). Population and Development Data Science.  Williamsburg, Virginia: William &amp; Mary / Data Science Series IA. <a href="">https://tyler-frazier.github.io/dsbook/</a></p>
<h1><a class="header" href="#about-the-author" id="about-the-author">About the author</a></h1>
<p>Tyler James Frazier (<a href="">tyler-frazier.github.io</a>) is a Lecturer in the Data Science program at William &amp; Mary.  His research and teaching focus on the use of data science methods to describe, analyze, model and predict the behavior of our planet's human population and its associated development patterns and processes as well as our larger complex and adapting social and economic system.  Prior to joining William &amp; Mary in the summer of 2015, Tyler has held academic appointments at the Santa Fe Institute, the Technical University of Berlin and the Center for Development Research in Bonn. He also previously held visiting acadmeic positions at the Technical University of Munich and the University of Ghana, Legon.  His research has been supported by funding from the Volkswagen Foundation, the Bill and Melinda Gates Foundation and the German Federal Ministry of Education and Research. </p>
<p>Dr. Frazier received his Ph.D. in Geography from the University of Bonn, Germany in 2011, a Masters in City and Regional Planning from the Georgia Institute of Technology in 2001, and a Bachelor of Arts in Architectural History from the Savannah College of Art and Design in 1999.  In 2001, Tyler gained acceptance to Georgia Tech's Masters of Mechanical Engineering program, but instead decided to begin his career in land use, development and management.  Prior to beginning his doctorate in 2006, Tyler worked for both private and public land use planning institutions in both Georgia and Florida.  He is a certified member of the American Institute of Certified Planners (AICP) and in the past has regularly been accepted as an expert witness on land use matters during both judicial and quasi-judicial proceedings in Georgia and Florida.</p>
<p>For a comprehsive view of his life's work, please see this <a href="tyler-frazier.github.io">curriculum vitae</a>.</p>
<h1><a class="header" href="#chapter-1" id="chapter-1">Chapter 1</a></h1>
<h2><a class="header" href="#describe" id="describe">Describe</a></h2>
<h1><a class="header" href="#honor-code" id="honor-code">Honor Code</a></h1>
<p>Among our most significant traditions is the student-administered honor system. The Honor Code is an enduring tradition with a documented history that originates as far back as 1736. The essence of our honor system is individual responsibility. Today, students, such as yourself, administer the Honor pledge to each incoming student while also serving to educate faculty and administration on the relevance of the Code and its application to students’ lives.</p>
<p>The Pledge</p>
<p>“As a member of the William and Mary community, I pledge on my honor not to lie, cheat, or steal, either in my academic or personal life. I understand that such acts violate the Honor Code and undermine the community of trust, of which we are all stewards.”</p>
<h1><a class="header" href="#accessibility-attendance--universal-learning" id="accessibility-attendance--universal-learning">Accessibility, Attendance &amp; Universal Learning</a></h1>
<p>William &amp; Mary accommodates students with disabilities in accordance with federal laws and university policy. Any student who feels s/he may need an accommodation based on the impact of a learning, psychiatric, physical, or chronic health diagnosis should contact Student Accessibility Services staff at 757-221-2509 or at sas@wm.edu to determine if accommodations are warranted and to obtain an official letter of accommodation. For more information, please see www.wm.edu/sas.</p>
<p>I am committed to the principle of universal learning. This means that our classroom, our virtual spaces, our practices, and our interactions be as inclusive as possible. Mutual respect, civility, and the ability to listen and observe others carefully are crucial to universal learning. Active, thoughtful, and respectful participation in all aspects of the course will make our time together as productive and engaging as possible.</p>
<h1><a class="header" href="#grade-categories" id="grade-categories">Grade Categories</a></h1>
<table><thead><tr><th></th><th></th><th></th></tr></thead><tbody>
<tr><td>exceptional A = 100 ≥ 97.0</td><td>excellent A = 96.9 ≥ 93.0</td><td>superior A- = 92.9 ≥ 90.0</td></tr>
<tr><td>very good B+ = 89.9 ≥ 87.0</td><td>good B = 86.9 ≥ 83.0</td><td>above average B- = 82.9 ≥ 80.0</td></tr>
<tr><td>normal C+ = 79.9 ≥ 77.0</td><td>average C = 76.9 ≥ 73.0</td><td>sub par C- = 72.9 ≥ 70.0</td></tr>
<tr><td>below average D+ = 69.9 ≥ 67.0</td><td>poor D = 66.9 ≥ 63.0</td><td>very poor D- = 62.9 ≥ 60.0</td></tr>
<tr><td>failing F &lt; 60.0</td><td></td><td></td></tr>
</tbody></table>
<p>note .9 = .9 with bar notation</p>
<h1><a class="header" href="#data-310-applied-machine-learning" id="data-310-applied-machine-learning">DATA 310: Applied Machine Learning</a></h1>
<p>Course ID: DATA 310<br />
Course Attribute:<br />
Title: Applied Machine Learning<br />
Credit Hours: 3<br />
Meeting Times: 12:30 to 2:20 MTWTh<br />
Location: Online and Remote via Live Broadcast<br />
Date Range: Jul 06,2020 - Aug 07,2020</p>
<h1><a class="header" href="#course-description" id="course-description">Course Description</a></h1>
<p>This course will focus on the technical application of machine learning algorithms, their nature, and discussions regarding the potential drawbacks and advantages of different classes of algorithms. Students entering into this course should have, at a minimum, a background in python and linear algebra. No single algorithm will be covered in great depth, and the course will place a focus on the code and implementation choices necessary for each class of algorithm. Topics covered will include data processing, regression in ML, decision trees, forests, k-nn, support vector machines, kernel SVM, k-means and hierarchical clustering, association rules, natural language processing, neural networks, and various associated approaches.Pre-requisite(s): (DATA 141 OR DATA 140 OR CSCI 140 OR CSCI 141) AND (DATA 146 OR CSCI 146)</p>
<h1><a class="header" href="#goals-and-objectives" id="goals-and-objectives">Goals and Objectives:</a></h1>
<ul>
<li>To provide students with a critical understanding of the variety of tools that can be used for machine learning.</li>
<li>To develop students ability to communicate findings, analysis, and visualization skills for future courses (and jobs).</li>
<li>To expose students to real-world problems that are being engaged with by contemporary problem solvers and decision makers.</li>
</ul>
<h1><a class="header" href="#grading-opportunities" id="grading-opportunities">Grading Opportunities</a></h1>
<table><thead><tr><th></th><th></th><th></th></tr></thead><tbody>
<tr><td>Class Participation</td><td>5%</td><td>Assessed at end of semester</td></tr>
<tr><td>Four laboratory Assignments</td><td>80%</td><td>End of Weeks 1 thru 4</td></tr>
<tr><td>Final Project</td><td>15%</td><td>Due at end of week 5</td></tr>
</tbody></table>
<h1><a class="header" href="#semester-schedule" id="semester-schedule">Semester Schedule</a></h1>
<h3><a class="header" href="#week-1-july-6" id="week-1-july-6">Week 1 (July 6)</a></h3>
<ul>
<li>Monday: 
<ul>
<li>Introductions and Getting Started </li>
<li>Lecture - Introduction to Applied Machine Learning</li>
<li>Lecture - Hierarchical Bayesian Models</li>
<li>Begin Lab 1 Exercises - Hierarchical Bayesian Models</li>
</ul>
</li>
<li>Tuesday: Hierarchical Bayesian Models</li>
<li>Wednesday: Hierarchical Bayesian Models</li>
<li>Thursday: Hierarchical Bayesian Models</li>
<li>Saturday: Hierarchial Bayesian Models Lab due by 5PM</li>
</ul>
<h3><a class="header" href="#week-2-july-13" id="week-2-july-13">Week 2 (July 13)</a></h3>
<ul>
<li>Monday: 
<ul>
<li>Review Lab 1</li>
<li>Lecture - Random Forest Models</li>
<li>Begin Lab 2 Exercises - Random Forest Models</li>
</ul>
</li>
<li>Tuesday: Random Forest Models</li>
<li>Wednesday: Random Forest Models</li>
<li>Thursday: Random Forest Models</li>
<li>Saturday: Random Forest Models Lab due by 5PM</li>
</ul>
<h3><a class="header" href="#week-3-july-20" id="week-3-july-20">Week 3 (July 20)</a></h3>
<ul>
<li>Monday:
<ul>
<li>Review Lab 2</li>
<li>Lecture - Artificial Neural Networks</li>
<li>Begin Lab 3 Exercises - Artificial Neural Network Models</li>
</ul>
</li>
<li>Tuesday: Artificial Neural Network Models</li>
<li>Wednesday: Artificial Neural Network Models</li>
<li>Thursday: Artificial Neural Network Models</li>
<li>Saturday: Artificial Neural Network Models Lab due by 5PM</li>
</ul>
<h3><a class="header" href="#week-4-july-27" id="week-4-july-27">Week 4 (July 27)</a></h3>
<ul>
<li>Monday:
<ul>
<li>Review Lab 3</li>
<li>Lecture - Recurrent Neural Networks</li>
<li>Begin Lab 4 Exercises - Recurrent Neural Network Models</li>
</ul>
</li>
<li>Tuesday: Recurrent Neural Network Models</li>
<li>Wednesday: Recurrent Neural Network Models</li>
<li>Thursday: Recurrent Neural Network Models</li>
<li>Saturday: Recurrent Neural Network Models Lab due by 5PM</li>
</ul>
<h3><a class="header" href="#week-5-august-3" id="week-5-august-3">Week 5 (August 3)</a></h3>
<ul>
<li>Monday:
<ul>
<li>Review Lab 4</li>
<li>Lecture - Convolutional Neural Networks</li>
<li>Begin Lab 5 Exercises - Convolutional Neural Network Models</li>
</ul>
</li>
<li>Tuesday: Convolutional Neural Networks Models</li>
<li>Wednesday: Convolutional Neural Network Models</li>
<li>Thursday: Convolutional Neural Network Models</li>
<li>Saturday: Convolutional Neural Network Models Lab due by 5PM</li>
</ul>
<h1><a class="header" href="#data-441-agent-based-modelling" id="data-441-agent-based-modelling">DATA 441: Agent-Based Modelling</a></h1>
<p>Course ID: DATA 441<br />
Course Attribute: COLL 400<br />
Title: Agent-Based Modelling<br />
Credit Hours: 3<br />
Meeting Times: 1:00 to 1:50 MWF<br />
Location: ISC 3248<br />
Date Range: Aug 26,2020 - Dec 15,2020</p>
<h1><a class="header" href="#course-description-1" id="course-description-1">Course Description</a></h1>
<p>In this course, students will use openly accessible, global, near present-time, high-resolution satellite, survey and CDR data, with machine learning and spatial statistics methodologies to construct agent-based models of human development processes. Each student will select and describe a developing population, its demographics, and its built and natural environments in order to estimate social and economic, complex and adapting, agent-based decision, movement and land use models. Students will construct modules that project demand for infrastructure (transportation, water, and electricity) and social services (health care, education, and public safety) as wellas simulate an infectious disease outbreak, a natural disaster and unabated urbanization. The statistical programming language R will be used in this course. Pre-requisite(s): DATA 146 OR CSCI 146</p>
<h1><a class="header" href="#courses-objectives" id="courses-objectives">Courses Objectives</a></h1>
<ul>
<li>To introduce ...</li>
<li>To introduce ...</li>
<li>To demonstrate ...</li>
<li>To demonstrate ...</li>
<li>To challenge ...</li>
</ul>
<h1><a class="header" href="#grading-opportunities-1" id="grading-opportunities-1">Grading Opportunities</a></h1>
<table><thead><tr><th></th><th></th><th></th></tr></thead><tbody>
<tr><td>Class &amp; Group Participation</td><td>20%</td><td>Individually graded, twice per semester</td></tr>
<tr><td>Three Informal Group Presentations</td><td>10%</td><td>Fridays during weeks 5, 8 &amp; 11</td></tr>
<tr><td>Four Individual Projects</td><td>40%</td><td>Due at the end of weeks 5, 8, 11 &amp; 14</td></tr>
<tr><td>Final Group Presentation</td><td>10%</td><td>Week 15</td></tr>
<tr><td>Final Individual Project</td><td>20%</td><td>due by 5PM Wednesday, May 13th</td></tr>
</tbody></table>
<h1><a class="header" href="#semester-schedule-1" id="semester-schedule-1">Semester Schedule</a></h1>
<h3><a class="header" href="#week-1-" id="week-1-">Week 1 (...)</a></h3>
<ul>
<li>Wednesday: ...</li>
<li>Friday: ...</li>
</ul>
<h3><a class="header" href="#week-2-" id="week-2-">Week 2 (...)</a></h3>
<ul>
<li>Monday: ...</li>
<li>Wednesday: ...</li>
<li>Friday: ...
<ul>
<li>add/drop period ends</li>
</ul>
</li>
</ul>
<h3><a class="header" href="#week-3-" id="week-3-">Week 3 (...)</a></h3>
<ul>
<li>Monday: ...</li>
<li>Wednesday: ...</li>
<li>Friday: ...</li>
</ul>
<h3><a class="header" href="#week-4-" id="week-4-">Week 4 (...)</a></h3>
<ul>
<li>Monday: ...</li>
<li>Wednesday: ...</li>
<li>Friday: ...</li>
</ul>
<h3><a class="header" href="#week-5-" id="week-5-">Week 5 (...)</a></h3>
<ul>
<li>Monday: ...</li>
<li>Wednesday: ...</li>
<li>Friday: ...</li>
</ul>
<h3><a class="header" href="#week-6-" id="week-6-">Week 6 (...)</a></h3>
<ul>
<li>Monday: ...</li>
<li>Wednesday: ...</li>
<li>Friday: ...</li>
</ul>
<h3><a class="header" href="#week-7-" id="week-7-">Week 7 (...)</a></h3>
<ul>
<li>Monday: ...</li>
<li>Wednesday: ...</li>
<li>Friday: ...</li>
</ul>
<h3><a class="header" href="#week-8-" id="week-8-">Week 8 (...)</a></h3>
<ul>
<li>Monday: ...</li>
<li>Wednesday: ...</li>
<li>Friday: ...</li>
</ul>
<h3><a class="header" href="#week-9-" id="week-9-">Week 9 (...)</a></h3>
<ul>
<li>Monday: ...</li>
<li>Wednesday: ...</li>
<li>Friday: ...</li>
</ul>
<h3><a class="header" href="#week-10-" id="week-10-">Week 10 (...)</a></h3>
<ul>
<li>Monday: ...</li>
<li>Wednesday: ...</li>
<li>Friday: ...</li>
</ul>
<h3><a class="header" href="#week-11-" id="week-11-">Week 11 (...)</a></h3>
<ul>
<li>Monday: ...</li>
<li>Wednesday: ...</li>
<li>Friday: ...</li>
</ul>
<h3><a class="header" href="#week-12-" id="week-12-">Week 12 (...)</a></h3>
<ul>
<li>Monday: ...</li>
<li>Wednesday: ...</li>
<li>Friday: ...</li>
</ul>
<h3><a class="header" href="#week-13-" id="week-13-">Week 13 (...)</a></h3>
<ul>
<li>Monday: ...</li>
<li>Wednesday: ...</li>
<li>Friday: ...</li>
</ul>
<h3><a class="header" href="#week-14-" id="week-14-">Week 14 (...)</a></h3>
<ul>
<li>Monday: ...</li>
<li>Wednesday: ...</li>
<li>Friday: ...</li>
</ul>
<h3><a class="header" href="#week-15-" id="week-15-">Week 15 (...)</a></h3>
<ul>
<li>Monday: ...</li>
<li>Wednesday: ...</li>
<li>Friday: ...</li>
</ul>
<h3><a class="header" href="#final-" id="final-">Final (...)</a></h3>
<h1><a class="header" href="#data-150-human-developmentdata-science" id="data-150-human-developmentdata-science">DATA 150: Human Development/Data Science</a></h1>
<p>Course ID: DATA 150<br />
Course Attribute: COLL 150<br />
Title: Evolving Solutions: Human Development/Data Science<br />
Credit Hours: 4<br />
Meeting Times: 9:30 to 10:50 TTh 
Location: Morton Hall 244<br />
Date Range: Aug 26,2020 - Dec 15,2020</p>
<h1><a class="header" href="#course-description-2" id="course-description-2">Course Description</a></h1>
<p>This course provides an introduction to critical, ethical, and moral issues surrounding data and society. It blends social and historical perspectives on data with ethics, policy, and case examples—from text analytics to self-driving cars—to help students develop a workable understanding of current ethical and moral issues in data science. The course examines the ethics and morality of studying human subjects, documenting workflows, and communicating results. Students debate issues surrounding privacy, surveillance, discrimination, transparency, responsibility, and trust throughout the data lifecycle –from collection and creation to storage and analysis to the application and sharing of data. Pre-requisite(s): None</p>
<h1><a class="header" href="#goals-and-objectives-1" id="goals-and-objectives-1">Goals and Objectives:</a></h1>
<ul>
<li>To learn about the research process and how it can be used to build a knowledge base to support your writing.</li>
<li>To investigate a subject matter by defining its boundaries, identifying significant contributing areas of interest and discarding non-essential and/or non-contributing information.</li>
<li>To use a body of knowledge as the basis for writing a research paper, including the formulation of a central research question</li>
<li>To produce a scientific article, including a literature review, methodological discussion, citations, bibliography, abstract and information about the author.</li>
<li>To challenge students to become apprentice scholars and identify a central research focus of interest.</li>
</ul>
<h1><a class="header" href="#grading-opportunities-2" id="grading-opportunities-2">Grading Opportunities</a></h1>
<table><thead><tr><th></th><th></th><th></th></tr></thead><tbody>
<tr><td>Class Participation</td><td>15%</td><td>Twice per semester</td></tr>
<tr><td>Two In-Class Essays</td><td>15%</td><td>Twice per semester</td></tr>
<tr><td>Three Assignments</td><td>30%</td><td>Due at the end of weeks 5, 8 &amp; 11</td></tr>
<tr><td>Group Presentation</td><td>15%</td><td>Week 15</td></tr>
<tr><td>Research Proposal</td><td>25%</td><td>Due 5PM Wednesday, May 13th</td></tr>
</tbody></table>
<h1><a class="header" href="#semester-schedule-2" id="semester-schedule-2">Semester Schedule</a></h1>
<h3><a class="header" href="#week-1--1" id="week-1--1">Week 1 (...)</a></h3>
<ul>
<li>Introductions</li>
<li>Syllabus</li>
<li>Slack</li>
</ul>
<h3><a class="header" href="#week-2--1" id="week-2--1">Week 2 (...)</a></h3>
<ul>
<li>Tuesday: open discussion; workshop
<ul>
<li><a href = "https://www.nature.com/magazine-assets/d41586-018-06215-5/d41586-018-06215-5.pdf">Don’t forget people in the use of big data for development</a> (Blumenstock)</li>
<li><a href = "https://web.flowminder.org/work/research-innovation"> FlowMinder</a></li>
</ul>
</li>
<li>Thursday: open discussion; workshop
<ul>
<li><a href = "https://www.nature.com/magazine-assets/d41586-018-05331-6/d41586-018-05331-6.pdf">Map-Making on a Budget</a> (Perkel)</li>
<li><a href = "https://www.nature.com/articles/sdata20174"> WorldPop, open data for spatial demography</a> (Tatem)</li>
<li><a href = "https://datahelpdesk.worldbank.org/knowledgebase/articles/906519"> LMICs</a> (Worldbank)</li>
<li><a href = "https://www.worldpop.org/"> WorldPop</a></li>
</ul>
</li>
<li>Friday: add/drop period ends</li>
</ul>
<h3><a class="header" href="#week-3--1" id="week-3--1">Week 3 (...)</a></h3>
<ul>
<li>
<p>Tuesday: open discussion; begin Assignment 1</p>
<ul>
<li><a href = "https://wicked-problems.github.io/workshop/annotated_bib"> Link to Assignment 1</a> Write an Annotated Bibliography</li>
<li><a href = "https://soundcloud.com/hdro-web/what-is-human-development"> What is Human Development</a> (Selim Jahan, Director of UNDP's Human Development Report Office)</li>
<li><a href = "https://soundcloud.com/hdro-web/hdr2015theme"> What is Human Development, continued</a> (Selim Jahan, Director of UNDP's Human Development Report Office)</li>
<li><a href = "https://www.gapminder.org/videos/ted-talks/hans-rosling-ted-2006-debunking-myths-about-the-third-world/"> The Best Stats You've Never Seen</a> (Hans Rosling, Gapminder)</li>
<li><a href = "https://data.humdata.org"> HDX</a></li>
<li><a href = "https://www.gadm.org"> GADM</a></li>
<li><a href = "https://maps.elie.ucl.ac.be/CCI/viewer/"> ESACCI-LC</a></li>
</ul>
</li>
<li>
<p>Thursday: open discussion; continue Assignment 1</p>
<ul>
<li><a href = "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5283062/"> High resolution global gridded data for use in population studies</a> (Lloyd, Sorichetta &amp; Tatem)</li>
<li><a href = "https://www.openstreetmap.org/"> OSM</a></li>
<li><a href = "https://ciesin.columbia.edu/data/hrsl/"> CIESN-HRSL</a></li>
<li><a href = "https://ngdc.noaa.gov/eog/viirs/download_dnb_composites.html"> VIIRS</a></li>
</ul>
</li>
</ul>
<h3><a class="header" href="#week-4--1" id="week-4--1">Week 4 (...)</a></h3>
<ul>
<li>Tuesday: open discussion; continue Assignment 1 
<ul>
<li><a href = "https://slack-files.com/TFB8EJWF3-FN5V4DWQ5-9824c193ba"> Development as Freedom</a> (Amartya Sen, 1999)</li>
</ul>
</li>
<li>Thursday: open discussion; continue Assignment 1
<ul>
<li><a href = "https://www.pnas.org/content/pnas/115/14/3529.full.pdf">Spatially disaggregated population estimates
in the absence of national population and housing census data</a> (Wardrop et al.)</li>
</ul>
</li>
</ul>
<h3><a class="header" href="#week-5--1" id="week-5--1">Week 5 (...)</a></h3>
<ul>
<li>Tuesday: open discussion, continue Assignment 1
<ul>
<li><a href = "https://www.youtube.com/watch?v=02EZPxPcFqs"> Development and Complexity</a> (Owen Barder, 2012)</li>
<li><a href = "https://firebasestorage.googleapis.com/v0/b/gitbook-28427.appspot.com/o/assets%2F-LivRaDWdoVboUIKeGNK%2F-Lq4IjZXwr9I85uFHZJ8%2F-Lq4JN3KOMsc08l5Enj6%2FDevelopment_and_Complexity_Slides.pdf?alt=media&token=57eee8e4-b59e-4152-9888-58d98e5c53f7"> Accompanying slides to Development and Complexity</a> (Owen Barder, 2012)</li>
</ul>
</li>
<li>Thursday: review of Assignment 1
<ul>
<li><a href = "https://www.nature.com/articles/s41598-018-22969-4"> Mapping road network communities for guiding disease surveillance and control strategies</a> (Strano, Viana, Sorichetta &amp; Tatem)</li>
</ul>
</li>
<li><strong>Assignment 1 Due</strong>: Saturday Midnight</li>
</ul>
<h3><a class="header" href="#week-6--1" id="week-6--1">Week 6 (...)</a></h3>
<ul>
<li>Tuesday: open discussion
<ul>
<li><a href = "https://www.wired.com/2008/06/pb-theory/"> The End of Theory: The Data Deluge makes the Scientific Method Obsolete</a> (Anderson)</li>
<li><a href = "http://journals.sagepub.com/doi/pdf/10.1177/2053951714528481"> Big Data, New Epistemologies and Paradigm Shifts</a> (Kitchin)</li>
</ul>
</li>
<li>Thursday: begin Assignment 2; open discussion
<ul>
<li><a href = "https://wicked-problems.github.io/workshop/lit_review"> Link to Assignment 2</a> Write a Literature Review</li>
<li><a href = "https://www.nature.com/articles/s41597-019-0142-2"> A spatial database of health facilities managed by the public health sector in sub Saharan Africa</a> (Maina et al.)</li>
</ul>
</li>
</ul>
<h3><a class="header" href="#week-7--1" id="week-7--1">Week 7 (...)</a></h3>
<ul>
<li>Tuesday: open discussion, continue Assignment 2
<ul>
<li><a href = "https://wm.kanopy.com/video/african-election"> An African Election - Ghana’s Democracy in Action</a> (Merz)</li>
</ul>
</li>
<li>Thursday: <strong>In-Class Essay 1</strong></li>
</ul>
<h3><a class="header" href="#week-8--1" id="week-8--1">Week 8 (...)</a></h3>
<ul>
<li>Tuesday: No Class (Spring Break)</li>
<li>Thursday:  No Class (Spring Break)</li>
</ul>
<h3><a class="header" href="#week-9--1" id="week-9--1">Week 9 (...)</a></h3>
<ul>
<li>Tuesday: cancelled</li>
<li>Thursday: cancelled</li>
</ul>
<h3><a class="header" href="#week-10--1" id="week-10--1">Week 10 (...)</a></h3>
<p>-Begin remote instruction, all instruction will be live via Zoom at our normally scheduled class times. A link to the live video feed will be posted on the slack channel for the current project.</p>
<ul>
<li>Tuesday: reconnect; continue Assignment 2
<ul>
<li><a href = "https://spatialdata.dhsprogram.com/home/"> DHS Spatial Program</a> <em>just for review, consider use when reading Alegana et al. and Bosco et al.</em></li>
<li><a href = "https://dhsprogram.com/publications/publication-SAR11-Spatial-Analysis-Reports.cfm"> Creating Spatial Interpolation Surfaces with DHS Data</a> <em>just for review, consider use when reading Alegana et al. and Bosco et al.</em></li>
<li><a href = "https://dhsprogram.com/pubs/pdf/SAR14/SAR14.pdf"> Guidance for Use of The DHS Program Modeled Map Surfaces</a> <em>just for review, consider use when reading Alegana et al. and Bosco et al.</em></li>
</ul>
</li>
<li>Thursday: open discussion, continue Assignment 2
<ul>
<li><a href = "https://journals.plos.org/plosone/article/file?id=10.1371/journal.pone.0107042&type=printable"> Disaggregating Census Data for Population Mapping Using Random Forests with Remotely-Sensed and Ancillary Data</a> (Stevens, Gaughan, Linard &amp; Tatem)</li>
</ul>
</li>
</ul>
<h3><a class="header" href="#week-11--1" id="week-11--1">Week 11 (...)</a></h3>
<ul>
<li>Tuesday: open discussion; continue Assignment 2
<ul>
<li><a href = "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5746564/pdf/rsif20170401.pdf"> Examining the correlates and drivers of human population distributions across low- and middle-income countries</a> (Nieves et al.) </li>
</ul>
</li>
<li>Thursday: open discussion, continue Assignment 2
<ul>
<li><a href = "https://royalsocietypublishing.org/doi/pdf/10.1098/rsif.2015.0073"> Fine resolution mapping of population age-structures for health and development applications</a> (Alegana et al.)</li>
<li><strong>Assignment 2 Due</strong>: Sunday Midnight</li>
</ul>
</li>
</ul>
<h3><a class="header" href="#week-12--1" id="week-12--1">Week 12 (...)</a></h3>
<ul>
<li>Tuesday: Begin Assignment 3
<ul>
<li><a href = "https://wicked-problems.github.io/workshop/methodology"> Link to Assignment 3</a> Investigate a Methodology</li>
<li><a href = "https://royalsocietypublishing.org/doi/pdf/10.1098/rsif.2016.0825"> Exploring the high-resolution mapping of gender-disaggregated development indicators</a> (Bosco et al.)</li>
</ul>
</li>
<li>Thursday: open discussion, continue Assignment 3
<ul>
<li><a href = "https://academic.oup.com/migration/article/3/1/89/2413406"> Modeling internal migration flows in sub-Saharan Africa using census microdata</a> (Garcia, Pindolia, Lopiano &amp; Tatem)</li>
</ul>
</li>
</ul>
<h3><a class="header" href="#week-13--1" id="week-13--1">Week 13 (...)</a></h3>
<ul>
<li>Tuesday: open discussion, continue Assignment 3
<ul>
<li><a href = "https://www.nature.com/articles/sdata201666.pdf"> Mapping internal connectivity through human migration in malaria endemic countries</a> (Sorichetta et al.) </li>
</ul>
</li>
<li>Thursday: open discussion, continue Assignment 3
<ul>
<li><a href = "https://www.pnas.org/content/pnas/111/45/15888.full.pdf"> Dynamic population mapping using mobile phone data</a> (Deville et al.)</li>
</ul>
</li>
<li><strong>Assignment 3 Due</strong>: Sunday Midnight</li>
</ul>
<h3><a class="header" href="#week-14--1" id="week-14--1">Week 14 (...)</a></h3>
<ul>
<li>Tuesday: <strong>Remote In-Class Essay 2</strong>
<ul>
<li><a href = "https://wicked-problems.github.io/workshop/presentation"> Link to Assignment 4, Part 1</a> Make a Public Presentation</li>
<li><a href = "https://wicked-problems.github.io/workshop/plan"> Link to Assignment 4, Part 2</a> Propose a Research Plan</li>
</ul>
</li>
<li>Thursday: Dry Run for Presenting (Draft of) Slides</li>
</ul>
<h3><a class="header" href="#week-15--1" id="week-15--1">Week 15 (...)</a></h3>
<ul>
<li>Tuesday: <strong>Final Individual Presentations</strong> (~8 presentations)</li>
<li>Thursday: <strong>Final Individual Presentations</strong> (~8 presentations)</li>
</ul>
<h3><a class="header" href="#final-individual-project" id="final-individual-project">Final Individual Project</a></h3>
<ul>
<li>Wednesday, ...: <strong>Research Proposal Due</strong></li>
</ul>
<p>Additional Relevant Readings:</p>
<ul>
<li><a href = "https://www.nature.com/articles/s41599-019-0242-9.pdf"> Exploring the use of mobile phone data for national migration statistics</a> (Lai et al.)</li>
<li><a href = "https://ij-healthgeographics.biomedcentral.com/track/pdf/10.1186/s12942-017-0115-7"> Mathematical models for predicting human mobility in the context of infectious disease spread: introducing the impedance model</a> (Sallah et al.)</li>
<li><a href = "https://www.nature.com/articles/s41598-019-41192-3.pdf"> Utilizing general human movement models to predict the spread of emerging infectious diseases in resource poor settings</a> (Kraemer et al.)</li>
</ul>
<h1><a class="header" href="#data-100-wicked-problems" id="data-100-wicked-problems">DATA 100: Wicked Problems</a></h1>
<p>Course ID: DATA 100<br />
Course Attribute: COLL 100<br />
Title: Wicked Problems<br />
Credit Hours: 4<br />
Meeting Times: 11:00 to 11:50 MWF<br />
Location: ISC 3248<br />
Date Range: Aug 26,2020 - Dec 15,2020</p>
<h1><a class="header" href="#course-description-3" id="course-description-3">Course Description</a></h1>
<p>Global, near present-time, high-resolution data is openly accessible to construct scientific descriptions ofhuman development. In this course you will use data describing populations, governments, and both the natural and built environments in order to construct a close-to-reality description of your selected region or country. You will then intersect a selected dimension of human development as an initial boundary for investigating a contextually relevant research question. While development is often thought of as a “missing ingredient” that is needed to improve the well-being of people or the output of firms, in this course human development is defined as the ability to enlarge people’s choices, capabilities and freedoms and is understood as an emergent property from our complex and adapting economic and social system. Data science methods are used to constructclose-to-reality descriptions of human development processes in order to identify interactions, describe co-evolving agents, recognize the conditions prevalent for emergence, understand the significance of scale and ultimately begin to establish a framework for analyzing human development’s multitude of seemingly intractable, wicked problems.  During this course you will also learn to use the flexible data science, programming language R, but no prior experience is needed. Pre-requisite(s): None</p>
<h1><a class="header" href="#courses-objectives-1" id="courses-objectives-1">Courses Objectives</a></h1>
<ul>
<li>To introduce students to human development as the ability to enlarge people’s choices, capabilities and freedoms and as an emergent property from society functioning as a complex adaptive social and economic system.</li>
<li>To introduce students to data science through understanding previously computationally intractable, wicked problems.</li>
<li>To demonstrate competent information literacy and data science skills by producing knowledge from data through the creation of plots, graphs, charts and maps.</li>
<li>To demonstrate competent application of fundamental computer science and statistics methods within the context of geospatial human development processes.</li>
<li>To challenge students to become apprentice scholars by supporting their answer to a formulated central research question with close-to-reality geospatial descriptions of human development processes.</li>
</ul>
<h1><a class="header" href="#grading-opportunities-3" id="grading-opportunities-3">Grading Opportunities</a></h1>
<table><thead><tr><th></th><th></th><th></th></tr></thead><tbody>
<tr><td>Class &amp; Group Participation</td><td>20%</td><td>Individually graded, twice per semester</td></tr>
<tr><td>Three Informal Group Presentations</td><td>10%</td><td>Fridays during weeks 5, 8 &amp; 11</td></tr>
<tr><td>Four Individual Projects</td><td>40%</td><td>Due at the end of weeks 5, 8, 11 &amp; 14</td></tr>
<tr><td>Final Group Presentation</td><td>10%</td><td>Week 15</td></tr>
<tr><td>Final Individual Project</td><td>20%</td><td>due by 5PM Wednesday, May 13th</td></tr>
</tbody></table>
<h1><a class="header" href="#semester-schedule-3" id="semester-schedule-3">Semester Schedule</a></h1>
<h3><a class="header" href="#week-1--2" id="week-1--2">Week 1 (...)</a></h3>
<ul>
<li>Introductions</li>
<li>Syllabus</li>
<li>Slack</li>
</ul>
<h3><a class="header" href="#week-2--2" id="week-2--2">Week 2 (...)</a></h3>
<ul>
<li>Monday: open discussion; workshop
<ul>
<li><a href = "https://www.nature.com/magazine-assets/d41586-018-06215-5/d41586-018-06215-5.pdf">Don’t forget people in the use of big data for development</a> (Blumenstock)</li>
</ul>
</li>
<li>Wednesday: open discussion; workshop
<ul>
<li><a href = "https://www.nature.com/magazine-assets/d41586-018-05331-6/d41586-018-05331-6.pdf">Map-Making on a Budget</a> (Perkel)</li>
</ul>
</li>
<li>Friday:  open discussion; workshop
<ul>
<li><a href = "https://www.nature.com/articles/sdata20174"> WorldPop, open data for spatial demography</a> (Tatem)</li>
<li><a href = "https://datahelpdesk.worldbank.org/knowledgebase/articles/906519"> LMICs</a> (Worldbank)</li>
<li>add/drop period ends</li>
</ul>
</li>
</ul>
<h3><a class="header" href="#week-3--2" id="week-3--2">Week 3 (...)</a></h3>
<ul>
<li>
<p>Monday: geospatial human development data; assign groups; begin Project 1 </p>
<ul>
<li><a href = "https://tyzao.gitbook.io/geodatasci/descript_pop/intro_spatdata">Link to Project 1, Part 1: Projecting, Plotting and Labeling Administrative Subdivisions</a></li>
<li><a href = "https://www.worldpop.org/"> WorldPop</a></li>
<li><a href = "https://www.gadm.org"> GADM</a></li>
<li><a href = "https://data.humdata.org"> HDX</a></li>
</ul>
</li>
<li>
<p>Wednesday: continue Project 1</p>
</li>
<li>
<p>Friday: group check-ins</p>
</li>
</ul>
<h3><a class="header" href="#week-4--2" id="week-4--2">Week 4 (...)</a></h3>
<ul>
<li>Monday: open discussion; continue Project 1 
<ul>
<li><a href = "https://tyzao.gitbook.io/geodatasci/descript_pop/extract_pops">Link to Project 1, Part 2: Extracting Populations from a Raster and Aggregating to each Unit</a></li>
<li><a href = "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5283062/"> High resolution global gridded data for use in population studies</a> (Lloyd, Sorichetta &amp; Tatem)</li>
</ul>
</li>
<li>Wednesday: continue Project 1</li>
<li>Friday: group check-ins</li>
</ul>
<h3><a class="header" href="#week-5--2" id="week-5--2">Week 5 (...)</a></h3>
<ul>
<li>Monday: open discussion, continue Project 1
<ul>
<li><a href = "https://tyzao.gitbook.io/geodatasci/descript_pop/geombar_plot">Link to Project 1, Part 3: Creating a Geometric Bar Plot with your Simple Feature object</a></li>
<li><a href = "https://www.pnas.org/content/pnas/115/14/3529.full.pdf"> Spatially disaggregated population estimates
in the absence of national population and housing census data</a> (Wardrop et al.)</li>
</ul>
</li>
<li>Wednesday: continue Project 1</li>
<li>Friday: Class cancelled due to snow</li>
</ul>
<h3><a class="header" href="#week-6--2" id="week-6--2">Week 6 (...)</a></h3>
<ul>
<li>Monday: <strong>Informal Group Presentations</strong></li>
<li><strong>Project 1 Due</strong>: Midnight</li>
<li>Wednesday: geospatial human development data; begin Project 2
<ul>
<li><a href = "https://maps.elie.ucl.ac.be/CCI/viewer/"> ESACCI-LC</a></li>
<li><a href = "https://ngdc.noaa.gov/eog/viirs/download_dnb_composites.html"> VIIRS</a></li>
<li><a href = "https://tyzao.gitbook.io/geodatasci/investigate/landuse_cover"> Link to Project 2, Part 1: Acquiring, Modifying and Describing the Data</a></li>
</ul>
</li>
<li>Friday: continue Project 2</li>
</ul>
<h3><a class="header" href="#week-7--2" id="week-7--2">Week 7 (...)</a></h3>
<ul>
<li>Monday: open discussion, continue Project 2
<ul>
<li><a href = "https://journals.plos.org/plosone/article/file?id=10.1371/journal.pone.0107042&type=printable"> Disaggregating Census Data for Population Mapping Using Random Forests with Remotely-Sensed and Ancillary Data</a> (Stevens, Gaughan, Linard &amp; Tatem)</li>
</ul>
</li>
<li>Wednesday: continue Project 2</li>
<li>Friday: group check-ins</li>
</ul>
<h3><a class="header" href="#week-8--2" id="week-8--2">Week 8 (...)</a></h3>
<ul>
<li>Monday: No Class (Spring Break)</li>
<li>Wednesday: No Class (Spring Break)</li>
<li>Friday: No Class (Spring Break)</li>
</ul>
<h3><a class="header" href="#week-9--2" id="week-9--2">Week 9 (...)</a></h3>
<ul>
<li>Monday: cancelled</li>
<li>Wednesday: cancelled</li>
<li>Friday: cancelled</li>
</ul>
<h3><a class="header" href="#week-10--2" id="week-10--2">Week 10 (...)</a></h3>
<ul>
<li>Begin remote instruction, all instruction will be live via <a href = "https://zoom.us/"> Zoom</a> at our normally scheduled class times.  A link to the live video feed will be posted on the slack channel for the current project.</li>
<li>Monday:
<ul>
<li><a href = "https://tyzao.gitbook.io/geodatasci/investigate/spat_model_predict"> Link to Project 2, Part 2: Modeling &amp; Predicting Spatial Values</a></li>
<li><a href = "https://www.openstreetmap.org/"> OSM</a> <em>just for review, consider use when reading Strano et al.</em></li>
<li><a href = "https://ciesin.columbia.edu/data/hrsl/"> CIESN-HRSL</a> <em>just for review, consider use when reading Maina et al. and Reed et al.</em></li>
</ul>
</li>
<li>Wednesday: continue Project 2
<ul>
<li><a href = "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5746564/pdf/rsif20170401.pdf"> Examining the correlates and drivers of human population distributions across low- and middle-income countries</a> (Nieves et al.)</li>
</ul>
</li>
<li>Friday: group check-ins</li>
</ul>
<h3><a class="header" href="#week-11--2" id="week-11--2">Week 11 (...)</a></h3>
<ul>
<li>Monday: continue Project 2
<ul>
<li><a href = "https://tyzao.gitbook.io/geodatasci/investigate/invest_compare"> Link to Project 2, Part 3: Investigating and Comparing Results</a></li>
</ul>
</li>
<li>Wednesday: continue Project 2
<ul>
<li><a href = "https://www.nature.com/articles/s41598-018-22969-4"> Mapping road network communities for guiding disease surveillance and control strategies</a> (Strano, Viana, Sorichetta &amp; Tatem)</li>
</ul>
</li>
<li>Friday: <strong>Informal Group Presentations</strong></li>
<li><strong>Project 2 Due</strong>: Sunday Midnight (...)</li>
</ul>
<h3><a class="header" href="#week-12--2" id="week-12--2">Week 12 (...)</a></h3>
<ul>
<li>Monday: Begin Project 3
<ul>
<li><a href = "https://tyzao.gitbook.io/geodatasci/access/defacto_descript"> Link to Project 3, Part 1: De facto description of human settlements and urban areas</a></li>
</ul>
</li>
<li>Wednesday: continue Project 3, Part 1
<ul>
<li><a href = "https://www.nature.com/articles/s41597-019-0142-2"> A spatial database of health facilities managed by the public health sector in sub Saharan Africa</a> (Maina et al.)</li>
</ul>
</li>
<li>Friday: group check-ins</li>
</ul>
<h3><a class="header" href="#week-13--2" id="week-13--2">Week 13 (...)</a></h3>
<ul>
<li>Monday: continue Project 3
<ul>
<li><a href = "https://tyzao.gitbook.io/geodatasci/access/defacto_descript"> Link to Project 3, Part 2: De facto description of human settlements and urban areas</a></li>
</ul>
</li>
<li>Wednesday: continue Project 3, Part 2
<ul>
<li><a href = "https://www.mdpi.com/2306-5729/3/3/33/htm"> Gridded Population Maps Informed by Different Built Settlement Products</a> (Reed et al.)</li>
</ul>
</li>
<li>Friday: <strong>Informal Group Presentations</strong></li>
<li><strong>Project 3 Due</strong>: Sunday Midnight (...)</li>
</ul>
<h3><a class="header" href="#week-14--2" id="week-14--2">Week 14 (...)</a></h3>
<ul>
<li>Monday: Begin Project 4
<ul>
<li><a href = "https://tyzao.gitbook.io/geodatasci/topography"> Link to Project 4, Part 1: Rendering Topography</a></li>
</ul>
</li>
<li>Wednesday: continue Project 4</li>
<li>Friday: continue Project 4</li>
</ul>
<h3><a class="header" href="#week-15--2" id="week-15--2">Week 15 (...)</a></h3>
<ul>
<li>Monday: group meeting and planning
<ul>
<li><a href = "https://tyzao.gitbook.io/geodatasci/final"> Link to Project 4, Part 2: Final Presentation</a></li>
</ul>
</li>
<li>Wednesday: group meeting and planning</li>
<li>Friday: - <strong>Presentation of Group Projects</strong> <em>each group schedules presentation time</em></li>
</ul>
<h3><a class="header" href="#final-due-" id="final-due-">Final (Due ...)</a></h3>
<ul>
<li><strong>Individual Project</strong></li>
</ul>
<h1><a class="header" href="#preparations" id="preparations">Preparations</a></h1>
<hr />
<h2>description: &gt;-
Create a GitHub site that will use to populate with results from your
geospatial data science investigation on your selected LMIC and administrative
subdivision(s).</h2>
<h1><a class="header" href="#getting-started-with-github" id="getting-started-with-github">Getting started with GitHub</a></h1>
<p>Through the course of this semester you will use GitHub as a repository to save and share your work.  GitHub uses a fairly simple programming language called markdown which you will use to present content you have created.  Upon completing your different GitHub sites, I will ask you to post a link to your website on the appropriate slack channel #data1X0_ prior to the given deadline.</p>
<p>To begin go to <a href="https://github.com">https://github.com</a> and create a new account.  You should see a website that is very similar to the following image.</p>
<p><img src="images/screen-shot-2019-12-08-at-9.15.32-pm.png" alt="" /></p>
<p>After clicking on the sign up link, create your account by designating your username, e-mail address and password.  In order to simulate the process of signing up, I am using the username <code>wicked-problems.</code>  My real GitHub account is <a href="https://github.com/tyler-frazier">https://github.com/tyler-frazier</a>, and you are welcome to follow me, although it is not necessary for this final project.</p>
<p><img src="images/screen-shot-2019-12-08-at-9.08.29-pm.png" alt="" /></p>
<p><img src="images/screen-shot-2019-12-08-at-9.11.13-pm.png" alt="" /></p>
<p>After creating your account, you should receive an e-mail asking to verify your account.  Go ahead and verify, so GitHub can permit you to create a new repository.  Once you verify your e-mail address, GitHub will likely ask if you want to create a new repository.  If somehow you are not automatically asked to create a new repository, it is also possible by selecting the + pull down arrow in the top right corner of the page.</p>
<p><img src="images/screen-shot-2019-12-08-at-9.28.39-pm.png" alt="" /></p>
<p>You will also notice that there is a guide made available for new users (the green, read the guide tab).  This is really good guide to read, in order to learn how to use GitHub as a version control system.  Although you will be using only a small amount of GitHub's full potential for this final project, I highly recommend making a mental note of the guide and returning to the 10 minute read when you have some time.  If you are planning to major or minor in data science, computer science, or any discipline that has a signficiant compuational component, it will be very likely that at some point in the future you will need to use a version control system (such as GitHub) for repository control, sharing, collaboration, conflict resolution etc...<a href="https://guides.github.com/activities/hello-world/">https://guides.github.com/activities/hello-world/</a></p>
<p>Create your first repository.  In the following example I have named my repository <code>workshop</code>.</p>
<p><img src="images/screen-shot-2019-12-08-at-9.09.24-pm.png" alt="" /></p>
<p>After creating your repository, go to the main page for your repository.  You should see a quick setup script under the <code>code</code> tab.  Click on <code>create a new file</code> under the quick set-up at the top of the page in order to populate your newly created repository with a file named <code>README.md</code>.  The <code>.md</code> extension after the filename is the extension for a markdown file.  Markdown is a simple, plain text, formatting, syntax language which has as its main design goal, as-is readability.   It is a relatively simple language that will enable you to program webpage content fairly easily. </p>
<p><img src="images/screen-shot-2019-12-08-at-9.56.08-pm.png" alt="" /></p>
<p>This should bring you to a new page where you are able to create a new file.  In order for your GitHub Pages site to function properly, you will need a <code>README.md</code> file in the root folder of your repository.  Below the field for the file name is the markdown file body, where you will type your script.  Add a first level <code>header</code> to your <code>README.md</code> file by adding one <code>#</code> and following it with your title.</p>
<p><img src="images/screen-shot-2019-12-08-at-10.32.57-pm.png" alt="" /></p>
<p>You can also preview the output from your markdown file, by clicking on the preview changes tab.</p>
<p><img src="images/screen-shot-2019-12-08-at-10.33.05-pm.png" alt="" /></p>
<p>After typing the simple markdown script, scroll to the bottom of the page and click on the green commit button, to commit your file to your repository.  You will need to press this green button, each time you edit the content within a file or add new files to your repository.  By making a new commit to your repository, you are essentially updating all of the changes you had previously made.  While in the case of your final project, there is essentially only one person executing changes per repository, potentially a version control system has the power of resolving conflicts amongst multiple persons all committing changes to the same file simultaneously.  That is the power of a version control system, such as GitHub.</p>
<p><img src="images/screen-shot-2019-12-08-at-10.06.32-pm.png" alt="" /></p>
<p>To begin getting an understanding of how to use markdown, have a look at the following cheatsheet.  The two main areas to note are how to use <strong>headers</strong> and then a bit further down in the cheatsheet, how to produce <strong>tables</strong>.</p>
<p>{% embed url=&quot;https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet&quot; %}</p>
<p>For the final project, you will only be using headers, paragraph text and inserting images.  After having a look at the markdown cheatsheet, return to the main page of your repository, which should appear similar to the following image.  After navigating to that location, click on the <code>settings</code> tab in the top right hand corner.</p>
<p><img src="images/screen-shot-2019-12-08-at-10.32.39-pm.png" alt="" /></p>
<p>Scroll down to the <strong>GitHub Pages</strong> section under <code>settings</code> and change the page source from <code>none</code> to <code>master_branch</code>.</p>
<p><img src="images/screen-shot-2019-12-08-at-10.24.15-pm.png" alt="" /></p>
<p>After setting the branch where your <strong>GitHub Pages</strong> files will reside, also select the theme tab and choose one of the available themes.  I chose the theme <code>Caymen</code> for my page, but you are welcome to select any of the available themes for your final project.  After, selecting your theme and returning to the <strong>GitHub Pages</strong> section, you should notice a web address appear where your site has been published.  It might take a few moments for your webpage to appear, but not more than 10 or 15 seconds.  Usually it updates and publishes almost immediately.</p>
<p><img src="images/screen-shot-2019-12-08-at-10.40.01-pm.png" alt="" /></p>
<p>After clicking on the link, the newly created webpage that you will use to publish the results from your investigation should appear.  To start making changes to your website, go back to the main page of your repository and select the <strong>upload files</strong> tab.</p>
<p><img src="images/screen-shot-2019-12-08-at-10.59.08-pm.png" alt="" /></p>
<p>This should bring you to a page that will enable you to upload the images you have produced from each of the previous projects.  The interface should appear similar to the following image.  You can simply drag and drop images directly through the GitHub <strong>upload files</strong> interface.</p>
<p><img src="images/screen-shot-2019-12-08-at-10.58.00-pm.png" alt="" /></p>
<p>I will begin by dragging and dropping a few of the plots produced that describe the administrative subdivisions of Liberia as well as the spatial distribution of it's population.</p>
<p><img src="images/screen-shot-2019-12-08-at-11.04.22-pm.png" alt="" /></p>
<p>After dropping the files into my repository, the basic file structure appears as follows.</p>
<p><img src="images/screen-shot-2019-12-08-at-11.15.14-pm.png" alt="" /></p>
<p>To add the image <code>details.png</code> to your <code>README.md</code> file, first select the <code>README.md</code> file, and then select the pen image in the upper right hand side of the screen to begin editing the content you already saved to your markdown file.</p>
<p><img src="images/screen-shot-2019-12-08-at-11.17.44-pm.png" alt="" /></p>
<p>After opening up the markdown file editor, add a second level header by preceding the text with two <code>##</code> and then add your image by adding a <code>![]</code> in advance of the file name <code>details.png</code> , which is contained within <code>()</code> .  Don't forget to scroll down to the bottom of the page and click on the <strong>commit</strong> button to make sure the changes you have made to the file are properly committed to the repository.  If you do not commit your changes to your repository, your file will not have been saved nor will your webpage updates be published.</p>
<p><img src="images/screen-shot-2019-12-08-at-11.25.56-pm.png" alt="" /></p>
<p>After committing the changes and waiting a few moments, your changes will appear to the published webpage.</p>
<p><img src="images/screen-shot-2019-12-08-at-11.28.27-pm.png" alt="" /></p>
<p>After adding your map that describes the political subdivisions of your LMIC, also add your description of population as spatially distributed at different adm levels.</p>
<p><img src="images/screen-shot-2019-12-09-at-3.25.56-am.png" alt="" /></p>
<p>If you created an animated video, such as a <code>.mp4</code> file that rotates and describes population in three dimensions, you will need to convert that file to a <code>.gif</code> in order to include it in your project webpage.  This is fairly easily accomplished by using an online conversion tool.  I simply entered &quot;<em>online conversion of mp4 to gif mac</em>&quot; into google, and the search engine returned several possible options, such as <a href="https://ezgif.com/video-to-gif">https://ezgif.com/video-to-gif</a>, among many others.  After converting your <code>.mp4</code> to a <code>.gif</code> , upload the file to your repository and include it as an image in your markdown file, just like the other images.</p>
<p><img src="images/screen-shot-2019-12-09-at-3.34.14-am.png" alt="" /></p>
<p>Which will produce the following image as part of your webpage.</p>
<p><img src="images/pop.gif" alt="" /></p>
<p>{% embed url=&quot;https://wicked-problems.github.io/final_project/&quot; %}</p>
<p>Now continue to populate your newly created GitHub Pages site, using markdown and your <code>README.md</code> file.  There are a multitude of different structural approaches you could take to creating your webpage, such as creating different markdown files and providing links to each, but in the most basic form, you can simply use the <code>README.md</code> file to produce your final project.</p>
<p>images/# Installing R and R Studio on your Computer</p>
<h2><a class="header" href="#what-is-r" id="what-is-r">What is R?</a></h2>
<p><strong>R</strong> is a free, open source, programming environment for statistical computing and graphics that compiles and runs on Linux, Windows and Mac OSX.  It is a very capable programming environment for accomplishing everything from an introduction to data science to some of the most poweful, advanced, and state of the art computational and statistical methods.  R is capable of working with big data, high dimension data, spatial data, temporal data, as well as data at pretty much any scale imaginable, from the cosmos to the quark and everywhere in between.</p>
<p>The statistical programming language R is often called an interpreted programming language, which is different from machine or native programming languages such a <strong>C</strong> or <strong>Java</strong>.  An interpreted programming language is distinguished from machine languages because commands and arguments are interpreted prior to being executed by the programming engine.  <strong>Python</strong> is another, closely related interpreted programming language that is also popular amongst data scientists.  Although the use of an interpreter compromises speed, interpreted languages have a distinct advantage in their capacity to be more readily accessible and understandable.  For example, commands such as <code>plot</code>, <code>read.csv()</code>, or <code>cbind()</code> can be fairly easily understood as the commands for plotting an object, importing a <code>.csv</code> file or binding together columns of data.  This accessibility has led to the strength of an open source community that is constantly developing new functions for use within the R programming framework and well as supporting their use by the larger community.  One of the major advantages of an open source approach to programming is the community that supports and contributes to <strong>R</strong> continued development.</p>
<p><img src="https://peerj.com/preprints/27127.pdf" alt="An introduction to open source solutions by Hengl, Wheeler &amp; MacMillan" /></p>
<p>In addition to being an open source programming framework, learning to use <strong>R</strong> also fullfills one of the fundamental principals of the scientific method, reproducibility.  A reproducible programming environment functions by always keeping source data in its original state external from the R framework.  Data is then imported to the work session and all changes occur within the framework through the code as it is sequentially executed.  In this manner, any code one writes is perfectly reproducible not only an unlimited number of times you choose to run it as well as by any other person who has access to your code (unless you are incorporating probabilities type methods in your code).  Compare this reproducible workflow concept to software that employs a graphic user interface (GUI), where commands are executed by selecting a pull down menu and following a series of preset options associated with each command.  Excel, Pages, Arc or QGIS are examples of software that use a GUI as their primary means of user interaction. Most programming environments keep the code separate from the interpreter or compiler and is much more easily reproducible.</p>
<p>While <strong>R</strong> is easier to learn than more difficult programming languages such as C or Java, increasing its ease of use can be greatly advanced by using an integrated developer environment (IDE).  One of the most popular IDEs for <strong>R</strong> is called RStudio.  RStudio is dependent upon R in order to function, and literally sends commands and receives results to/from the interpreter.  RStudio has a number of different features that facilitate programming, project management, graphics production, reviewing data and a whole slew of other useful functions.  First you will want to install R and the associated tools, then follow by installing RStudio on your computer.</p>
<h2><a class="header" href="#installing-r" id="installing-r">Installing R</a></h2>
<p>Before installing R on your operating system, it is a good idea to briefly assess the state of your computer and its constituent hardware as well as the state of your operating system.  Prior to installing a new software environment, such as R, I always recommend the following.</p>
<ol>
<li>Do your best to equip your personal computer with the latest release of your operating system</li>
<li>Make sure you have installed all essential updates for your operating system</li>
<li>Restart your computer</li>
<li>Make sure that all non essential processes have not automatically opened at login, such as e-mail, messaging systems, internet browsers or any other software</li>
</ol>
<p>After you have updated your computer and done your best to preserve all computational power for the installation process, go the <strong>R Project for Statistical Computing</strong> website.</p>
<p>{% embed url=&quot;https://www.r-project.org&quot; %}</p>
<p>Find the <strong>download</strong> link and click on it.  If this is the first time you have downloaded <strong>R</strong>, then it is likely that you will also need to select a CRAN mirror, from which you will download your file.  Choose one of the mirrors from within the USA, preferable a server that is relatively close to your current location.  I typically select, Duke, Carnegie Mellon or Oak Ridge National Laboratory.   A more comprehensive install of R on a Mac OS X will include the following steps.</p>
<ol>
<li>Click on the <code>R.pkg</code>  file to download the latest release.  Following the steps and install <strong>R</strong> on your computer.</li>
<li>Click on the <strong>XQuartz</strong> link and download the latest release of <code>XQuartz.dmg</code> .  It is recommended to update your XQuartz system each time you install or update <strong>R</strong>.</li>
<li>Click on the <strong>tools</strong> link and download the latest <code>clang.pkg</code> and <code>gfortran.pkg</code>. Install both.</li>
</ol>
<p>Following are two video tutorials that will also assist you to install <strong>R</strong> on your personal computer.  The first one is for installing <strong>R</strong> on a Mac, while the second video will guide you through the process on Windows.</p>
<p>{% embed url=&quot;https://www.youtube.com/watch?v=V2x_SWJCd1A&amp;t=11s&quot; caption=&quot;Video tutorial of how to install R on a Mac&quot; %}</p>
<p>{% embed url=&quot;https://www.youtube.com/watch?v=1A-xvxNhd2w&quot; caption=&quot;Video tutorial of how to install R on Windows&quot; %}</p>
<h2><a class="header" href="#installing-rstudio" id="installing-rstudio">Installing RStudio</a></h2>
<p>RStudio is an integrated developer environment that provides an optional front end, graphic user interface (GUI) that &quot;sits on top&quot; of the R statistical framework. In simple terms, RStudio will make your programming experience much easier, and is typically a good way for beginners to start off with a programmer langauge such as R.  RStudio assists with coding, executing commands, saving plots and a number of other different functions.  While the two are closely aligned in design and function, it is important to recognizing that RStudio is a separate program, which depends on <strong>R</strong> having first been installed.</p>
<p>To install RStudio go to the following webpage and download the appropriate installer for your operating system.</p>
<p>{% embed url=&quot;https://www.rstudio.com/products/rstudio/download/#download&quot; %}</p>
<h1><a class="header" href="#getting-started-with-rstudio--r" id="getting-started-with-rstudio--r">Getting Started with RStudio &amp; R</a></h1>
<h2><a class="header" href="#starting-rstudio" id="starting-rstudio">Starting RStudio</a></h2>
<p>Once you have finished the installation process, run the RStudio IDE, which will automatically find R on your computer.  Find the application RStudio on your computer.  The RStudio executable should be located in the applications folder on a Mac.  Once running the RStudio application on a Mac it is often helpful to keep the application icon in the dock, which is the bar of applications that exists along the bottom of your computer desktop screen.  On Windows, if you select the Window icon in the bottom left corner and begin typing RStudio, you should see the application icon appear. On a Linux system, the application should appear in one of the OS drop down windows.  Choose the application icon and open it.</p>
<p>If both R and RStudio were properly installed, then the start up for RStudio should appear something like the following image.</p>
<p><img src="images/rstudio.png" alt="A new RStudio work session at initial startup" /></p>
<p>One of the first things to note at start up is the bottom left hand pane, which is essentially a window to the R interpreter.  RStudio reports the version of R that has been installed on your computer.  Next go to the pull down menu for <strong>File &gt; New Script &gt; R Script</strong> and select that option.  This will create a new R Script that will appear in the top left pane of your R Studio IDE.  One can think of the script as the location where all computer code will be written and saved, in a manner somewhat analogous to writing a letter or essay with a work processor.  Below the script in RStudio is the console or the location where your commands are sent and responses from R will be returned.  You can think of the <strong>&gt;</strong> symbol in the console as R somewhat figuratively waiting for your command and subsequently also the location where R will respond.</p>
<p>Since you now have a script file where you will save your first R commands, you should also have a working director where you will save your <code>my_first_script.R</code> file.  At this point you should minimize RStudio, and return to your file explorer or finder and create a folder that you will use to save your script, output as well as any files you may import to R.  Generally, I create a project specific folder and then within that folder I begin with two subdirectories, one that is dedicated for storing data and a second one that is dedicated to saving my scripts.  After you have created your project folder, return to RStudio and then select <strong>Session &gt;</strong> <strong>Set Working Directory &gt; Choose Directory</strong> from the drop down menu.  Choosing this command will result in a file explorer window appearing in order for RStudio to select the working directory for your work session.  The working directory is the default location where R will automatically look in order to import or export and data.  Go ahead and select the <strong>data</strong> subdirectory you just created within your project folder.  Upon selecting your data folder, you should notice a command appear within the console pane in the bottom left hand corner of RStudio.</p>
<p><code>setwd(&quot;~/my_folder/my_project_folder/my_data_folder&quot;)</code></p>
<p>By using the RStudio IDE GUI you have just executed your first command.  You can confirm that the command was properly executed from within the console by typing the following command directly in the console.</p>
<p><code>getwd()</code></p>
<p>You should notice that R returns the path from the working directory you just designated.  Instead of setting your working directory using the drop down menu, the preferred method is to designate that path by using code in R.  Fortunately, RStudio has already specified the command for you, so just go ahead and copy the <code>setwd()</code> command from above and paste it into your script file in the top left hand corner of your RStudio work session.  You could also retype it, but in general, copying and pasting is going to be much more efficient.  On a Mac copying and pasting is accomplished by using the <strong>⌘C</strong> &amp; <strong>⌘V</strong> keys or on Windows <strong>control-C</strong> and <strong>control-V</strong>. ****  After copying and pasting that line of code within your script, go ahead and execute the function again, except this time, send the command directly from your script to the console.  To do this use, move the cursor to the line where you pasted the code and then select <strong>⌘return</strong> on a Mac or <strong>control-return</strong> on Windows.  Congratulations! You have just written and executed your first line of code.</p>
<p>Now that your script has content, you should save the file.  Select the <strong>&gt;File&gt;Save</strong> command from the drop down window and choose the data subdirectory you created within your project folder.  Name your script file and then select save.  Your RStudio work space should appear similar to the following image.</p>
<p><img src="images/rstudio1.png" alt="State of your RStudio workspace after setting the working directory and saving your script" /></p>
<p>One noteworthy observation regarding the command <code>setwd()</code>, notice how the path to the working directory is specified within quotation marks.  In general, whenever RStudio is communicating with your operating system (OS) or any entity outside of its workspace, what ever is being sent to that computer will be included within quotation marks.  For example <code>setwd(&quot;the/path/to_my/working/directory&quot;)</code> is contained within quotation marks in order for RStudio to traverse the path  as defined by your OS to that location on your computer.</p>
<hr />
<h2>description: &gt;-
In this exercise you will learn how to create vector and data frame objects,
use the sample function and generate a plot that includes different types of
squares, circles and lines.</h2>
<h1><a class="header" href="#creating-and-plotting-objects" id="creating-and-plotting-objects">Creating and Plotting Objects</a></h1>
<h2><a class="header" href="#creating-an-object--creating-a-plot" id="creating-an-object--creating-a-plot">Creating an object &amp; creating a plot</a></h2>
<p>Since you have already set your working directory in the previous step, now you can create your first object.  Do so by writing the following command in your script.</p>
<p><code>x &lt;- 1:10</code></p>
<p>There are essentially three parts to this command.  First take note of the <code>&lt;-</code> symbol, which is often called the assignment operator.  The <code>&lt;-</code> operator will function by assigning everything on its right hand side to the newly named object on the left.  For example, if you entered the command <code>t &lt;- 1</code> and then typed <code>t</code> directly in the console and pressed return, R would inform you of the value of <code>t</code>, which would be 1.  After creating and defining <code>x</code> do the same thing for <code>y</code> but this time start with the highest value and decrease sequentially to 1.</p>
<p><code>y &lt;- 10:1</code></p>
<p>Now lets move to the console and ask R a few things directly. Sometimes we want to save our script, while at other times we just want to ask R a quick question. First lets ask R to list all the objects that exist in our workspace at this point in time.  We use the <code>ls()</code> command to list all objects that exist in our workspace.</p>
<p><code>[1] &quot;x&quot; &quot;y&quot;</code></p>
<p>Let's also ask R to tell us more about the two objects we have created and placed in our workspace. Go ahead and type <code>x</code> and then <code>y</code> directly into your console and consider the output.</p>
<p><code>x</code></p>
<p><code>[1] 1 2 3 4 5 6 7 8 9 10</code> </p>
<p><code>y</code></p>
<p><code>[1] 10 9 8 7 6 5 4 3 2 1</code></p>
<p>We can see that our earlier use of the colon in <code>x &lt;- 1:10</code> created an object named <code>x</code> that contains each whole number in sequence from 1 to 10, while y likewise did the same except in reverse. Also by simply typing the name of the object, R reveals to us everything it knows.  Since we have two objects of equal length, lets plot x &amp; y together.</p>
<p><code>plot(x,y)</code></p>
<p><img src="images/rplot01%20%283%29.png" alt="A plot of x increasing while y is decreasing" /></p>
<p>We can continue to describe our plot by adding an argument to our command by specifying the plot type as a line and not simply points</p>
<p><code>plot(x, y, type = &quot;l&quot;)</code></p>
<p>or alternatively a plot with both a line and points over that line.</p>
<p><code>plot(x, y, type = &quot;o&quot;)</code></p>
<p><img src="images/rplot02%20%282%29.png" alt="A plot produced using the &quot;over&quot; specification in the argument " /></p>
<p>We can also add some description to our plot in order to better communicate our results.  We can begin by adding a title, indicating the units of measurement while also adding labels for both the x and y axes.</p>
<pre><code class="language-r">plot(x, y, type = &quot;o&quot;, 
main = &quot;The Path of a Running Boy&quot;,
sub = &quot;units of distance = meters&quot;,
xlab = &quot;longitude&quot;, 
ylab = &quot;latitude&quot;)
</code></pre>
<p><img src="images/rplot03.png" alt="Plot with a Title, Sub-Title and Axes Labels" /></p>
<p>We can also change the linetype by specifying the <code>lty =</code> argument or set the lineweight by using the <code>lwd =</code> argument.  The color of our line can be changed using the <code>col = &quot;some_color&quot;</code> argument, while the point symbol itself can be modified by using the <code>pch =</code> argument.  Scale of the symbol is increased or descreased using <code>cex =</code>.  Have a look at the <a href="https://www.statmethods.net/advgraphs/parameters.html">Quick-R</a> website for a comprehensive list of some available graphical parameters.</p>
<pre><code class="language-r">plot(x, y, type = &quot;b&quot;, main = &quot;The Path of a Running Boy&quot;, 
     sub = &quot;units of distance = meters&quot;, 
     xlab = &quot;longitude&quot;, 
     ylab = &quot;latitude&quot;,
     lty = 2,
     lwd = .75,
     col = &quot;blue&quot;,
     pch = 0,
     cex = 1.5)
</code></pre>
<p><img src="images/rplot04%20%281%29.png" alt="A Plot with Some Point and Line Type Modifications" /></p>
<h2><a class="header" href="#creating-a-more-complicated-plot-while-also-creating-and-then-using-a-data-frame" id="creating-a-more-complicated-plot-while-also-creating-and-then-using-a-data-frame">Creating a More Complicated Plot while also creating and then using a Data Frame</a></h2>
<p>Now lets make your plot a bit more complicated than simply a line with points.  First increase the scale of our plot area by increasing the range of values for both the x &amp; y axes.</p>
<pre><code class="language-r">x &lt;- 1:100
y &lt;- 1:100
</code></pre>
<p>Now instead of using those values, let's randomly select from both <code>x</code> &amp; <code>y</code> in order to produce a random series of x &amp; y coordinates.</p>
<pre><code class="language-r">east &lt;- sample(x, size = 10, replace = TRUE)
north &lt;- sample(y, size = 10, replace = TRUE)
</code></pre>
<p>The above command <code>sample()</code> will randomly select in a uniform manner, one number from <code>x</code> and then also <code>y</code>, 10 times, creating the vector objects <code>east</code> &amp; <code>north</code>.  I have also included the <code>replace = TRUE</code> argument, such that each time a number is selected, it is returned and potentially can be selected again in the next draw.  Now, lets take each value and use it as the coordinates for the center point of a number of squares.  We will use the <code>symbols()</code> command in order to add additional specifications to our command.</p>
<pre><code class="language-r">symbols(east, north, squares = rep(.75,10), inches = FALSE)
</code></pre>
<p>Following is one possible outcome produced by the randomly produced coordinates.  While the squares produced in your plot will be in different locations, the number of squares as well as the size of each, should be very similar.  Lets also consider the additional arguments in the <code>symbols()</code> command.  In the <code>squares =</code> argument within the command, I have also used the <code>rep()</code> function, which will repeat the length of each square, <code>.75</code> in this case, 10 times, or 1 time for each square.  I have also added the <code>inches = FALSE</code> argument so the units are considered to be similar to the axes.</p>
<p><img src="images/rplot01%20%286%29.png" alt="Squares within a Defined Area" /></p>
<p>Now lets add some circles to our plot.  This time, instead of assigning an object a permanent value by randomly selecting from a series of numbers, lets randomly select values as part of creating the plot with the <code>symbol()</code> function.</p>
<pre><code class="language-text">symbols(sample(x, 10, replace = TRUE), 
        sample(y, 10, replace = TRUE), 
        circles = rep(.75,10), 
        inches = FALSE,
        fg = &quot;green&quot;,
        add = TRUE)
</code></pre>
<p>Where as before I created two objects and plotted their values as x &amp; y coordinates, this time I have nested the <code>sample()</code> command within the <code>symbols()</code> function, in the place where R is looking for the x &amp; y value coordinates.  In this manner, each time I execute the command, 10 circles will be randomly placed throughout the defined area, each with a radius of <code>.75</code>.  I have also included the <code>add = TRUE</code> argument within the command, in order to add the circles to our previous plot of square.  The <code>fg =</code> argument permits us to select a color for each circle.</p>
<p><img src="images/rplot02%20%283%29.png" alt="Squares with Randomly Placed Circles within a Defined Area" /></p>
<p>Let's also add some larger trees and specify their color as well.  Again we will randomly place them while using the <code>add = TRUE</code> argument so they are added to our previous plot.  Also, consider a wider range of colors to use as the outline for each circle, while also filling each circle with a color.  In order to determine how to fill the circle with a color, use the <code>?</code> followed by the command you are interested in learning more about in order to view all of the available options.  In this case you can type <code>?symbols</code> directly in the console in order to see all of the arguments possible.  If you scroll down in the help window, you will see that <code>fg =</code> is used to specify the color or your symbol border, while <code>bg =</code>  is used to indicate the color for your symbol's fill.  You may also be interested to know which colors are available to select.  In order to review a list of all available colors, simply type <code>colors()</code> directly into your console.  Running the following chunk of commands will then produce a plot similar to the following image.</p>
<pre><code class="language-text">symbols(east, north, squares = rep(.75,10), inches = FALSE)

symbols(sample(x, 10, replace = TRUE), 
        sample(y, 10, replace = TRUE), 
        circles = rep(.75,10), 
        inches = FALSE,
        fg = &quot;green1&quot;,
        bg = &quot;beige&quot;,
        add = TRUE)

symbols(sample(x, 10, replace = TRUE), 
        sample(y, 10, replace = TRUE), 
        circles = rep(1.5,10), 
        inches = FALSE,
        fg = &quot;green4&quot;,
        bg = &quot;beige&quot;,
        add = TRUE)

</code></pre>
<p><img src="images/rplot03%20%284%29.png" alt="Squares with Two Types of Circles within a Defined Area" /></p>
<p>Thus far we have only created R objects that are of the vector class.  We can review the class of one of the objects we have created by typing <code>class(east)</code> directly into the console and observe that R informs us that the object is a vector of integers.  Now let's create a new class of an object called a data frame that contains a series of rows and columns where each row represents an observation while each column represents a different variable.  We can start with the coordinates that represent the center point of each square.</p>
<pre><code class="language-r">dwellings &lt;- cbind.data.frame(id = 1:10, east, north)
</code></pre>
<p>In this case, we are using the <code>cbind.data.frame()</code> command to column bind together the newly created variable named <code>id</code> with our two integer vectors <code>east</code> &amp; <code>north</code> into a newly formed data frame named <code>dwellings</code>.  After executing the above command, you can type the name of your data frame directly into the console to review its content.  Within the environment pane in the top right hand window, under the data tab, you can also use your mouse to click on the data frame symbol that is off to the right of the <code>dwellings</code> data object.</p>
<table><thead><tr><th align="left"></th><th align="left">id</th><th align="left">east</th><th align="left">north</th></tr></thead><tbody>
<tr><td align="left">1</td><td align="left">1</td><td align="left">48</td><td align="left">64</td></tr>
<tr><td align="left">2</td><td align="left">2</td><td align="left">25</td><td align="left">74</td></tr>
<tr><td align="left">3</td><td align="left">3</td><td align="left">59</td><td align="left">10</td></tr>
<tr><td align="left">4</td><td align="left">4</td><td align="left">37</td><td align="left">83</td></tr>
<tr><td align="left">5</td><td align="left">5</td><td align="left">97</td><td align="left">29</td></tr>
<tr><td align="left">6</td><td align="left">6</td><td align="left">74</td><td align="left">92</td></tr>
<tr><td align="left">7</td><td align="left">7</td><td align="left">84</td><td align="left">16</td></tr>
<tr><td align="left">8</td><td align="left">8</td><td align="left">17</td><td align="left">98</td></tr>
<tr><td align="left">9</td><td align="left">9</td><td align="left">70</td><td align="left">21</td></tr>
<tr><td align="left">10</td><td align="left">10</td><td align="left">33</td><td align="left">69</td></tr>
</tbody></table>
<p>You'll notice that R also provides row numbers that in this case are identical to the identification number we have assigned to each square.  Instead of assigning our <code>id</code> variable manually, we could have just as easily used <code>id = row.numbers(dwellings)</code> in order to achieve the same result, if the object <code>dwellings</code> already exists.</p>
<p>Now let's add a line that represents some type of transportation activity between each of the different dwelling units we have represented within our plot as squares.  We can add lines to the plot with the <code>lines()</code> command.  In order to identify the beginning and ending point of each line we set the <code>x =</code> argument to the <code>east</code> variable within the <code>dwellings</code> data frame.  Likewise we set the the <code>y =</code> argument to the <code>north</code> variable also witin the <code>dwellings</code> data frame.  One manner of informing R which variable is needed within a data frame is to use the <code>$</code> operator.  In general terms, the form to call a variable is <code>my_data_frame$my_variable</code>.  Following is an example, which should produce something similar to the subsequent plot.</p>
<pre><code class="language-r">lines(x = dwellings$east,
      y = dwellings$north,
      lty = 2,
      lwd = .75,
      col = &quot;blue&quot;)
</code></pre>
<p><img src="images/rplot04.png" alt="Paths travelled from House to House" /></p>
<p>You'll notice that unlike the previous commands, it wasn't necessary to include <code>add = TRUE</code> in order to add the lines to the plot.  Perhaps it would also be helpful to add some text to annotate each household.  We can accomplish this using the <code>text()</code> command.  As with <code>lines()</code>, we also do not need to use the <code>add = TRUE</code> argument.  The <code>text()</code> function also requires identifying the location of the text you will use to annotate each dwelling unit.  That is accomplished through using the <code>labels =</code> argument.  Again, identify the variable where the id is located within the data frame using the <code>my_data_frame$my_variable</code> format.</p>
<pre><code class="language-r">text(x = dwellings$east,
     y = dwellings$north,
     labels = dwellings$id)
</code></pre>
<p>Since label coordinates are the same as the center point for each square, reading the labels is confounded.  Instead of placing the label directly on top of the dwelling unit, add a few units north to the <code>y =</code> argument in order to displace each label a bit in the northerly direction.</p>
<p><img src="images/rplot05%20%283%29.png" alt="Paths &amp; House Numbers" /></p>
<p>Now perhaps instead of traversing a path between each house sequentially, our traveling person selected on 3 of the dwellings and moved between each of those buildings.  First we will randomly select 3 numbers that will be used to identify the chosen homes.  This time, set the <code>replace =</code> argument to <code>FALSE</code> since our traveling person will only visit each dwelling unit one time.</p>
<pre><code class="language-r">locs &lt;- sample(1:10, 3, replace = FALSE)
</code></pre>
<p>Now instead of using the <code>lines()</code> command to identify the <code>x =</code> and <code>y =</code> coordinates of each dwelling unit's center point, we will select only 3 building locations.  To do this, we wil lintroduce another method of traversing and selecting rows and/or columns from a data frame for use in an command and its arguments.  The <code>[</code> and <code>]</code> symbols are extremely powerful operators and can be used to subscript from within a function or argument.  Subscripting operators follow the format of first selecting the rows followed by a comma and then columns in this <code>[row_numbers, column_numbers]</code> format.  If either the rows space or columns space is left blank, then R assumes ALL rows and/or columns should be selected.  In the following command, I am using these subscripting operators to first select the 3 rows from the data frame that were randomly identified and then also include either column 2 for the easterly coordinate, or column 3 for the northerly coordinate.</p>
<pre><code class="language-r">lines(x = dwellings[locs, 2],
      y = dwellings[locs, 3],
      lty = 2,
      lwd = .75,
      col = &quot;blue&quot;)
</code></pre>
<p>Alternatively I could have also specified <code>x = dwellings[locs, ]$east</code> and <code>y = dwellings[locs, ]$north</code> in order to achieve the same result.  The following snippet demonstrates how that is accomplished while adding text in order to annotate each house with its id.</p>
<pre><code class="language-r"># text(x = dwellings$east,
#      y = dwellings$north + 3,
#      labels = dwellings$id)

text(x = dwellings[locs, ]$east, 
     y = dwellings[locs, ]$north + 3,
     labels = dwellings[locs, ]$id)
</code></pre>
<p>You'll notice in the previous snippet of code that the <code>#</code> sign has been added to the first character space on lines 1, 2, &amp; 3.  Adding the <code>#</code> sign enables you to comment out that line of code so R will ignore it.  In the above example, I have commented out the lines of code we produced earlier where we labeled all 10 houses, and followed it with out code that serves to label only the 3 units that were randomly selected.  At this point our plot should appear similar to the following image.</p>
<p><img src="images/rplot06.png" alt="Paths between 3 Identified Homes" /></p>
<p>Now instead of using a straight line, let's use a spline to represent a more continuous path betweem each of the selected locations along the persons travel path.  Comment out the previous <code>lines()</code> command and instead use the <code>xspline()</code> command to identify the path.  I will set the <code>shape = -1</code> in order to interpolate all points while crossing each dwelling unit.</p>
<pre><code class="language-text">xspline(x = dwellings[locs, 2],
      y = dwellings[locs, 3],
      shape = -1,
      lty = 2)
</code></pre>
<p><img src="images/rplot07.png" alt="The Path of a Person en route between Homes" /></p>
<p>Finally, add a title to your plot using <code>title(main=&quot;A Person's path between Homes&quot;)</code>.</p>
<h2><a class="header" href="#challenge-question" id="challenge-question">Challenge Question</a></h2>
<p>Create a similar plot as the one produced above, but instead meet the following specifications.</p>
<ul>
<li>Increase the minimum and maximum limits of your area from 1 to 1000 in both the <code>x</code> &amp; <code>y</code> dimension.</li>
<li>Randomly place 50 dwelling units throughout the 1000 x 1000 dimensioned area. Size each square appropriately.</li>
<li>Randomly place 40 small circles (trees) throughout the 1000 x 1000 dimensioned area.  Set the radius of each circle to the same or approximately the same as the width of each home.</li>
<li>Randomly place 12 large trees throughout the defined area, such that each tree has almost twice the radius as each home's width.</li>
<li>Randomly select 7 homes from the 50 total, and use a dashed spline to describe the path between each labeled dwelling unit.</li>
<li>Title your plot.</li>
</ul>
<p><img src="images/rplot08.png" alt="One version of the plot produced by following the Challenge Question Specifications" /></p>
<h1><a class="header" href="#local" id="local">Local</a></h1>
<h1><a class="header" href="#getting-started-with-google-colab" id="getting-started-with-google-colab">Getting Started with Google Colab</a></h1>
<h1><a class="header" href="#chapter-2" id="chapter-2">Chapter 2</a></h1>
<h2><a class="header" href="#describe-1" id="describe-1">Describe</a></h2>
<hr />
<h2>description: &gt;-
Locating and retrieving administrative subdivisions for your selected LMIC, as
well as plotting boundaries and labelling each local government unit.</h2>
<h1><a class="header" href="#projecting-plotting-and-labelling-administrative-subdivisions" id="projecting-plotting-and-labelling-administrative-subdivisions">Projecting, Plotting and Labelling Administrative Subdivisions</a></h1>
<p>We have had a bit of practice creating a theoretical environment, but now we will move to a more practical application.  In this exercise you will learn how to <strong>install a package</strong> and <strong>load a library of functions</strong> into R, <strong>install spatial data as a simple feature</strong> and then <strong>use the grammar of graphics</strong> (aka <code>ggplot::</code>) to plot your geospatial data.  To begin, install a package that will be used in order to describe and analyze our simple features.</p>
<pre><code class="language-r">install.packages(&quot;tidyverse&quot;, dependencies = TRUE)
</code></pre>
<p>In the above command we are installing a collection of packages designed for data science, where all packages share a common design.  Once RStudio has informed you that the package has been installed, you may then execute the command that makes the library function available for use during your current work session.</p>
<pre><code class="language-r">library(tidyverse)
</code></pre>
<p>After executing the library command, R may inform you about the current version of attached packages while also identifying any conflicts that may exist.  Conflicts between functions often exist when one package installs a function that has the same name as another function in another package.  Generally, what happens, is the latest package to be installed will mask a same named function from a previously loaded library.</p>
<p>The tidyverse is not one library of functions, but is in fact a suite of packages where each one conforms to an underlying design philosphy, grammar and data structure.  In the previous exercises we used commands from the base R package, but in this exercise we will begin to consider the more recent development of the tidyverse syntax nomenclature that emerged from the gramar of graphics (ggplot2).  The <a href="https://www.tidyverse.org/">tidyverse</a> is arguably a more coherent, effective and powerful approach to data science programming in R.</p>
<p>After installing and loading the <code>tidyverse</code> suite of packages, let's install yet another important package that is used when working with spatial data.</p>
<pre><code class="language-r">install.packages(&quot;sf&quot;, dependencies = TRUE)
</code></pre>
<p>This will install the <code>sf</code> package,  or <a href="https://r-spatial.github.io/sf/">simple features</a>, which like the tidyverse is a recent, arguably more effective implementation of a design philosphopy for using spatial data in R.  The <code>sf::</code> package also has been designed to integrate with the <code>tidyverse</code> syntax.  After installing <code>sf::</code>, then as before run the <code>library()</code> function to load the library of functions contained within the package for use in your current R worksession.</p>
<p>After running the <code>install.packages()</code> command successfully, you should add a <code>#</code> at the beginning of that line in order to comment it out. Running the <code>install.package()</code> command is generally necessary only once, in order to retrieve the package from a remote location and install it on your local machine, but it is necessary to run the <code>library()</code> command each time you open R and wish to access a function from within that library.</p>
<p>Another helpful command to add at the beginning of your script is <code>rm(list=ls(all=TRUE))</code> , which will delete everything from your R workspace from the outset. By running this line of code first in your script, you will be working with what John Locke called a <em>tabula rasa</em> or a clean slate from the outset. After adding the remove all function as your first line of code but after installing your packages and loading those libraries, be sure to set your working directory. While it's fine to use the drop down menu to find the location of your working directory, the first time, it is a good idea to copy that line of code into your script, so the <code>setwd()</code> command can be executed programmatically instead of through the GUI (which will save you time). At this point your script should look like the following snippet of code.</p>
<pre><code class="language-r">rm(list=ls(all=TRUE))

# install.packages(&quot;tidyverse&quot;, dependencies = TRUE)
# install.packages(&quot;sf&quot;, dependencies = TRUE)

library(tidyverse)
library(sf)

setwd(&quot;the/path/to_my/working/directory&quot;)
</code></pre>
<p>The next step is to visit the <a href="https://www.gadm.org/">GADM</a> website, which is a repository of spatial data that is describing global administrative subdivisions or every country on earth.  Select the data tab and become familiar with how the portal presents the administrative subdivision of each country.  Find the country link towards the top of the page that forwards you to another page with a drop down tab for downloading GADM data.</p>
<p><img src="images/screen-shot-2020-02-02-at-6.53.27-pm.png" alt="GADM webpage at UC Davis" /></p>
<p>As an example, I will select the West African country of Liberia.  The result should present a number of different options for obtaining a spatial data that describes of <strong>Liberia's administrative boundaries</strong>.  Administrative boundaries refer to the national border as well as all of the regional, district and local government subdivisions of that country.</p>
<p>Throughout the course of the semester we will use a number of different data sets that  describe healthsites, settlements, roads, population, pregnancies, births, and a number of other local dimensions of human development. Some of the data made available through WorldPop or the Humanitarian Data Exchange will have been <strong>remotely sensed</strong>, usually from a satellite orbitting the earth. This remotely sensed data is then classified according to different discrete types or perhaps by assigning values or intervals of possible values. Other times the data available will have been obtained from a source in the field, and most typically from some institution or group located or working within that particular country. Surveys and census data are examples of <strong>secondary sources</strong> that were most often obtained from local institutions. Like remotely sensed data, secondary sources also serve to provide a description of existing conditions, while serving as the basis for further analysis, modeling, inference and potential simulations.</p>
<p>Typically, administrative boundaries and subdivisions have been obtained and provided by one of the regional offices within the <em>United Nations Office for the Coordination of Humanitarian Affaris</em> (OCHA).  For example, the secondary sources of data that describe Liberia's political geography were likely provided by the <em>Regional Office of West and Central Africa</em> (ROWCA), presumably as they have obtained these sources from a ministry of government from within Liberia.  Every country employs a unique nomenclature in order to describe its administrative subdivisions.  Liberia is first subdivided into <em>counties</em> with each county further subdivided into <em>districts</em>.  Each of Liberia's <em>districts</em> is then further subdivided into what are called <em>clan areas.</em></p>
<p>Once you have found the the page for downloading Liberia's administrative subdivisions, note the different available spatial data types, as well as the different levels.</p>
<p><img src="images/screen-shot-2020-02-02-at-7.06.06-pm.png" alt="" /></p>
<p>For our purposes, we want to obtain the national boundary (LBR_0), first level administrative subdivisions (LBR_1) and second level administrative subdivisions (LBR_2).  Click on the <strong>Shapefile</strong> link in order to download a folder that contains a shapefile as well as a number of different corresponding files.  After the folders have been downloaded, go to your working directory and create a new folder named <strong>data</strong> and then move the folders describing Liberia's administrative subdivisions to within that folder.  The structure of your working directory should look something like the following (minus the additional folders).</p>
<p><img src="images/screen-shot-2020-02-02-at-7.41.35-pm.png" alt="" /></p>
<p>You will also notice that there are a number of different files, each one with the same file name yet also having a unique file extension.  The file extension is the <em>three letter part of the file name that is to the right of the period</em>, and acts somewhat as an acronym for the file type.  For example, files that have the <code>.shp</code> file extension are called shapefiles.  A shapefile contains the geometry of the points, lines and polygons used to spatially describe, in this example, the political geography of Liberia.  A shapefile also requires most of the other files found in the folder in order for it to function properly.  For example, the <code>.prj</code> file provides the projection that is used when plotting the geometry.  The <code>.dbf</code> file provides the attributes associated with each spatial unit (for example the name associated with each county or district).  Other files also provide information that enables RStudio to further interpret the spatial information in order to better serve our purposes.</p>
<p>In order to import a shapefile into RStudio we are going to use a command from the <code>sf::</code> package (simple features).  RStudio will need to find each of the <code>.shp</code> files in order to import the international border, the first level administrative subdivisions and the second level administrative subdivisions.  If I have set my working directory to the <strong>data</strong> folder, then RStudio will need to traverse through the subfolder in order to locate the correct <code>.shp</code> files.  You also will need to use the <code>read_sf()</code> command to import the <code>.shp</code> file into RStudio and create a simple feature class object.</p>
<pre><code class="language-r">lbr_int  &lt;- add_command_here(&quot;add_folder_here/add_file_name_here.shp&quot;)
</code></pre>
<p>Once you have successfully executed the above function using the <code>sf::read_sf()</code> command, you should observe a new object named <code>lbr_int</code>appearing in the top right data pane within your RStudio environment.  To the right of your newly created object there is a small gridded box that you will be able to click on in order to view individual attributes associated with this simple feature class spatial object.  You will also notice that within the data pane, RStudio also provides you with some basic information about the object, in this case 1 observation that has 7 variables.</p>
<p>The <code>sf::</code> package also includes a function called <code>st_geometry()</code> that will enable you to view some of the basic geometry associated with the object you have named <code>lbr_int</code>.  Type the name of your object within the <code>st_geometry()</code> command so that RStudio will return some basic geometric information about our spatial object that describes Liberia's international border.  You don't necessarily need to write this command in your script, you can just enter it directly into the console</p>
<p><img src="images/screen-shot-2019-09-07-at-1.32.41-pm.png" alt="Some basic R commands" /></p>
<p>After using the <code>st_geometry()</code> command with our <code>lbr_int</code> object, RStudio provides us with a basic description that includes the geometry type (polygons in this case, but it could also return points or lines), the x &amp; y minimum and maximum values or also know as the bounnding box (bbox), the epsg spatial reference identifier (a number used to identify the projection) and finally the projection string , which provides additional information about the projection used.</p>
<p>Now that we have conducted a cursory investigation of our simple feature object geometry, let's plot our simple features class object that describes the international border of Liberia.  To plot, we will use a series of functions from a package called <code>ggplot()</code>.  The gg in the package name <code>ggplot::</code> stands for the grammar of graphics, and is a very useful package for plotting all sorts of data, including spatial data classes created with the <code>sf::</code> package.  To start add <code>ggplot() +</code> to your script and then on the following line add the <code>geom_sf(data = your_sf_obj)</code> in order to specify the data that <code>ggplot()</code> should use in producing its output.</p>
<pre><code class="language-r">ggplot() +
  geom_sf(data = your_sf_obj)
</code></pre>
<p>Following the <code>data =</code> argument, you can also specifiy the line weight for the border using the <code>size =</code> argument.  It is also possible to specify the <code>color =</code> as well as the opacity / transparency of your polygon using the <code>alpha =</code> argument.  With the following script I have set the international border line weight width to <code>1.5</code> , the color of the border to <code>&quot;gold&quot;</code> , the fill color for the internal portion of the polygon to <code>&quot;green&quot;</code> and the <code>alpha =</code>   value to .5 or 50% transparent.</p>
<p><img src="images/liberia%20%283%29.png" alt="Liberia with a green fill and gold border" /></p>
<p>It would also be helpful to have a label describing our plot.  In order to do this we can use either the <code>geom_sf_text()</code> command or the <code>geom_sf_label()</code> command.  In the following snippet of code you will notice that I have added the aesthetics argument within my <code>geom_sf_text()</code> command.  The <code>aes =</code> argument enables us to specify which variable contains the label we will place on our object.  If you click on the blue arrow to the left of the <code>lbr_int</code> object in the top right data pane, the object will expand below to reveal the names of all variables.  The second variable is named <code>NAME_0</code> and provides us with the name we will use as our label, Liberia.  Following the <code>aes()</code> argument, you can also specify the <code>size =</code> of your label as well as its <code>color =</code>.</p>
<pre><code class="language-r">ggplot() +
  geom_sf(data = your_sf_obj,
          size = value,
          color = &quot;color&quot;,
          fill = &quot;color&quot;,
          alpha = value_between_0_&amp;_1) +
  geom_sf_text(data = your_sf_obj,
               aes(label = variable_name),
               size = value,
               color = &quot;color&quot;)
</code></pre>
<p><img src="images/liberia.png" alt="Liberia labelled" /></p>
<p>Good job!  You have successfully used ggplot from the tidyverse with the simple features package in order to properly project and plot Liberia's international border, as well as to include a label.  Now continue with the first level of administrative subdivisions, Liberia's fifteen counties.  In order to do this, return to your use of the <code>read_sf()</code> command in order to import and create an object named <code>lbr_adm1</code>.</p>
<pre><code class="language-r">lbr_adm1  &lt;- add_command_here(&quot;add_folder_here/add_file_name_here.shp&quot;)
</code></pre>
<p>As before you could use the data pane in the top right corner to expand your view of the <code>lbr_adm1</code> file you created.  You can also click on the small grid symbol to the right of your data object (within the data pane) in order to view your data in a new tab in the same pane where your script is located.  Whereas before we had a simple feature class object with 1 observation with 7 variables, your <code>lbr_adm1</code> simple feature object has 15 observations, with each observation having 8 different variables describing some attribute associated with each individual polygon.  Let's plot both Liberia's international border as well as its 15 counties.</p>
<p>To do this, follow the same approach you used with the <code>lbr_int</code> object but replace it with the name of your adm1 spatial object, <code>lbr_adm1</code>.  Also follow the same approach you used for adding the labels in your previous snippet of code, but this time specify the variable with the county names from <code>lbr_adm1</code>.</p>
<pre><code class="language-r">ggplot() +
  geom_sf(data = your_adm1_sf_obj,
          size = value,
          color = &quot;color&quot;,
          fill = &quot;color&quot;,
          alpha = value) +
  geom_sf(data = your_int_sf_obj,
          size = value,
          color = &quot;color&quot;,
          fill = &quot;color&quot;,
          alpha = value) +
  geom_sf_text(data = your_adm1_sf_obj,
               aes(label = variable_name),
               size = value,
               color = &quot;color&quot;) +
  geom_sf_label(data = your_int_sf_obj,
               aes(label = variable_name),
               size = value,
               color = &quot;color&quot;)
</code></pre>
<p>The code above will produce the plot below when the<code>geom_sf()</code> function using the <code>lbr_adm1</code> arguments is specified with a line weight <code>size = 0.65</code>, line weight <code>color = &quot;gray50&quot;</code>, a polygon <code>fill = &quot;gold3&quot;</code> and a 65% opacity value of <code>alpha = 0.65</code>.  Additionally, I have set the <code>size = 2.0</code> , and the <code>alpha = 0</code> (100% transparent) for the <code>data = lbr_int</code> object. The <code>geom_sf()</code> command will default to a <code>color = &quot;black&quot;</code> if the line color is not specified. Additionally, since the <code>alpha = 0</code> no <code>fill = &quot;color&quot;</code> is needed (since it will not appear). The county labels have a <code>size = 2</code> (and also defaults to a <code>color = &quot;black&quot;</code>, while the <code>geom_sf_text()</code> command to label Liberia has a <code>size = 12</code> argument. In order to nudge the label to the east and south I have also added the <code>nudge_x = 0.3</code> and <code>nudge_y = -.1</code> arguments to the <code>geom_sf_label()</code> command.</p>
<p><img src="images/liberia%20%282%29.png" alt="Liberia and its 15 Counties" /></p>
<p>After adding the counties go back and add the second level of administrative subdivisions, or districts.  Again use <code>read_sf()</code> to import that shapefile as a simple feature object into your RStudio workspace.  Use the  <code>geom_sf_text()</code> command to add the labels, while also making sure to specify the correct variable name in the <code>aes(label = variable_name)</code> argument.  Size the district borders and labels so they are smaller than the internation border as well as the county delineations.</p>
<pre><code class="language-r">rm(list=ls(all=TRUE))

# install.packages(&quot;tidyverse&quot;, dependencies = TRUE)
# install.packages(&quot;sf&quot;, dependencies = TRUE)

library(tidyverse)
library(sf)

setwd(&quot;~/Tresors/teaching/project_folder/data&quot;)

lbr_int  &lt;- add_command_here(&quot;add_folder_here/add_file_name_here.shp&quot;)
lbr_adm1  &lt;- add_command_here(&quot;add_folder_here/add_file_name_here.shp&quot;)
lbr_adm2  &lt;- add_command_here(&quot;add_folder_here/add_file_name_here.shp&quot;)

ggplot() +
  geom_sf(data = adm2_object,
          size = value,
          color = &quot;color&quot;,
          fill = &quot;color&quot;,
          alpha = value) +
  geom_sf(data = adm1_object,
          size = value,
          color = &quot;gray50&quot;,
          alpha = value) +
  geom_sf(data = int_object,
          size = value,
          alpha = value) +
  geom_sf_text(data = adm2_object,
               aes(label = variable_name),
               size = value) +
  geom_sf_text(data = adm1_object,
               aes(label = variable_name),
               size = value)

ggsave(&quot;liberia.png&quot;)
</code></pre>
<p>Use <code>ggsave(file_name.png)</code> to save your plot as a <code>.png</code> file, to your working directory.</p>
<p><img src="images/liberia%20%281%29.png" alt="Liberia, its counties and districts" /></p>
<h2><a class="header" href="#team-challenge-question" id="team-challenge-question">Team Challenge Question</a></h2>
<p>Follow the steps from above that you used to produce your plot of Liberia, but instead each team member should select their own LMIC country and produce the output for it.  Refer this <a href="https://datahelpdesk.worldbank.org/knowledgebase/articles/906519">World Bank</a> guide for a list of low, middle and high income economies.  Go back to the GADM website and find the administrative boundaries for the LMIC country you have selected.  Plot and label the international border, the first level of administrative subdivisions and the second level of administrative subdivisions.  Make sure you designate heavier line widths for the higher level administrative subdivisions and thinner line widths for the more local governments.  You may also use darker and lighter colors to discern hierarchy.  Please be sure to use different label sizes and/or colors to further differentiate administrative hierarchies.  Modifying annotation transparency also as needed.</p>
<p>Meet with your group and prepare to present the best two plots for the Friday informal group presentation.  Then as a group, upload all 5 team members plots to <a href="https://wmdsi.slack.com/archives/CTJDRU4VC">#data100_project1</a> (informal group presentations) by Sunday night.</p>
<h2><a class="header" href="#individual-stretch-goal-1" id="individual-stretch-goal-1">Individual Stretch Goal 1</a></h2>
<p>Go to the <a href="https://data.humdata.org">HDX</a> website, find and download the shapefiles for your selected country.  Compare their administrative subdivisions to those obtained from GADM.  Are they the same?  Are there any differences?  Which source do you think more closely describes the local political reality within your selected LMIC?  Do the HDX shapefiles work?</p>
<p>Alternatively, do the same using the <a href="https://www.geoboundaries.org">geoBoundaries</a> website, which is housed right here at William &amp; Mary!  When comparing GADM, HDX and geoBoundaries, be sure to identify the source of the data you are presenting.  Are these administrative boundaries primary or secondary sources?  Are you able to identify who produced the data?  How did each repository obtain the data they are sharing with you?</p>
<h2><a class="header" href="#individual-stretch-goal-2" id="individual-stretch-goal-2">Individual Stretch Goal 2</a></h2>
<p>Create a new <code>ggplot() +</code> as you did before.  This time <code>filter</code> your <code>lbr_adm1</code> object by using the <code>%&gt;%</code> (pipe) operator and using the assignment operator to create a new sf object that includes only the county named Montserrado.  Inside the <code>filter()</code> command you will need to specify the <code>admin1name = &quot;Montserrado&quot;.</code> Then continue to use the <code>%&gt;%</code> operator with your <code>lbr_adm2</code> object again filtering based on the <code>admin1Name == &quot;Montserrado&quot;</code> .  Follow that <code>%&gt;%</code> with your <code>ggplot()</code>, <code>geom_sf()</code> and <code>geom_sf_text()</code> commands to plot the geometries and labels for both the first and second level administrative subdivisions of Montserrado, Liberia.</p>
<pre><code class="language-r">new_sf_obj &lt;- lbr_adm1 %&gt;%
  filter(variable == &quot;outcome&quot;)
  
lbr_adm2 %&gt;%
  filter(variable == &quot;outcome&quot;) %&gt;%
  ggplot() +
  geom_sf(size = value) +
  geom_sf_text(aes(label = variable),
               size = value) +
  geom_sf(data = newly_created_sf_obj,
          size = value,
          alpha = value) +
  geom_sf_text(data = newly_created_sf_obj,
               aes(label = variable),
               size = value) +
  xlab(&quot;longitude&quot;) + ylab(&quot;latitude&quot;) +
  ggtitle(&quot;Montserrado County&quot;, subtitle = &quot;Liberia's most populous county and its subdivisions&quot;) +
  theme(plot.title = element_text(hjust = 0.5), 
        plot.subtitle = element_text(hjust = 0.5))

ggsave(&quot;montserrado.png&quot;)
</code></pre>
<p><img src="images/montserrado%20%282%29.png" alt="" /></p>
<p>Now identify the most populous urban area within your LMIC and use <code>ggplot() +</code> to plot the first and second level administrative subdivisions where it is located.</p>
<h2><a class="header" href="#individual-stretch-goal-3" id="individual-stretch-goal-3">Individual Stretch Goal 3</a></h2>
<p>Produce detailed maps of your more densely populated areas and include them in your final product.  Use the <code>geom_rect() +</code> command to identify the area of increased scale.  Also use the <code>annotation_custom() +</code> command to arrange each plot within a larger graphical layout. The following is a fully working example for Liberia.  Translate the script to your LMIC.  You may need to install and load the package <code>ggsflabel</code>.</p>
<pre><code class="language-r">### Create Larger Map of Liberia with Rectangles identifying area of Detailed Maps

plot1 &lt;- ggplot() +
  geom_sf(data = lbr_adm1,
          size = 0.5,
          color = &quot;gray50&quot;,
          fill = &quot;gold3&quot;,
          alpha = 0.5) +
  geom_sf(data = lbr_int,
          size = 2.0,
          alpha = 0) +
  geom_rect(data = lbr_adm1, xmin = -10.95, xmax = -10.3, ymin = 6.2, ymax = 6.9, 
            fill = NA, colour = &quot;green&quot;, size = 2) +
  geom_rect(data = lbr_adm1, xmin = -8.80, xmax = -7.35, ymin = 4.3, ymax = 5.65, 
            fill = NA, colour = &quot;blue&quot;, size = 2) +
  geom_sf_text(data = lbr_adm1,
               aes(label = admin1name),
               size = 3) +
  geom_sf_text(data = lbr_adm1,
               aes(x = -10.60, y = 6.05, label = &quot;Detail A&quot;),
               size = 5,
               color = &quot;green&quot;) +
  geom_sf_text(data = lbr_adm1,
               aes(x = -9.10, y = 4.6, label = &quot;Detail B&quot;),
               size = 5,
               color = &quot;blue&quot;) +
  xlab(&quot;longitude&quot;) + ylab(&quot;latitude&quot;) +
  ggtitle(&quot;Liberia&quot;, subtitle = &quot;Details A &amp; B&quot;) +
  theme(plot.title = element_text(hjust = 0.5), plot.subtitle = element_text(hjust = 0.5),
        panel.background = element_rect(fill = &quot;azure&quot;),
        panel.border = element_rect(fill = NA))

### Create Detail A Map

mont_cnty &lt;- lbr_adm1 %&gt;%
  filter(admin1name == &quot;Montserrado&quot;)

plot2 &lt;- lbr_adm2 %&gt;%
  filter(admin1Name == &quot;Montserrado&quot;) %&gt;%
  ggplot() +
  geom_sf(size = .15) +
  geom_sf_text(aes(label = admin2Name),
               size = 1.75) +
  geom_sf(data = mont_cnty,
          size = .5,
          alpha = 0) +
  geom_sf_text(data = mont_cnty,
               aes(label = admin1name),
               size = 3.75,
               alpha = .5) +
  xlab(&quot;longitude&quot;) + ylab(&quot;latitude&quot;) +
  ggtitle(&quot;Detail A&quot;, subtitle = &quot;Montserrado County&quot;) +
  theme(plot.title = element_text(hjust = 0.5), plot.subtitle = element_text(hjust = 0.5),
        panel.background = element_rect(fill = &quot;azure&quot;),
        panel.border = element_rect(fill = NA))


### Create Detail B Map

east_cnties &lt;- lbr_adm1 %&gt;%
  filter(admin1name == &quot;Grand Kru&quot; | admin1name == &quot;Maryland&quot; | admin1name == &quot;River Gee&quot;)

plot3 &lt;- lbr_adm2 %&gt;%
  filter(admin1Name == &quot;Grand Kru&quot; | admin1Name == &quot;Maryland&quot; | admin1Name == &quot;River Gee&quot;) %&gt;%
  ggplot() +
  geom_sf(size = .15) +
  
  geom_sf_text(aes(label = admin2Name),
               size = 1.75) +
  geom_sf(data = east_cnties,
          size = .5,
          alpha = 0) +
  geom_sf_text(data = east_cnties,
               aes(label = admin1name),
               size = 3.75,
               alpha = .5) +
  xlab(&quot;longitude&quot;) + ylab(&quot;latitude&quot;) +
  ggtitle(&quot;Detail B&quot;, subtitle = &quot;River Gee, Grand Kru &amp; Maryland Counties&quot;) +
  theme(plot.title = element_text(hjust = 0.5), plot.subtitle = element_text(hjust = 0.5),
        panel.background = element_rect(fill = &quot;azure&quot;),
        panel.border = element_rect(fill = NA))



ggplot() +
  coord_equal(xlim = c(0, 6.0), ylim = c(0, 4), expand = FALSE) +
  annotation_custom(ggplotGrob(plot1), xmin = 0.0, xmax = 4.0, ymin = 0, 
                    ymax = 4.0) +
  annotation_custom(ggplotGrob(plot3), xmin = 4.0, xmax = 6.0, ymin = 0, 
                    ymax = 2.0) +
  annotation_custom(ggplotGrob(plot2), xmin = 4.0, xmax = 6.0, ymin = 2.0, 
                    ymax = 4.0) +
  theme_void()

ggsave(&quot;details.png&quot;)
</code></pre>
<p><img src="images/details.png" alt="" /></p>
<h1><a class="header" href="#extracting-populations-from-a-raster-and-aggregating-to-each-unit" id="extracting-populations-from-a-raster-and-aggregating-to-each-unit">Extracting Populations from a Raster and Aggregating to each Unit</a></h1>
<p>Now that you have selected your LMIC and produced a basic geospatial description of that country at both the adm1 and adm2 levels of government, you are now set to join some data to each of those units and begin conducting a basic descriptive analysis.  Start by going back to the <a href="https://www.worldpop.org">WorldPop</a> website, click on the <strong>population</strong> tab under the <strong>data</strong> pull down menu, search individual countries and type the name of your selected LMIC.  Click on the 2019 data and resources tab for your country and then select the download button in order to obtain the spatial distribution of population for your selected LMIC.  For Liberia the downloaded file is named <strong>lbr_ppp_2019.tif</strong>.  Move the file to the data folder within your working directory.</p>
<p><img src="images/screen-shot-2020-02-09-at-6.55.31-pm.png" alt="" /></p>
<p>You may need to right click or two finger click and choose the <strong>download linked file</strong> option in order to initiate the process of downloading the <code>.tif</code> file into your downloads folder.  Sometimes your web browser may be set to try and display the image file directly within the browser itself.  You should still be able to save the file directly to your downloads folder by right clicking on it and saving it.</p>
<p>After you have succesfully downloaded the file, go to your project folder that you previously used as your working directory and create a new folder within the <code>/data</code> folder that will be dedicated to raw data from worldpop.  I have made a subdirectory within my <code>data</code> folder named <code>world_pop</code> to further categorize and organize my source data.</p>
<p><img src="images/screen-shot-2020-02-09-at-6.59.34-pm.png" alt="" /></p>
<p>Once you have your <code>.tif</code> file located within a subdirectory of the data folder, you can go ahead and open up RStudio.  Create a new, R Script file, and save it in your scripts folder.  Add the <code>rm(list=ls(all=TRUE))</code> at the beginning of your code and then load the <code>tidyverse</code> and <code>sf</code> libraries.  Following your libraries, be sure to set your working directory.</p>
<pre><code class="language-r">rm(list=ls(all=TRUE))

# install.packages(&quot;tidyverse&quot;, dependencies = TRUE)
# install.packages(&quot;sf&quot;, dependencies = TRUE)

library(tidyverse)
library(sf)

setwd(&quot;~/path/to_my/working/directory/&quot;)
</code></pre>
<p>For this exercise, we will install a new package and then load its library of functions.  Use the <code>install.packages()</code> to install the <code>raster::</code> package.  Be sure to set the <code>dependencies = TRUE</code> argument within your command.  After you have successfully installed the <code>raster::</code> package, use the <code>library()</code> function to load <code>raster::</code> and make its set of commands available as part of your current RStudio work session.</p>
<p>The first command we will use from the <code>raster::</code> package shares the same name as the library itself.  We use the <code>raster()</code> function to import our <code>.tif</code> file from its location within our data subdirectory to the current RStudio work session.  Keep in mind, if you set your working directory to the <code>/data</code> folder, but then also created a subfolder named <code>/world_pop</code> you will need to include the subdirectory path, as well as the full name of the <code>.tif</code> within the <code>raster()</code> command.</p>
<pre><code class="language-r">myLMIC_raster_pop19 &lt;- add_command_here(&quot;add_folder_name_here/add_file_name_here.tif&quot;)
</code></pre>
<p>Once you have created your new raster object, by using the <code>raster()</code> function, you should notice a new <em>Formal class RasterLayer</em> data object appear in the top right data pane.  In order to find out some basic information about my newly created raster object, I will type the name of my object directly into the console.</p>
<p><img src="images/screen-shot-2019-09-15-at-5.00.12-pm.png" alt="Basic Description of a Raster Layer" /></p>
<p>The name of my raster class object is <code>lbr_pop19</code> and by typing the objects name directly into the console, R informs me of the class of the object, dimensions, resolution, extent, coordinate reference system as well as the minimum and maximum values.  The information about the objects dimensions can be useful, since it is informing us of how many rows of gridcells by how many columns of gridcells are contained within the object.  In the case of the WorldPop raster layer describing Liberia's population in 2019, the object contains 24,922,800 gridcells of equal size, each one with a value describing how many people live in that location.  Resolution informs us of the size of each grid cell, which in this case is defined in terms of decimal degress.  We can also, obtain additional information about the projection of the raster layer from the crs row, which is in longitude and latitude (decimal degrees) while using the WGS84 datum.  We will want to confirm that our shapefiles also are using the WGS84 datum in their projection.</p>
<p>You'll want to note the number of gridcells that your raster layer contains.  If your country contains too many gridcells the computational expense required to execute calculations may be too time intensive.  As noted above, Liberia has about 25 million gridcells, while quite large, most modern desktop and laptop computers should be able to handle this data within a reasonable amount of time.  Comparatively, Ghana has about 41 million, Syria has about 48 million while Cuba has about 53 million total gridcells.  While a bit larger in size than Liberia as well as the computational power that will be demanded in order to execute calculations over those raster files, countries of this approximate size (40 to 50 million gridcells) should also be manageable.  Raster files containing more than 50 million gridcells will begin to become exorbitantly more time intensive.  For example, South Sudan with 140 million, Madagascar with 143 million, Morocco with 144 million, or Vietnam with 156 million gridcells per raster will all likely be computationally very expensive in terms of the time it will take to execute commands using the raster files.</p>
<p>If your country has a very large number of gridcells within the population raster, there are two recommendations for how to proceed.  First you are welcome to reselect your LMIC by choosing one that is smaller in terms of area and number of gridcells.  Second, you are also welcome to select a subdivision of your LMIC and then subset your country to include only that administrative area.  A good example of how to subset your LMIC to include one or more of its subdivisions was provided in project 1, part 1, <a href="https://tyzao.gitbook.io/geodatasci/descript_pop/intro_spatdata#individual-stretch-goal-2">individual stretch goal 2</a> (lines 1 &amp; 2 of the code).  If you want to subset a larger country and raster, please ask me, and I'll share some example code with you.</p>
<p>As we  did in the previous exercise, we will again import our shapefiles using the <code>read_sf()</code> command from the <code>sf::</code> library of functions.  Let's start out by importing the adm1 shapefile for your selected LMIC.</p>
<pre><code class="language-r">myLMIC_sf_adm1  &lt;- add_command_here(&quot;add_folder_here/add_file_name_here.shp&quot;)
</code></pre>
<p>In a manner similar to how we retrieved a basic description of our raster file, we can simply type the name of our simple features class object into the console.</p>
<p><img src="images/screen-shot-2019-09-15-at-5.36.44-pm.png" alt="Description of a sf class object from within an R work session" /></p>
<p>R informs us that our simple feature collection has 15 features, each one with 7 fields (or variables).  R also provides us with the bounding box for our collection of polygons in terms of the minimum and maximum longitude and latitude values.  Additionally, we are able to confirm that the source shapefile used to important our sf object also used the WGS84 datum for projection.</p>
<p>You also may notice that below the proj4string row, R describes the object as a tibble: 15 x 8.  A <strong>tibble</strong> is a new object class for data that is commonly used with the tidyverse syntax.  <strong>Tidyverse</strong> syntax is sometimes referred to as <strong>tidyR</strong> and is different from the baseR syntax.  While tidyR is fully capable of calling variables from data frames using either the <code>$</code> operator or the <code>[ ]</code> subscripting operators, it is a more advanced design in its approach to data that can include multiple dimensions, and thus <code>%&gt;%</code> pipe operators can be very effective.  For now, all you need to know is that a <strong>tibble</strong> is a kind of data object, and <strong>tidyR</strong> is a new kind of data science syntax for R.</p>
<p>Since both our <code>raster</code> and <code>sf</code> objects are similarly projected, we should be able to plot both and confirm they have the same bounaries.  Start by plotting the <code>raster</code> object.  Follow that on the next line, by also plotting your <code>sf</code> object.  You will want to nest the name of your <code>sf</code> object within the <code>st_geometry()</code> command in order to plot just the geometry for all 15 polygon features.  Finally, also include the <code>add = TRUE</code> argument to the command, in order to add the ploygon features to the already plotted raster layer.</p>
<pre><code class="language-r">plot(your_raster_object)
plot(st_geometry(your_adm1_sf_obj), add = TRUE)
</code></pre>
<p><img src="images/rplot%20%287%29.png" alt="Raster Layer of Liberia's Population with ADM1 subdivisions overlayed" /></p>
<p>We can see that we now have a scale on the right hand side of the plot that is using a color scale to coorespond with all continuous values between a minimum and maximum (from about 0 to a little more than 112).  We can also begin to identify the locations throughout Liberia where people have settled.  Clearly there is a large clump of green and yellow gridcells located along the southern coast (this is the location of Liberia's capital city Monrovia).  As we move away from the centrally populated coastal urban area, inland to the north-east we also notice some less densely populated areas along the outskirts of Monrovia, which have pinkish colored gridcells.  There are also a few, less populated urban areas further to the south as well as along the northern border with Guinea.  In fact, if we looked at all 24,922,800 gridcells that indivually comprise this map, each one would have a value and cooresponding color that indicates its population.</p>
<p>We can confirm that our <code>raster</code> and <code>sf</code> objects have almost coterminous boundaries (not exactly, but fairly close).  Now we will use a function from the <code>raster::</code> package that will evaluate each gridcell according to its location, which will be one of the 15 counties.  Since we have 24,922,800 gridcells to evaluate in accordance with one of 15 different locations, we can imagine this could very well be a computationally expensive task.  Before executing your extract command, it is a good idea to close all applications and processes that you may have running on your desktop or laptop.  It is also a good idea to connect your computer to a power supply cable that is plugged into a 110V wall jack.  Restarting your computer from a cold boot and confirming that no superfluous processes automatically begin during start-up, will also help to maximize your potential computational power for RStudio. </p>
<p>In order to optimize the efficiency of your computer, we are also going to do something called <em>parallel processing</em> by sending streams of data to available cores found in the central processing unit of your computer.  To do this, we will need to add two new packages in your script.  Go back to the top of your script and add a line of code beneath the other lines where you executed the <code>install.packages()</code> command.  This time, install two new packages, <code>doParallel::</code> and <code>snow::</code>.  Add the <code>dependencies = TRUE</code> argument to inform RStudio to include any other packages that <code>doParallel::</code>and <code>snow::</code> may depend upon in order to properly function.  After you have sucessfully installed both packages (always observe their installation and watch to see if any errors pop up), then use the <code>library()</code> command in order to load each packages' associated library of functions.  Don't forget to comment off the <code>install.packages()</code> lines of code after they have finished.</p>
<p>Once you have successfully made both of these new packages available, move back to after the last lines of code you wrote, where you plotted your <code>raster</code> layer with the <code>sf</code> layer on top.  First, check to see how many cores are available on your computer.  To do this use, enter the <code>detectCores()</code> command directly into the console.  When running parallel processes on your computer, you should always save at least one core for system operations, thus we will create an object that is equal to the number of cores on your computer - 1.</p>
<p>In the next steps that follow, <strong>do not</strong> execute any of the following four lines of code until you have first properly specified them in your script (I'll indicate when to run them further below).  Start by creating an object that designates the number of cores you will use once you begun parallel processing.  Follow the creation of your <code>ncores</code> object with the <code>beginCluster()</code> command, which will inform RStudio to start parallel processing.</p>
<pre><code class="language-r">ncores &lt;- detectCores() - 1
beginCluster(ncores)
</code></pre>
<p>Once parallel processing has been engaged, we will add the command from the <code>raster::</code> package that will evaluate all of the gridcells and assign a number to each one that cooresponds to its location as being within one of the 15 counties.  This command is called <code>extract()</code>.  The <code>extract()</code> command will need two objects, the first will be our raster layer object while the second will be our simple features class object.  In addition to adding the <code>extract()</code> command itself to the script, I will also further specify the <code>raster::</code> library in the command to make certain, RStudio doesn't attempt to execute a different <code>extract()</code> command from another library.  Do not run this command yet, just write it in your script after <code>beginCluster()</code>.</p>
<pre><code class="language-r">pop_vals_adm1 &lt;- raster::extract(your_raster_obj, your_sf_obj, df = TRUE)
</code></pre>
<p>Also add the <code>df = TRUE</code> argument at the end of the command to create the new object as a data frame.  Following the <code>extract()</code> command, add the <code>endCluster()</code> command, to inform RStudio that you will no longer need to use additional cores for parallel processing.  This snippet of code should appear as follows.  Select all four lines and run them at the same time.</p>
<pre><code class="language-r">ncores &lt;- detectCores() - 1
beginCluster(ncores)
pop_vals_adm1 &lt;- raster::extract(lbr_pop19, lbr_adm1, df = TRUE)
endCluster()
</code></pre>
<p>Depending on your computer, the size of the <code>raster</code> file as well as the size of your <code>sf</code> file, running the above 4 lines of code could take a few minutes.  You will want to be patient and wait for the <code>extract()</code> command to complete its evaluation of every grid cell.  If you would like to monitor the progress of your comptuer you could go to the activity monitor on a Mac or the task manager on a Windows machine.</p>
<p><img src="images/screen-shot-2019-09-15-at-8.07.45-pm%20%281%29.png" alt="" /></p>
<p>For example on this particular Mac, you will see that 7 processes have been allocated to R in order to evaluate the location of all ~25 million gridcells.  You will also notice the CPU load has increased considerable, to almost 90% in the above case.  With 7 i7 cores, it took about 1 minute and 10 seconds to extract the values of all 4 million persons distributed across the 25 million gridcells throughout Liberia.  Your case could be faster or slower depending on the size of the data, the speed of your machine, and how much computational power you have reserved for the given task.</p>
<p>After your <code>raster::extract()</code> has finished, you should have a new data frame object in your top right data pane that is populated with probably hundreds of thousands if not millions of rows (observations), and two columns (variables).  Each row will have a number between 1 and 15 in the above case (each number cooresonding to each of Liberia's counties) and then a following column that provides the WorldPop estimate for how many people occupy each individual gridcell.  You may notice that all of the observational values have fractions and even quite a large number are likely to be a fraction less than 1.  While not an ideal outcome, these fractions are a result of the current methodology and essentially is still state of the art for dasymmetric population distribution.  In the future, I expect new methodologies will discretize intervals and over come this &quot;zero cell problem&quot; by some means other than adding these small values across the entire space that essentially amount to &quot;noise.&quot;</p>
<p>Since this newly created data frame is quite large, and it would be better if you didn't have to run the <code>extract()</code> command everytime you opened and ran this script, it is a good idea to go ahead and save the data frame as a <code>.RData</code> file.  You can save data using the <code>save()</code> command, and then you can also later load data using the <code>load()</code> command.  Once you have executed the <code>save()</code> command, you can then comment it off, thus only needing to <code>load()</code> the data.</p>
<pre><code class="language-r"># ncores &lt;- detectCores() - 1
# beginCluster(ncores)
# pop_vals_adm1 &lt;- raster::extract(lbr_pop19, lbr_adm1, df = TRUE)
# endCluster()
# save(pop_vals_adm1, file = &quot;pop_vals_adm1.RData&quot;)

load(&quot;pop_vals_adm1.RData&quot;)
</code></pre>
<p>We have assigned a cooresponding ID for each gridcell according to its county, and now we will sum the totals all gridcells by ID.  Start with the data frame that you created with your <code>extract()</code> command.  For my Liberia example, I have called the data frame object <code>pop_vals_adm1</code>.  Follolw your object with the <code>%&gt;%</code> pipe operator.  You will use the <code>group_by()</code> command in order to group all of the observations within our data frame according to its <code>ID</code>.  Follow the <code>group_by()</code> command again with another <code>%&gt;%</code> pipe operator.  Now specify that you will group each row according to its <code>ID</code> and also summarize all of the rows with the same <code>ID</code> according to the <code>lbr_ppp_2019</code> variable, which contains the estimate of how many persons live within each gridcell.  Finally, be sure to add the <code>na.rm = TRUE</code> argument to your command, which will remove from the calculation all grid cells that do not have a value (generally designated in R as NA).</p>
<pre><code class="language-r">totals_adm1 &lt;- pop_vals_adm1 %&gt;%
  group_by(add_ID_variable_here) %&gt;%
  summarize(name_of_newly_created_var = sum(add_pop_var_here, na.rm = TRUE))
</code></pre>
<p>Grouping the data frame we produced with the <code>extract()</code> function, by <code>ID</code> while also summing together all gridcell values that share that same <code>ID</code> will produce the following estimated population totals for every county in Liberia.</p>
<p><img src="images/screen-shot-2019-09-15-at-8.49.48-pm.png" alt="" /></p>
<p>Review the sum totals to see if they are realistic.  Execute the equivalent of  <code>sum(totals_adm1$pop19)</code> directly in the console, and consider the total returned.  In the above example, R returns a total of 4,288,144 total persons living in 15 different counties across Liberia during the year 2019.  What does R return for your LMIC?  Is the sum total realistic?  Research the population of your LMIC in 2019 and confirm your returned value is realistic.</p>
<p>Now that we have the total population for each county, we need to add it to our <code>sf</code> class object so that we can spatially describe the population of our LMIC.  You can do this with the <code>%&gt;%</code> pipe operator and the <code>add_column()</code> command.  In the argument of the <code>add_column()</code> command first specify the name of the column you will be creating in your <code>sf</code> adm1 object and then set that <code>=</code> to the name of the data frame and variable where those population totals exist.  In our example case <code>pop19 = totals_adm1$pop19</code>.  Also notice how I simply write over my existing <code>sf</code> object by assigning the newly created object the exact same name <code>lbr_adm1 &lt;- lbr_adm1 %&gt;%</code>. </p>
<pre><code class="language-r">myLMIC_adm1 &lt;- myLMIC_adm1 %&gt;%
  add_column(pop19 = totals_adm1$name_of_newly_created_var)
</code></pre>
<p>After running the above code, look in the data pane in the top right corner of RStudio and find your modified adm1 simple features object.  Click on the small grid off to the right of the object to view the data in the top left pane (scripts pane).  Scroll all the way to the right in the data, and you should notice a new column named <code>pop19</code> that has the population counts for every adm1 subdivision in your country.</p>
<p>Now that we have totals for each county, it is finally time to plot our results.  Since we are only going to call one object in the first example, we can start our <code>ggplot()</code> command by automatically specifying the object we will be using in our plot.  Within the <code>geom_sf()</code> command, use the <code>aes(fill = )</code> argument to identify the variable that will be used to spatially describe the continuous values of population totals for each of Liberia's counties.  Also add the <code>scale_fill_gradient()</code> command with the <code>low =</code>  and <code>high =</code>  arguments to desginate a color that will coorespond to the low and high ends of the value range.  A heatmap typically sets the color yellow to coorespond with the minimum value and red as the maximum value.</p>
<pre><code class="language-r">ggplot(myLMIC_adm1) +
  geom_sf(aes(fill = pop19)) +
  geom_sf_text(aes(label = admin1name),
               color = &quot;color&quot;,
               size = size) +
  scale_fill_gradient(low = &quot;color&quot;, high = &quot;color&quot;)
  
  ggsave(&quot;lbr_pop19.png&quot;)
</code></pre>
<p><img src="images/lbr_pop19.png" alt="Population of Liberia's Counties in 2019" /></p>
<h2><a class="header" href="#team-challenge-question-1" id="team-challenge-question-1">Team Challenge Question</a></h2>
<p>Follow the steps from above that you used to produce your plot of Liberia, but instead each team member should use their own selected LMIC country.  Go back to the HDX website and find the population totals for the LMIC country you have selected.</p>
<p>Meet with your group and prepare to present the two best plots for the Friday informal group presentation.  Then as a group, upload all 5 team members plots to #data100_igps (informal group presentations) by Sunday night.</p>
<h2><a class="header" href="#individual-stretch-goal-1-1" id="individual-stretch-goal-1-1">Individual Stretch Goal 1</a></h2>
<p>Go back and replicate the step by step instructions from above, but instead of extracting and plotting the values for your LMIC's adm1 subdivisions, do it for adm2.  Set the <code>fill =</code>  argument by making it equal to the log transformation of your population variable <code>log(variable_name)</code>.</p>
<p><img src="images/lbrdist_logpop19.png" alt="Liberia's District's described in terms of Log of Population" /></p>
<h2><a class="header" href="#individual-stretch-goal-2-1" id="individual-stretch-goal-2-1">Individual Stretch Goal 2</a></h2>
<p>Take your spatial description of population at the district level from above and add the adm1 boundaries, such that you can determine where each district is located.  Be sure to add the <code>data =</code>  argument where you specify both your adm1 and adm2 <code>sf</code> class object for  each <code>geom_sf()</code> function within the <code>ggplot()</code> object you are creating.  Set the <code>size =</code>  argument for the adm1 object as much smaller than the lines width for the adm2 (in my plot below they are <code>.1</code> and <code>.65</code> respectively.  Also be sure to set the <code>alpha = 0</code> for the adm1 object, in order to be able to see the districts.</p>
<p>Again, include the <code>data =</code>  argument when using the <code>geom_sf_text()</code> command in order to add the labels for both the districts and counties.  District labels can be relatively small, perhaps <code>size = 1.0</code> while they should be considerable larger for the county labels, possibly along the order of <code>size = 2.5</code>. In your <code>geom_sf_text()</code> argument for the county lables, set the <code>alpha = .35</code>, such that the labels are transparent enough to interpret whats beneath them, while still discenable enough to read.</p>
<p>Change your <code>scale_fill_gradient()</code> command to <code>scale_fill_gradient2()</code> in order to add a third color and midpoint to the colors mapped to each contiuous value.  Look at the value from the previous scale.  What is the midpoint?</p>
<pre><code class="language-r">scale_fill_gradient2(low = &quot;blue&quot;, mid=&quot;yellow&quot;, high=&quot;red&quot;, midpoint = add_value_here)
</code></pre>
<p>Add other descriptive elements to your plot, such as labels for axes, title and panel background.</p>
<p><img src="images/lbrdist_logpop19b.png" alt="" /></p>
<h2><a class="header" href="#individual-stretch-goal-3-1" id="individual-stretch-goal-3-1">Individual Stretch Goal 3</a></h2>
<p>Install the package <code>rayshader::</code> from Tyler Morgan Wall's github repository.</p>
<pre><code class="language-r">remotes::install_github(&quot;tylermorganwall/rayshader&quot;, dependencies = TRUE)
</code></pre>
<p>Once it has been installed (it might take a few minutes), use the <code>library(rayshader)</code> command to load the library of functions.  Create a simple ggplot() of adm2 values without any annotations or other descriptive details.  Keep either the <code>scale_fill_gradient()</code> or <code>scale_fill_gradient2()</code> . Notice how assign my <code>ggplot()</code> object to a new object named <code>gglbr_adm2</code>.  I used the following code for Liberia.</p>
<pre><code class="language-r">gglbr_adm2 &lt;- ggplot(lbr_adm2) +
  geom_sf(aes(fill = log(pop19))) +
  scale_fill_gradient2(low = &quot;blue&quot;, mid=&quot;yellow&quot;, high=&quot;red&quot;, midpoint = 11.0)
</code></pre>
<p>Finally, create a three dimension plot of all log of density population values by district.  Notice the name of the <code>ggplot</code> object I created above is the same object used in the <code>plot_gg()</code> command from the <code>rayshader::</code> package.</p>
<pre><code class="language-text">plot_gg(gglbr_adm2, multicore = TRUE, width = 6 ,height=2.7, fov = 70)
</code></pre>
<p><img src="images/pop%20%281%29.gif" alt="" /></p>
<h1><a class="header" href="#creating-a-geometric-bar-plot-with-your-simple-feature-object" id="creating-a-geometric-bar-plot-with-your-simple-feature-object">Creating a Geometric Bar Plot with your Simple Feature object</a></h1>
<p>In the previous exercise, you extracted population data from a raster, and then aggregated these totals to the first level administrative area of your selected LMIC.  You then added this new column describing the population of each first level administrative subdivision to your simple feature object.  Now we are going to use that newly created column as the basis for generating a geometric bar plot of population, share of population and density by first level adminsitrative subdivision.</p>
<p>Rerun the code you used to create your adm1 <code>sf</code> class object in R, including the newly added population column.  Click on the <code>View()</code> grid symbol to the right of the data object in the top right, RStudio pane under the environment tab.  When the data viewer appears in the top left pane (beside your script tab), it should look something like the following.</p>
<p><img src="images/screen-shot-2019-09-22-at-9.19.22-pm.png" alt="Viewer displaying the attributes of an sf object" /></p>
<p>Confirm that your <code>sf</code> object has the name of each first level administrative subdivision as well as the population data you calculated and introduced.  Then use the <code>save()</code> command to save your <code>sf</code> object to your working directory.</p>
<pre><code class="language-r">save(your_adm1_obj, file = &quot;name_of_the_file_you_save.RData&quot;)
</code></pre>
<p>Once you have run the <code>save()</code> command you should be able to find your newly created <code>.RData</code> file in your working directory.  Please keep in mind that this <code>.RData</code> file will be different from the one you previously saved that contained the results from your <code>extract()</code> , therefor be certain to name it differntly, or else you may write over your previous saved <code>.RData</code> file, and effectively erasing it.  Save the <code>.RData</code> file containing your  <code>sf</code> class object.  Create and name a new script in RStudio, while saving it to your working directory.</p>
<p>As you have done with your prior scripts, start with the <code>rm()</code> command to clean the workspace, followed with <code>install.packages()</code> which are normally all commented off with the <code>#</code> at the beginning of each line and then the <code>library()</code> command, in order to load your needed libraries of commands.</p>
<pre><code class="language-r">rm(list=ls(all=TRUE))

# install.packages(&quot;tidyverse&quot;, dependencies = TRUE)
# install.packages(&quot;sf&quot;, dependencies = TRUE)

library(tidyverse)
library(sf)
 
setwd(&quot;~/your/working/directory/for_data&quot;)
</code></pre>
<p>Open the <code>tidyverse::</code> and <code>sf::</code> libraries and set your working directory.  Use the <code>load()</code> command to import the <code>sf</code> object contained within your  <code>.RData</code> file into your workspace.</p>
<pre><code class="language-r">load(&quot;name_of_the_file_you_saved.RData&quot;)
</code></pre>
<p>After you have executed the above command, you should notice your adm1 <code>sf</code> object reappear in the top right pane under the environment tab.  Confirm the newly created <code>pop19</code> variable is present in your <code>sf</code> class object by using the <code>View()</code> command or data viewer.</p>
<p>Add two new columns to your adm1 object.  First will be a column that provides us with the area of each first level administrative subdivision unit in square kilometers, while the second column will describe density of your LMIC.  In order to add these two columns, we will use the <code>%&gt;%</code> operator followed by the <code>mutate()</code> function.  The <code>mutate()</code> command is part of the tidyverse syntax and is used to create a new variable which is calculated from data found in another variable.  As part of the argument within the <code>mutate()</code> command, you will give the new column that you are creating a name.</p>
<p>Start with the name of your adm1 object followed by the pipe operator, which you will assign to the same named adm1 object, thus writing over and replacing it with the newly incorporated and created columns. The first newly created column will be named <code>area</code>.  In order to calculate this newly created column, we will also use a new command from the <code>sf</code> library of functions called <code>st_area()</code>.</p>
<pre><code class="language-r">yourLMIC_adm1 &lt;- yourLMIC_adm1 %&gt;%
  mutate(area = sf::new_command_here(yourLMIC_adm1))
</code></pre>
<p>After you execute this command, view the data associated with yout adm1 object and confirm that you have a new column named <code>area</code>. </p>
<p><img src="images/screen-shot-2019-09-22-at-10.15.28-pm.png" alt="The last two columns of your adm1 object" /></p>
<p>While these area calculations are accurate, to describe a country in square meters is probably not the most useful unit to select.  Instead of meters squared, we will convert our unit of measurement to square kilometers.  In order to do this, we must first install a new library of functions for use in RStudio.  Install the <code>units::</code> package and use the <code>library()</code> command in order to make it available for use.</p>
<p>The command we need from the <code>units::</code> package is <code>set_units()</code>, although this time we will nest our command within a <code>%&gt;%</code> to modify the units of measurement from <code>m^2</code> to <code>km^2</code>.  Notice how the last parenthesis doesn't coorespond with the new command from the <code>units::</code> library but rather with the parenthesis from the prior line.  We specify our syntax in this manner since we are applying the <code>set_units()</code> command to the results which have been <em>piped</em>  from the <code>st_area()</code> command.</p>
<pre><code class="language-r">yourLMIC_adm1 &lt;- yourLMIC_adm1 %&gt;%
  mutate(area = sf::new_command_here(yourLMIC_adm1) %&gt;% 
           units::new_command_here(new_units))
</code></pre>
<p>The second step in creating our two new columns is to use the <code>area</code> variable <em>on the fly</em> to calculate a column named <code>density</code> .  This second new column will be the result of our <code>area</code> column divided by the <code>pop19</code> variable (which we created in the last exercise).</p>
<pre><code class="language-r">yourLMIC_adm1 &lt;- yourLMIC_adm1 %&gt;%
  mutate(area = sf::new_command_here(yourLMIC_adm1) %&gt;% 
           units::new_command_here(new_units)) %&gt;%
  mutate(density = numerator_variable / denominator_variable)
</code></pre>
<p>Since we have modfied the units, you should notice both the variables <code>area</code> and <code>density</code> being described in units of persons per square kilometer.</p>
<p><img src="images/screen-shot-2019-09-22-at-10.39.17-pm.png" alt="Three newly created spatial, descriptive statistical variables" /></p>
<p>That is all the data we need for now.  Start the creation of your geometric bar plot by first piping <code>%&gt;%</code>  your adm1 object to a newly specified <code>ggplot</code> object.  Add the aesthetics to your <code>ggplot</code> object using the <code>ggplot()</code> command and specifying the  <code>x</code> and <code>y</code> variables from your <code>sf</code> class object.  These <code>x</code> and <code>y</code> objects will be used to plot the values using the <code>x</code> and <code>y</code> axes (although we will flip the horizontal to the verticle and <em>vice-versa</em> in a moment).</p>
<p>Since we are generating a bar plot, we will use the <code>geom_bar() +</code> command.  Include the <code>stat = &quot;identity&quot;</code> argument to plot the values of individual units of observation, in this case the population of each first level administrative subdivision from your LMIC.  Also add a <code>color =</code>  argument to your <code>geom_bar()</code> command and set the width of each bar.  Following the <code>geom_bar()</code> command, use the <code>coord_flip()</code> to flip the county names along the xaxis and give them a verticle disposition.</p>
<pre><code class="language-r">yourLMIC_adm1 %&gt;%
  ggplot(aes(x=your_adm1_names, y=pop19)) +
  geom_bar(stat=&quot;identity&quot;, color=&quot;color&quot;, width=value) +
  coord_flip() +
  xlab(&quot;label&quot;) + ylab(&quot;label&quot;)
</code></pre>
<p><img src="images/rplot03%20%281%29.png" alt="" /></p>
<p>Let's order our counties in accordance with population size from largest to smallest in order to more easily associate the descriptive statistics presented in our bar plot with the spatial descriptive statistics we previosuly created with our map.  Add a second <code>%&gt;%</code> after your adm1 object, where you will reorder the adm1 names based on the variable <code>pop19</code>.  Use the <code>mutate()</code> command again to write over the existing variable for adm1 names.  The key command you are adding within the <code>mutate()</code> argument is <code>fct_reorder()</code> which will change the order of the first named variable (in this case <code>admin1name</code>) based on the descending rank order of the second variable (<code>pop19</code>).  While I am using the raw population counts to change the county order listed along the verticle axis, you could use also the <code>area</code> or <code>density</code> variables.</p>
<pre><code class="language-r">yourLMIC_adm1 %&gt;%
  mutate(admin1name = fct_reorder(admin1name, pop19)) %&gt;%
  ggplot(aes(x=your_adm1_names, y=pop19)) +
  geom_bar(stat=&quot;identity&quot;, color=&quot;color&quot;, width=value) +
  coord_flip() +
  xlab(&quot;label&quot;) + ylab(&quot;label&quot;)
</code></pre>
<p>In addition to changing the order of the adm1 names, also add an annotation to each bar that indicates the share of the total population located within that subdivision.  Use the <code>geom_text()</code> command to add labels to your bar plot and set the <code>label =</code>  argument within the <code>aes()</code> parameter in order to calculate each administrative units share of the total population.  Divide the <code>sum()</code> of <code>pop19</code> variable in the denominator by the raw <code>pop19</code>  counts as the numerator.  Place the division of these values within the <code>percentage()</code> command from the <code>scales::</code> library (you'll need to install this new package).</p>
<p>Place the value that describes each administrative unit's share of the total population within the center of each bar using the <code>position =</code> .  Set it using the <code>position_stack(vjust = 0.5)</code> command with a verticle adjust to the center of the bar (half the total width).  Also, decrease the size of the text annotations.</p>
<pre><code class="language-r">  geom_text(aes(label=percent(pop19/sum(pop19))),
            position = position_stack(vjust = 0.5),
            size=2.0)
</code></pre>
<p><img src="images/rplot01%20%285%29.png" alt="" /></p>
<p>The last step of creating our geometric bar plot is to add a <code>fill =</code>  argument to the <code>ggplot(aes())</code> command that will be used to map a color to each counties population total, based on its place along the continuous scale from maximum to minimum.  As we did with our spatial description of population, also add the <code>scale_fill_gradient()</code> command to define colors that will coorespond to the <code>low =</code> and <code>high =</code>  values.  Use your assignment operator to create a new ggplot object that will be plotted with spatial description of your LMIC.</p>
<pre><code class="language-r">yourLMIC_bplt &lt;- yourLMIC_adm1 %&gt;%
  mutate(admin1name = fct_reorder(admin1name, pop19)) %&gt;%
  ggplot(aes(x=admin1name, y=pop19, fill = pop19)) +
  geom_bar(stat=&quot;identity&quot;, color=&quot;color&quot;, width=value) +
  coord_flip() +
  xlab(&quot;label&quot;) + ylab(&quot;label&quot;) +
  geom_text(aes(label=percent(pop19/sum(pop19))), 
            position = position_stack(vjust = 0.5),
            color=&quot;black&quot;, size=2.0) +
  scale_fill_gradient(low = &quot;yellow&quot;, high = &quot;red&quot;)
</code></pre>
<p><img src="images/rplot02%20%281%29.png" alt="" /></p>
<p>Return to the spatial plot that you created in the last exercise.  Copy the snippet of code that you used with the <code>geom_sf(aes(fill = pop19))</code> command in order to plot the population of every first level administrative subdivision along a contiuous scale for your LMIC.  Paste this snippet into your new script.  Add a new line to the snippet where you use the <code>geom_sf_text()</code> command to set plot the density of each individual adm1 object beneath its name.  Use the <code>aes(label=command(variable,2)</code> argument to add the <code>density</code> values.  Also, use the <code>round()</code> command, so the values from this variable are limited to two decimal points.  Nudge the density values, so they appear benath each label, while also modifying their size and color.</p>
<pre><code class="language-r">  geom_sf_text(aes(label=round(add_variable_here, 2)),
            color=&quot;color&quot;, size=add_size, nudge_y = add_value) +
</code></pre>
<p><img src="images/rplot05%20%281%29.png" alt="" /></p>
<p>Finally, install the package <code>ggpubr</code> and use the command <code>ggarrange()</code> to arrange your two plots together side by side.</p>
<pre><code class="language-r">liberia &lt;- ggarrange(your_spatial_plot, your_bar_plot, nrow = 1, widths = c(2.25,2))
</code></pre>
<p>Use the <code>ggtitle()</code> command to title each plot, and then also use the <code>annotate_figure()</code> command to set a common title for the combination of the two descriptive results. </p>
<pre><code class="language-r">annotate_figure(liberia, top = text_grob(&quot;Liberia&quot;, color = &quot;black&quot;, face = &quot;bold&quot;, size = 26))
</code></pre>
<p>To save your two plots together, use the <code>ggsave()</code> command.  Modify the <code>width =</code> and the <code>height =</code> commands to set the dimensions for your combined spatial and bar plot.  Use the <code>dpi =</code>  command to set the number of dots per inch, or effectively increase the resolution.</p>
<pre><code class="language-r">ggsave(&quot;liberia.png&quot;, width = 20, height = 10, dpi = 200)
</code></pre>
<p><img src="images/liberia%20%284%29.png" alt="" /></p>
<h2><a class="header" href="#project-1-individual-deliverable" id="project-1-individual-deliverable">Project 1. Individual Deliverable</a></h2>
<p>Upload the combined spatial description and geometric bar plot of your selected LMIC to your GitHub repository.  Create a link in your <code>README.md</code> file that connects to a webpage that presents your results.  Describe your plot, how you produced it, and any modifications you needed to make.  If you produced any of the stretch goals, include those in your Project 1 individual deliverable.  What observations are you able to make about the spatial description of your LMIC's population?</p>
<p>Share a link to your Project 1 webpage on the slack channel #data100_project1 no later than 11:59PM on Saturday, September 28th.</p>
<h2><a class="header" href="#individual-stretch-goal-1-2" id="individual-stretch-goal-1-2">Individual Stretch Goal 1</a></h2>
<p>Again create a combined spatial description and geometric bar plot of your LMIC, but this time use the adm2 <code>sf</code> object you created in part 2, stretch goal 2.  Use the <code>save()</code> and <code>load()</code> commands as you did before to import your adm2 object that also includes the newly created poulation column.  Also, again use the <code>mutate()</code> command to create new variables that describe <code>area</code> and <code>density</code> , but this time as new columns in your <code>adm2</code> object.    Modify the following script to produce the subsequent geometric bar plot based on your own adm2 <code>sf</code> class object.</p>
<pre><code class="language-r">lbr_adm2 %&gt;%
  ggplot(aes(x=admin1Name, y=pop19, weight = pop19, fill = admin2Name)) +
  geom_bar(stat=&quot;identity&quot;, color=&quot;blue&quot;, width=.75) +
  coord_flip() +
  theme(legend.position = &quot;none&quot;) +
  geom_text_repel(aes(label = admin2Name),
                  position = position_stack(vjust = 0.5),
                  force = 0.0005,
                  direction = &quot;y&quot;,
                  size = 1.35,
                  segment.size = .2,
                  segment.alpha = .4)
  
ggsave(&quot;lbr_adm2_bp.png&quot;, width = 20, height = 15, dpi = 300)
</code></pre>
<p><img src="images/lbr_adm2_bp.png" alt="Population by County and District" /></p>
<p>Include this with your deliverable posted to #data100_project1.</p>
<h2><a class="header" href="#individual-stretch-goal-2-2" id="individual-stretch-goal-2-2">Individual Stretch Goal 2</a></h2>
<p>Use the <code>render_movie(&quot;liberia.mp4&quot;)</code> command to create an orbitting video of the three dimension spatial plot you created in part 2, stretch goal 3.  Also, include this with your deliverable posted to #data100_project1.</p>
<h1><a class="header" href="#acquiring-modifying-and-describing-the-data" id="acquiring-modifying-and-describing-the-data">Acquiring, Modifying and Describing the Data</a></h1>
<p>For the next lab you will use land use and land cover data to describe and analyze your LMIC as well as to model relationships between different large area, geospatial attributes.  To start, create a new folder within your project <code>data</code> folder.  This will be the location where you will store a number of different raster files, or geospatial coveriates, that you will use to begin describing and analyzing your LMIC.  I have called my subfolder <code>lulc</code> which stands for land use and land cover.</p>
<p>Once you have created your <code>lulc</code> folder within your <code>data</code> folder, open google and search for the 3 digit ISO code for your seleted low or middle income country.  I simply type <em>ISO code Liberia</em> and hit return in google and the result <strong>LBR</strong>.  Once you have determined your 3 digit ISO code, copy the following webaddress and paste it into your internet browser, BUT modify the last part of the path (i.e. /ISO/) and replace it with your LMIC's ISO code.</p>
<p><a href="ftp://ftp.worldpop.org.uk/GIS/Covariates/Global_2000_2020/">ftp://ftp.worldpop.org.uk/GIS/Covariates/Global_2000_2020/</a></p>
<p>After entering the path into your browser, you may be asked to enter your name and password in order to access the file transfer protocal (ftp) site at ftp.worldpop.uk.org.  Choose guest and then attempt to connect.</p>
<p><img src="images/screen-shot-2019-09-29-at-9.05.57-pm.png" alt="" /></p>
<p>After connecting as a guest you should gain access to the folder at worldpop containing the geospatial covariates, either though the finder, file explorer, or possibly directly through your browser.  My connection protocal in OS X forwards to my finder and opens a new folder from the worldpop server.  This folder on my computer is a kind of window to the WorldPop server location where the geospatial covariates for Liberia are located.</p>
<p><img src="images/screen-shot-2019-09-29-at-9.11.03-pm.png" alt="" /></p>
<p>Each of these different folders contains sets of geospatial covariates or raster files that you will need to copy and paste into your <code>lulc</code> folder.  To start, open the <code>ESA_CCI_Annual</code> folder.  There should be several years within the folder; select the folder with the 2015 data.  Copy all of the files from the <code>ESA_CCI_Annual</code> folder to your <code>lulc</code> folder.  There will be several, each one being some megabytes to tens of megabytes in size, so be patient when copying the data.  Also keep in mind, it is likely that the WorldPop server will be overloaded with all of your classmates trying to access the data at the same time.  After you have copied the <code>ESA_CCI_Annual</code> raster data for 2015, do likewise for the <code>ESA_CCI_Water</code> raster that is found within the <code>DST</code> folder (which stands for distance).  Following the water geospatial covariate layer, continue to the folders that contain topographical and slope data.  Finally, open the <code>VIIRS</code> folder and copy the <code>.tif</code> file into your <code>lulc</code> folder that has the night time lights values for your LMIC.  After you have finished copying all of the files to your <code>lulc</code> folder, your data structure should appear similar to the following, except each of your files will begin with the ISO code for your LMIC.</p>
<p><img src="images/screen-shot-2019-09-29-at-9.17.47-pm.png" alt="" /></p>
<p>Visit the ESA-CCI Viewer at <a href="https://maps.elie.ucl.ac.be/CCI/viewer/">https://maps.elie.ucl.ac.be/CCI/viewer/</a> and have a look at the ESA-CCI data you just copied into your data subdirectory.  In the bottom left hand corner of the viewer you will find a legend for the map.  Open the legend and consider the values in the left hand column as well as each one's corresponding label.  Each value cooresponds to the three digit code found within the raster files your just copied into your <code>lulc</code> folder.  For example, the file <code>lbr_esaccilc_dst150_100m_2015.tif</code> is the geospatial covariate layer for <em>Sparse vegetation (tree, shrub, herbaceous cover) (&lt;15%)</em> since the third part of the file name <strong>dst150</strong> cooresponds to the 150 value in the legend.  As before, the dst part of the filename again stands for distance, since each gridcell will provide a distance measure.  Save the legend to your data folder for reference, since it is likely you will need it again later.</p>
<p>Once all the data is properly situated in your folder, open RStudio and create a new script.  Use the <code>library()</code> command to load the <code>raster</code>,<code>sf</code>,<code>tidyverse</code>, <code>doParallel</code> and <code>snow</code> libraries of functions just as we did before.  Set your working dirctory to your data folder.  Also, be sure to <code>load()</code> the <code>sf</code> files you previously created for your LMIC's adm1 &amp; adm2, each one with the population data variable you created.</p>
<pre><code class="language-r">rm(list=ls(all=TRUE))

# install.packages(&quot;raster&quot;, dependencies = TRUE)
# install.packages(&quot;sf&quot;, dependencies = TRUE)
# install.packages(&quot;tidyverse&quot;, dependencies = TRUE)
# install.packages(&quot;doParallel&quot;, dependencies = TRUE)
# install.packages(&quot;snow&quot;, dependencies = TRUE)

library(sf)
library(raster)
library(tidyverse)
library(doParallel)
library(snow)

setwd(&quot;/the_path/to_your/project_folder/with_data/&quot;)

### Import Administrative Boundaries ###

load(&quot;lbr_adms.RData&quot;)
</code></pre>
<p>With your working directory set to the <code>lulc</code> folder where your geospatial covariate rasters are located, you will write a command that imports all of the <code>esaccilc_dst</code> files into your R workspace, at the same time, while also stacking each rasters on top of one another, until you have formed what is called a <code>RasterStack</code>.  To do this first start with the <code>list.files()</code> command and create an object named <code>f</code> that will contain the names of all of the <code>esaccilc_dst</code> files in your <code>lulc</code> folder.  It's probably possible to import ALL of your raster files from the <code>lulc</code> folder by identifying a common pattern to ALL the geospatial covariate files, but for now we will start with just the files containing the <code>esaccilc_dst</code> <code>.tif</code> pattern in their file name.  The <code>recursive = TRUE</code> argument will enable the <code>list.files()</code> command to search not only in the parent <code>lulc</code> directory, but also in any child subdirectories.</p>
<pre><code class="language-r">f &lt;- list.files(pattern=&quot;add_file_name_pattern_here&quot;, recursive=TRUE)
</code></pre>
<p>After properly executing the above command, you should notice the object <code>f</code> appear in your top right pane.  It is also possible to check the contents of <code>f</code> which should be the names of all the <code>esaccilc_dst</code> files. </p>
<p><img src="images/screen-shot-2019-09-29-at-10.13.04-pm.png" alt="" /></p>
<p>The object <code>f</code> is needed to identify all of the <code>raster</code> objects you will stack one on top of another until you have created your <code>RasterStack</code>.  You may recall in project 1 using the <code>raster()</code> command to import a <code>.tif</code> into RStudio.  This time you will use both the <code>raster()</code> command on the inside of a function as well as the <code>stack()</code> command on the outside of the function.  In combination with the <code>lapply()</code> command (which stands for list apply), the <code>raster()</code> command will iterate through your <code>f</code> object, identifying the name of each <code>.tif</code> file from your <code>lulc</code> folder, until each one has been imported, and then with the <code>stack()</code> command, stack each raster one by one, until your formal <code>RasterStack</code> class object has been created.  The <code>function(i)</code> part of the argument is used to indicate which function will be used to iterate the number of times as objects in your <code>i</code> argument, which in this case is equal to the number of rows in <code>f</code>.</p>
<pre><code class="language-r">lulc &lt;- your_outside_cmd(lapply(f, function(i) your_inside_cmd(i, band=1)))
</code></pre>
<p>Once you have executed your <code>stack()</code> command to create your <code>RasterStack</code> object in your workspace, check to confirm the contents of your <code>lulc</code> object.</p>
<p><img src="images/screen-shot-2019-09-29-at-10.29.26-pm.png" alt="" /></p>
<p>You will notice that the <code>RasterStack</code> object not only is comprised of nearly 25 million gridcells in this instance, there is also a new dimension to the object named <code>nlayers</code>, which is 9.  Within this <code>RasterStack</code> is the <code>names</code> identifier, with each name representing one of the files we copied from the WorldPop website into your <code>lulc</code> data folder and then imported into RStudio.  While the name of each layer is provided on the <code>names</code> row having been directly assigned from each file name, specifically the names themselves are very long and confusing.  Rename each layer, by again identifying patterns from the object <code>f</code> we created, and replacing the superfluous parts with an empty space or <code>&quot;&quot;</code>.  You will need to retain the part of each file name that begins with <code>dst</code> and is then followed by three digits.  For example, with the file name <code>lbr_esaccilc_dst040_100m_2015.tif</code> you will need to retain everything BUT the <code>dst040</code> part of the name.  To do this, you will first want to replace the common pattern from the last part of the file name sequence with a <code>&quot;&quot;</code>. Then you will want to replace the first part of the common pattern from the file name sequence with a <code>&quot;&quot;</code>.  You will do this by nesting the two commands within each other.</p>
<pre><code class="language-r">nms &lt;- sub(&quot;last_part.tif&quot;, &quot;&quot;, sub(&quot;first_part_&quot;, &quot;&quot;, object_with_the_file_names))
</code></pre>
<p>Type <code>nms</code> directly into the console to confirm you have correctly created this new object that contains the truncated form of each raster layer name you plan to assign.</p>
<p><img src="images/screen-shot-2019-09-29-at-11.11.48-pm.png" alt="" /></p>
<p>The first file that contains the distance to water layer had a slightly different naming pattern, but don't worry about it just yet.  Go ahead and assign it as is, but keep in mind you will also replace that layer's name momentarily.</p>
<p>Once you have created your <code>nms</code> object that contains each layer's name, use the <code>names()</code> command with your <code>lulc</code> object as the object and simply assign the names using <code>nms</code>.</p>
<pre><code class="language-r">add_command_here(your_RasterStack_obj) &lt;- object_with_truncated_names
</code></pre>
<p>Confirm you have correctly used the <code>names()</code> command with your <code>lulc</code> object to rename each layer by viewing the <code>RasterStack</code> in the console.  You should notice that there are several new names listed for each layer in your <code>RasterStack</code>.</p>
<p><img src="images/screen-shot-2019-09-29-at-11.17.41-pm.png" alt="" /></p>
<p>There are still three more raster <code>.tif</code> files in your <code>lulc</code> data folder that need to be imported and added as new layers to your <code>lulc</code> <code>RasterStack</code> object.  Import the topography, slope and night time lights layers into R by using the <code>raster()</code> command as you have done in the past.</p>
<pre><code class="language-r">topo &lt;- raster(&quot;lbr_srtm_topo_100m.tif&quot;)
slope &lt;- raster(&quot;lbr_srtm_slope_100m.tif&quot;)
ntl &lt;- raster(&quot;lbr_viirs_100m_2015.tif&quot;)
</code></pre>
<p>Once you have those three new <code>raster</code> class objects in your R workspace, use the <code>addLayer()</code> command to combine all twelve layers into a single <code>RasterStack</code>.  To add these three layers to your existing <code>RasterStack</code> with 9 layers first specify your existing object, then follow it with the three newly imported geospatial covariate rasters you plan to stack on top of the existing nine.</p>
<pre><code class="language-r">lulc &lt;- command(existing_stack, new_raster1, new_raster2, new_raster3)
</code></pre>
<p>Manually update the names for the water layer as well as each of the three newly stacked rasters.  Again use the <code>names()</code> command with your <code>RasterStack</code> object, but this time specifiy which layers will have their names modified and updated.  In this case you want to update the names of the first layer as well as layers ten through twelve.  Using the <code>[]</code> subscripting operators with the <code>c()</code> combine command is a powerful way to traverse an object in order to pinpoint your specified command.  In this case it is important that the number of names being modified (as specified by the 1, 10, 11 &amp; 12 on the left hand side inside the subscripting operators) is the same length as the number of names being assigned (specified by the names water, topo, slope and ntl within the combine command on the right hand side).</p>
<pre><code class="language-r">add_command_here(object_name)[c(1,10:12)] &lt;- c(&quot;water&quot;,&quot;topo&quot;,&quot;slope&quot;, &quot;ntl&quot;)
</code></pre>
<p>With all of the geospatial covariates in place as separate layers within your <code>RasterStack</code> , you are now able to plot each one.  Have a look at a few of the different layers using the <code>plot()</code> command with the <code>[[layer_number]]</code> double subscripting operators.  Using the <code>[[]]</code> double subscripting operator will identify entire lists, rather than rows, objects and/or observations from within a <code>data.frame</code>.  Try adding the <code>adm1</code> or <code>adm2</code> <code>sf</code> object to your plot.  Also use the <code>contour()</code> command to add contour lines to your topographic map.</p>
<pre><code class="language-r">plot(lulc[[12]])
</code></pre>
<p><img src="images/ntl%20%282%29.png" alt="" /></p>
<pre><code class="language-r">plot(lulc[[8]])
plot(st_geometry(lbr_adm1), add = TRUE)
</code></pre>
<p><img src="images/urban.png" alt="" /></p>
<pre><code class="language-r">plot(lulc[[10]])
contour(lulc[[10]], add = TRUE)
</code></pre>
<p><img src="images/contours.png" alt="" /></p>
<h2><a class="header" href="#extracting-land-use-and-land-cover-data-for-description" id="extracting-land-use-and-land-cover-data-for-description">Extracting Land Use and Land Cover Data for Description</a></h2>
<p>Now that you have your <code>lulc</code> <code>RasterStack</code> in place, use the <code>extract()</code> command to assign the adm2 ID to each gridcell.  Just as you did before, <code>save()</code> your <code>data.frame</code> object so you don't have to unnecessarily rerun the computationally expensive <code>extract()</code> command again and again.</p>
<pre><code class="language-r">ncores &lt;- detectCores() - 1
beginCluster(ncores)
lulc_vals_adm2 &lt;- raster::extract(lulc, lbr_adm2, df = TRUE)
endCluster()
save(lulc_vals_adm2, file = &quot;lulc_vals_adm2.RData&quot;)
</code></pre>
<p>Comment off these 5 lines using the <code>#</code>, once the <code>extract()</code> has finished, and then add the <code>load(&quot;name_of_you_data_file.RData&quot;)</code> command to reload the data the next time you run your script.</p>
<p>Use the <code>sum()</code> command with the <code>summarize_all()</code> command to sum all of the values within each adm2 subdivision for each of the twelve different raster layers.  The <code>summarize_all()</code> command is  different than the one used in the previous project, since you will summarize all of the geospatial covariates at once rather than specifying each one at a time (although it is still possible, it would just take a lot more typing).</p>
<pre><code class="language-r">lulc_ttls_adm2 &lt;- lulc_vals_adm2 %&gt;%
  group_by(add_column_name) %&gt;%
  summarize_all(sum, na.rm = TRUE)
</code></pre>
<p>Your object <code>lulc_ttls_adm2</code> should have the same number of rows as your <code>adm2</code> <code>sf</code> object as well as thirteen variables, one for each of the geospatial covariates obtained from WorldPop and the <code>ID</code> column.  You will notice that the names of each column in your <code>lulc_ttls_adm2</code> object will correspond with the names of each layer from your <code>RasterStack</code>.</p>
<p><img src="images/screen-shot-2019-09-30-at-12.22.03-am.png" alt="Summation of gridcell values for each adm2 subdivision (in this case numbers 60 through 81)" /></p>
<p>Now use the <code>bind_cols()</code> command to bind each of these thirteen rows to the eleven existing variables in your adm2 object.</p>
<pre><code class="language-r">lbr_adm2 &lt;- add_command_here(lbr_adm2, lulc_ttls_adm2)
</code></pre>
<p>Your adm2 <code>sf</code> object should now have something on the order of 24 variables.  To start with your description and analysis of the land use and land cover data, consider first the <code>pop19</code> variable you created in the last project.  Use <code>ggplot()</code> to produce a histogram using the <code>geom_histogram() +</code> command.</p>
<pre><code class="language-r">ggplot(lbr_adm2, aes(pop19)) +
  geom_histogram()
</code></pre>
<p>Compare how the histogram plot changes after adding the <code>log()</code> command to the <code>pop19</code> variable within the <code>aes()</code> argument.</p>
<p><img src="images/loghist.png" alt="" /></p>
<p>Likewise, do the same with the <code>geom_density() +</code> command, also adding the <code>log()</code> command by wrapping the <code>pop19</code> variable within it.</p>
<pre><code class="language-r">ggplot(lbr_adm2, aes(pop19)) +
  geom_density()
</code></pre>
<p><img src="images/logdense.png" alt="" /></p>
<p>You will notice that the density plot has a similar profile as the histogram.  We can compare the two by overlapping the histogram with the density plot or probability density function (pdf).  In order to transform a histogram into a density plot, the density function uses somethings called a <strong>kernel</strong> and <strong>bandwidth</strong> to smooth the data over the space.  A good analogy for thinking about how a histogram transforms into a pdf is to think of each verticle bar as stacked, square pieces of chocolate, and then you took a hairdryer to warm the chocolate squares until they melted and smoothed out over the space.  While there are statistical methods that can be used to modify the shape and profile of the pdf function, essentially the area of the histogram and the density plot should be nearly the same.</p>
<pre><code class="language-r">ggplot(lbr_adm2, aes(pop19)) +
  geom_histogram(aes(y = ..density..), color = &quot;black&quot;, fill = &quot;white&quot;) + 
  geom_density(alpha = 0.2, fill = &quot;#FF6666&quot;) + 
  theme_minimal()
</code></pre>
<p><img src="images/loghistdense.png" alt="" /></p>
<p>Create another histogram with the pdf overlapping, but this time use a different variable.  For example in the following plot, I have used the <code>ntl</code> variable, without the <code>log()</code> function added.</p>
<p><img src="images/ntlhistdens.png" alt="" /></p>
<h2><a class="header" href="#team-challenge-question-2" id="team-challenge-question-2">Team Challenge Question</a></h2>
<p>Follow the steps from above used to produce the plots describing Liberia, but instead each team member should use their own selected LMIC country.  Produce <strong>two combined histogram</strong> <strong>with</strong> <strong>density plots</strong> that describe the coorelationship between population at the adm2 level as a dependent variable and two of the other land use land cover variables you added.  You are also welcome to use density as a variable.</p>
<p>Regress the data from two variables against each other and examine the coorelationship that is being described by the two variables.  Use the <code>geom_point()</code> command to add the points for your two variables as well as the <code>geom_smooth()</code> command to add the regression line (as well as the confidence interval).</p>
<pre><code class="language-r">ggplot(lbr_adm2, aes(pop19, ntl)) + 
  geom_point(size = .1, color = &quot;red&quot;) +
  geom_smooth()
</code></pre>
<p><img src="images/popntl.png" alt="" /></p>
<p>Estimate the parameters of your model using the <code>lm()</code> command and then return a <code>summary()</code> to find out more information regarding the model's fit and capacity to explain the coorelationship between your two selected variables.</p>
<pre><code class="language-r">fit &lt;- lm(pop19 ~ ntl, data=lbr_adm2)
summary(fit)
</code></pre>
<p><img src="images/screen-shot-2019-09-30-at-12.47.52-am%20%281%29.png" alt="" /></p>
<p>Add a few more variables to the <code>lm()</code> command.  For example in the following plot I have estimated a regression model where the population of Liberia in 2019 is the dependent variable (response), while night time lights (<code>ntl</code>), urban cover (<code>dst190</code>), and bare cover (<code>dst200</code>) are the independent variables (predictors).</p>
<pre><code class="language-r">ggplot(lm(pop19 ~ ntl + dst190 + dst200, data=lbr_adm2)) + 
  geom_point(aes(x=.fitted, y=.resid), size = .1) +
  geom_smooth(aes(x=.fitted, y=.resid))
</code></pre>
<p><img src="images/popntlurbbare.png" alt="" /></p>
<p>Again estimate the model and check the fit.</p>
<pre><code class="language-r">fit &lt;- lm(pop19 ~ ntl + dst190 + dst200, data=lbr_adm2)
summary(fit)
</code></pre>
<p><img src="images/screen-shot-2019-09-30-at-1.06.19-am.png" alt="" /></p>
<p>Finally, add all of the variables to your regression model.  Compare the results.</p>
<pre><code class="language-r">ggplot(lm(pop19 ~ water + dst011 + dst040 + dst130 + dst140 + dst150 + dst160 + dst190 + dst200 + topo + slope + ntl, data=lbr_adm2)) + 
  geom_point(aes(x=.fitted, y=.resid), size = .1) +
  geom_smooth(aes(x=.fitted, y=.resid))
</code></pre>
<p><img src="images/all.png" alt="" /></p>
<pre><code class="language-r">fit &lt;- lm(pop19 ~ water + dst011 + dst040 + dst130 + dst140 + dst150 + dst160 + dst190 + dst200 + topo + slope + ntl, data=lbr_adm2)
summary(fit)
</code></pre>
<p><img src="images/screen-shot-2019-09-30-at-1.10.44-am.png" alt="" /></p>
<h2><a class="header" href="#team-challenge-question-3" id="team-challenge-question-3">Team Challenge Question</a></h2>
<p>Also use <code>ggplot()</code> to plot <strong>two linear models</strong>.  Use the <code>fit()</code> and <code>summary()</code> commands to describe your models.  Are you able to definitively identify coorelation between population and any of the other or combination of other land use and land cover geospatial covariates?  How about density?</p>
<p>Meet with your group and prepare four different plots from at least three different countries (or team members) for the Friday informal group presentation.  Then as a group, upload all 5 team members plots to #data100_igps (informal group presentations) by Sunday night.  Each member should upload at least <strong>two combined histogram / density plots</strong> as well as <strong>two linear model plots</strong>.</p>
<h2><a class="header" href="#individual-stretch-goal-1-3" id="individual-stretch-goal-1-3">Individual Stretch Goal 1</a></h2>
<p>Manually recreate the <code>ggplot()</code> model of your regression from above.  First identify the <code>fitted.values</code> as a variable in the model you named <code>fit.</code>  Use the <code>$</code> operator to identify the variable within the model object and return all of the values.</p>
<pre><code class="language-r">name_of_model$variable.with.fitted.values
</code></pre>
<p>Send this <code>object$variable</code> directly to the console and review the results.  You should have the same number of fitted values as subdivisions within your adm2.  Each individual fitted value is calculated by multiplying each variables' estimate (or coefficient) by the actual value for that observation (or row) and then summating the total of those products.</p>
<p>Likewise, manually calculate each individual model residual by subtracting all of the values for the dependent or response variable, <code>pop19</code>, from each cooresponding calculated, fitted value.  The difference of these two outcomes are the model residuals.</p>
<pre><code class="language-r">your_adm2$pop19 - name_of_model$variable.with.fitted.values
</code></pre>
<p>Plot the two variables as a <code>ggplot</code> object.  First create a <code>data.frame</code> using the <code>cbind.data.frame()</code> command.  Name each of the new columns within your data frame accordingly.</p>
<pre><code class="language-r">model_data &lt;- cbind.data.frame(fitted = name_of_model$variable.with.fitted.values, residuals = your_adm2$pop19 - name_of_model$variable.with.fitted.values)
</code></pre>
<p>Use <code>ggplot()</code> to plot your model.</p>
<pre><code class="language-r">ggplot(data = you_data_frame, aes(x = variable, y = variable)) +
  geom_point(size = 0.25) +
  geom_smooth(size = 0.5)
</code></pre>
<p><img src="images/plot%20%281%29.png" alt="" /></p>
<p>The three observations beneath the curve before it begins to rise seem to evidence the final contributions to the model before it transitions towards the observation for Monrovia.  Add labels to these four points, by using the <code>subset()</code> command and creating a new object that you will use to annotate each of those four observations.</p>
<pre><code class="language-r">text &lt;- subset(model_data, fitted &gt; add_value_here)
</code></pre>
<p>Use this new object to plot the names of these four observations from the data.</p>
<pre><code class="language-r">ggplot(data = your_data, aes(x = variable, y = variable)) +
  geom_point(size = 0.25) +
  geom_smooth(size = 0.5) +
  geom_text(data = your_data,
            aes(x = variable,
                y = variable,
                label = name),
            size = 2,
            nudge_y = value)
</code></pre>
<p><img src="images/plot.png" alt="" /></p>
<p>Likewise manually calculate residual standard error.</p>
<pre><code class="language-r">#How to calculate Residual Standard error (Like Standard Deviation)
k &lt;- length(fit$coefficients)-1 #Subtract one to ignore intercept
SSE &lt;- sum(fit$residuals^2)
n &lt;- length(fit$residuals)
#Residual Standard Error
sqrt(SSE/(n-(1+k)))
</code></pre>
<p>Also, manually calculate multiple R^2.</p>
<pre><code class="language-text">#Multiple R-Squared (Coefficient of Determination)
SSyy &lt;- sum((lbr_adm2$pop19 - mean(lbr_adm2$pop19))^2)
SSE &lt;- sum(fit$residuals^2)
(SSyy-SSE)/SSyy
#Alternatively
1-SSE/SSyy
</code></pre>
<p>Calculate adjusted R^2.</p>
<pre><code class="language-r">#Adjusted R-Squared
n &lt;- length(lbr_adm2$pop19)
k &lt;- length(fit$coefficients)-1
SSE &lt;- sum(fit$residuals^2)
SSyy = sum((lbr_adm2$pop19 - mean(lbr_adm2$pop19))^2)
1-(SSE/SSyy)*(n-1)/(n-(k+1))
</code></pre>
<p>Calculate the F-statistic.</p>
<pre><code class="language-r">#F-Statistic
((SSyy-SSE)/k) / (SSE/(n-(k+1)))
</code></pre>
<p>Finally, manually add the adjusted R^2 and F-statistic as labels to your plot.</p>
<pre><code class="language-r">ggplot(data = model_data, aes(x = fitted, y = residuals)) +
  geom_point(size = 0.25) +
  geom_smooth(size = 0.5) +
  geom_text(data = text,
            aes(x = fitted,
                y = residuals,
                label = adm1),
            size = 2,
            nudge_y = 7500) +
  geom_text(aes(x = 500000,
                y = 25000,
                label = &quot;Adjusted R-Squared&quot;)) +
  geom_text(aes(x = 500000,
                y = 0,
                label = round(as.numeric(summary(fit)[9]), 4))) +
  geom_text(aes(x = 500000,
                y = -40000,
                label = &quot;F-statistic&quot;)) +
  geom_text(aes(x = 500000,
                y = -65000,
                label = round(as.numeric(summary(fit)[[10]][1]), 4)))
</code></pre>
<p><img src="images/plot%20%282%29.png" alt="" /></p>
<h1><a class="header" href="#modeling--predicting-spatial-values" id="modeling--predicting-spatial-values">Modeling &amp; Predicting Spatial Values</a></h1>
<p>In this lab, you will use the model parameters your previously estimated in order to predict spatial values across the landscape of your selected LMIC.  To do this create a new script, install and load needed packages and libraries, and set your working directory.  Once you have your script set up with <code>sf::</code> , <code>raster::</code>, <code>tidyverse::</code>, <code>doParallel::</code>, and <code>snow::</code> all in place, again load your <code>RasterStack</code> into your RStudio workspace.  I named my 12 layer <code>RasterStack</code> that describes land use and land cover throughout Liberia, <code>lulc</code>, and just as before it displays the following summary characteristics.</p>
<p><img src="images/screen-shot-2019-10-06-at-6.53.01-pm.png" alt="" /></p>
<p>Also, load the <code>adm0</code> (or international boundary), <code>adm1</code> and <code>adm2</code> for your LMIC.  If you don't have your international boundary, go back to GADM, HDX or also look on Geoboundaries for the shapefile in order to import to your RStudio work session.</p>
<p>{% embed url=&quot;https://www.gadm.org&quot; caption=&quot;Link to GADM&quot; %}</p>
<p>{% embed url=&quot;https://data.humdata.org&quot; caption=&quot;Link to HDX&quot; %}</p>
<p>{% embed url=&quot;http://www.geoboundaries.org/data/1_3_3/zip/shapefile/&quot; caption=&quot;Geoboundaries subdirectory with shapefiles by ISO code&quot; %}</p>
<p>For this exercise, I will retrieve my international border shapefile from the Geoboundaries subdirectory and then use the <code>read_sf()</code> command to import the data as an object I named <code>lbr_int</code>.</p>
<p>You will also need the WorldPop raster later in the exercise in order to calculate a basic estimate of spatial error.  To improve upon the predictive capability of the model, I have gone back and retrieved the 2015 WorldPop raster file of persons per pixel (ppp) for Liberia, rather than the 2019 population counts we previously used.  It is probably not going to have a huge impact, but if you want to try for the best results, the date value of your response variable should be the same as the date value of your geospatial covariates.</p>
<pre><code class="language-r">lbr_pop15 &lt;- raster(&quot;lbr_ppp_2015.tif&quot;)
</code></pre>
<p>You may have noticed when reviewing the characteristics of your <code>RasterStack</code> that many of the layers had <code>?</code> as the value for both the <code>min values</code> and <code>max values</code>.  The reason this occurred is because each of the layers within the <code>raster</code> is presenting values outside of the boundaries of our LMIC.  For example, with Liberia, you will notice that there is a large portion of the area within the plot but outside of the national border that has some assigned value (likely <code>NA</code>).  These values are not part of our analytical area and should be omitted.  In order to fix this problem, we need to use the <code>mask()</code> command to remove all of the gridcells that are not explicitly within the international border of our LMIC.</p>
<pre><code class="language-r">yourRasterStack &lt;- add_command_here(yourRasterStack, yourLMIC_intlborder)
</code></pre>
<p>It might take a few minutes to run the <code>mask()</code> command.  On a MBAir using the <code>mask()</code> command on a 12 layer <code>RasterStack</code> (each layer having about 25 million gridcells) it takes about 10 minutes.  Once the command is completed, you should now notice <code>min values</code> and <code>max values</code> when retrieving a summary of what has now been transformed from a <code>RasterStack</code> to a <code>RasterBrick</code>.</p>
<p><img src="images/screen-shot-2019-10-06-at-7.50.14-pm.png" alt="" /></p>
<p>As in the previous exercise, estimate your linear model using the <code>pop15</code> variable as your response (dependent variable) and all of the covariates from your <code>adm2</code> sf object as the predictors (independent variables).</p>
<pre><code class="language-r">model &lt;- add_command_here(depvar ~  ind1 + ... + indN, data=your_adm2_sf)
</code></pre>
<p>Once you have estimated your model, use the <code>summary()</code> command to review a summary of its characteristics.</p>
<p><img src="images/screen-shot-2019-10-06-at-8.23.25-pm.png" alt="" /></p>
<p>Confirm that each variable in your <code>lulc</code> object has a corresponding variable in the linear model you just estimated.  You will use these estimates with the 12 different geospatial coverariate layers within your <code>RasterBrick</code> to predict the population at each gridcell across your LMIC.  Use the <code>predict()</code> function from the <code>raster::</code> package with your <code>lulc</code> object as well as your <code>model</code> to predict the population value of every gridcell within the borders of your LMIC.</p>
<pre><code class="language-r">predicted_values &lt;- library::function(RasterBrick, your_model, progress=&quot;window&quot;)
</code></pre>
<p>Adding the <code>progress=&quot;window&quot;</code> argument at the end of the command should force a progress window to appear on main desktop that informs you of how many steps are needed to completely execute the command as well as how many have been completed.  The <code>progress=&quot;window&quot;</code> argument is purely optional.</p>
<p>The resulting object <code>predicted_values</code> should be a single <code>RasterLayer</code> with the same number of gridcells as each layer within your <code>RasterBrick</code>.   Type the name of the <code>RasterLayer</code> into the console to review its summary output, while also noting the minimum and maximum values across all gridcells.</p>
<p>Use the <code>cellStats(predicted_values, sum)</code> command to calculate the sum of all the values in every gridcell throughout your newly created <code>RasterLayer</code>.  With the model estimated for Liberia, the sum total of all predicted values is <code>113413402375</code>(113 billion).  Compared with the output from <code>sum(your_adm2$pop15)</code> (which is <code>4039128</code>for Liberia) your will very likely that your model has massively overestimated population values (in this case by an order of about 28,000 times).</p>
<p>While these predicted values are no where near the real population count at each gridcell, they do nonetheless provide a spatial description of the proportion of persons as distributed across the landscape of your LMIC.  In fact, if we execute some basic raster algebra and subtract the minimium value from my <code>predicted_values</code> <code>RasterLayer</code> and then sum the values of all gridcells, we will find that while the total population predicted is still very likely a gross overestimation, it is getting closer to our best estimate of the real value (in the case of Liberia, now an order of 15 times <code>pop15</code>).</p>
<pre><code class="language-r">base &lt;- predicted_values - minValue(predicted_values)
cellStats(base, sum) 
</code></pre>
<p>We will proceed with the <code>RasterLayer</code> by using the <code>extract()</code>command to assign the ID from each <code>adm2</code> object to each gridcell containing a predicted value from our linear model using the <code>lulc</code> geospatial covariates as indenpendent variables.  To effectively use the <code>extract()</code> command, set <code>ncores</code> object to one less than your total and then also execute the <code>beginCluster()</code> command as you have done in previous exercises.  In this case, since it is only one layer, the extract command should take less time to execute (about 10 to 15 minutes on an MBAir).</p>
<pre><code class="language-r">ncores &lt;- detectCores() - 1
beginCluster(ncores)
pred_vals_adm2 &lt;- raster::extract(your_pred_vals_raster, your_adm2, df=TRUE)
endCluster()
</code></pre>
<p>Once you have assigned the <code>ID</code> to each gridcell according to its <code>adm2</code> location, aggregate the values.  This time we will use a slightly different command to sum the values by <code>adm2</code> unit, although either way could work.  Also, bind this new column to your <code>adm2</code> <code>sf</code> object.</p>
<pre><code class="language-r">pred_ttls_adm2 &lt;- aggregate(. ~ ID, pred_vals_adm2, sum)
lbr_adm2 &lt;- bind_cols(lbr_adm2, pred_ttls_adm2)
</code></pre>
<p>Your <code>sf</code> object now has a new column named <code>layer</code> that has the sum of all predicted values for each <code>adm2</code> subdivision of the LMIC.  Assign the value for <code>layer</code> to each gridcell according to its <code>adm2</code> subdivision.  Use the <code>rasterize()</code> command with your <code>adm2</code> object and your <code>predicted_values</code> raster in order to create a new <code>raster</code> that has the predicted totals of every <code>adm2</code> assigned to each gridcell according to its location.  The <code>raster</code> object used in the argument (in this case <code>predicted_values</code>) is the base template for the new raster produced as a result of the command. </p>
<pre><code class="language-r">new_raster &lt;- command(adm2, template_raster, field = &quot;layer&quot;)
</code></pre>
<p>Create a new raster that represents each gridcells proportion of the total within its <code>adm2</code> subdivision.</p>
<pre><code class="language-r">another_new_raster  &lt;- raster_1 / raster_2
</code></pre>
<p>Again use the <code>rasterize()</code> command to assign a value to every gridcell according to its <code>adm2</code> location, but this time use the <code>pop15</code> variable.</p>
<pre><code class="language-r">yet_another_new_raster &lt;- command(adm2, template_raster, field = &quot;pop15&quot;)
</code></pre>
<p>Distribute the <code>adm2</code> populatoin totals across each gridcell according to its fractional proportion of summed predicted population (also at <code>adm2</code>), multiply the proportion by the totals.</p>
<pre><code class="language-text">population &lt;- gridcell_proportions * population_adm2
</code></pre>
<p>Confirm your results by evaluating the totals.</p>
<pre><code class="language-text">cellStats(population, sum)
[1] 4039128
</code></pre>
<p>R should return the same total previously used when you calcualte <code>sum(your_adm2$pop15)</code>.</p>
<p><img src="images/rplot01%20%289%29.png" alt="" /></p>
<h2><a class="header" href="#investigate-margins-of-error" id="investigate-margins-of-error">Investigate Margins of Error</a></h2>
<p>Our model is serving to allocate population totals across all gridcells, but how accurate is it?  To start we can calculate the different of our predicted values - the worldpop values and sum the totals.</p>
<pre><code class="language-text">diff &lt;- population - lbr_pop15
</code></pre>
<p>In order to establish a basis for comparing total error across your LMIC take the absolute value of the differences and sum them to arrive a term that represnts total error.</p>
<pre><code class="language-text">cellStats(abs(diff), sum)
</code></pre>
<p>Taking the <code>hist(diff)</code> will also inform you of the magnitude and direction of error in your predicted values.  Use the <code>plot(diff)</code> command to have a look at the resulting raster.</p>
<p><img src="images/rplot02%20%285%29.png" alt="" /></p>
<p>By looking at the histogram and the above difference of predicted value from worldpop raster it appears that most of the error is slightly above or below 0, and is also distributed fairly evenly across the entire space.  Looking closely though, the area close to the southwest coast appears to exhibit a different phenomenon.  This is the capital of Liberia, Monrovia.  For your investigation, select the primary urban area and conduct the same analysis as follows.</p>
<p>First subset your <code>adm2</code> by using the name of the administrative subdivision.</p>
<pre><code class="language-text">new_name &lt;- your_adm2 %&gt;%
  filter(name_var == &quot;Add Name Here&quot;)
</code></pre>
<p>Use the <code>mask()</code> command with this newly created <code>sf</code> object to focus your analysis on the primate city within your LMIC.</p>
<pre><code class="language-text">urban_diff &lt;- mask(diff, urban_adm2)
urban_pop &lt;- mask(population, urban_adm2)
</code></pre>
<p>Create an object the defines the boundaries of your identified urban area.  The bounding box used in your <code>crop()</code> command should be defined according the following order.</p>
<pre><code class="language-text">c(western_most_longitude, eastern_most_longitude, southern_most_latitude, northern_most_latitude)
</code></pre>
<p>Following is the bounding box and <code>crop()</code> command used for Monrovia, Liberia.</p>
<pre><code class="language-text">extGMN &lt;- c(-10.83, -10.64, 6.20, 6.42)
gmonrovia_diff &lt;- crop(gmonrovia_diff, extGMN)
gmonrovia_pop &lt;- crop(gmonrovia_pop, extGMN)
</code></pre>
<p>Plot your Monrovia rasters.</p>
<p><img src="images/rplot03%20%285%29.png" alt="Error in terms of Predicted Values - WorldPop estimates" /></p>
<p><img src="images/rplot04%20%283%29.png" alt="" /></p>
<p>Finally, plot a three dimension map of the values, to gauge exactly how much variation was exhibited in the predicted values.  Install and load the <code>rgl::</code> and <code>rasterVis::</code> libraries in order to execute the following command.</p>
<pre><code class="language-text">rasterVis::plot3D(gmonrovia_pop)
</code></pre>
<p><img src="images/screen-shot-2019-10-07-at-12.26.00-am.png" alt="" /></p>
<p>Finally, add the <code>tmap::</code> library and overlay your differences plot.</p>
<pre><code class="language-r">mapview::mapview(gmonrovia_diff, alpha = .5)
</code></pre>
<p>Do you identify a geospatial trend associated with the error resulting from your predicted values?</p>
<p><img src="images/rplot07%20%282%29.png" alt="" /></p>
<h2><a class="header" href="#team-challenge-question-4" id="team-challenge-question-4">Team Challenge Question</a></h2>
<p>Follow the steps from above used to produce the plots describing Liberia, but instead each team member should use their own selected LMIC country.  Investigate the results from your model at different scales and locations across your selected LMIC.  How effective was your model?  Do you identify any trends?  Produce a variety of plots that investigate, describe and analyze your dasymmetric population allocation using a linear model with land use and land cover geospatial covariates.  Investigate at least two different locations and two different scales.  Use adm1, adm2 or adm3 units of analysis, either in combination or alone to define the boundaries of your analysis.</p>
<p>Meet with your group and prepare to present three different plots from at least three different countries (or team members) for the Friday informal group presentation.  You are welcome to combine output from the previous Project 2 exercise (part 1) as you wish.  Then as a group, upload all 5 team members plots to #data100_igps (informal group presentations) by Sunday night.  Each member should upload at least <strong>four plots</strong> that describe <strong>at least two different locations of differing scales</strong> within your LMIC.</p>
<h1><a class="header" href="#investigating-and-comparing-results" id="investigating-and-comparing-results">Investigating and Comparing Results</a></h1>
<p>Load all of your covariates, import your adm0 (international boundary) to <code>crop()</code> and <code>mask()</code> your <code>RasterBrick</code> and then use <code>writeRaster()</code> to save it.  Later, use the <code>brick()</code> function to import your <code>RasterBrick</code> to your RStudio work session as needed.  Make sure the layers in your <code>RasterBrick</code> are named after using the <code>brick()</code> command.  Use the <code>names()</code> command to name your layers.</p>
<pre><code class="language-r">f &lt;- list.files(pattern=&quot;lbr_esaccilc_dst&quot;, recursive=TRUE)
lulc &lt;- stack(lapply(f, function(i) raster(i, band=1)))
nms &lt;- sub(&quot;_100m_2015.tif&quot;, &quot;&quot;, sub(&quot;lbr_esaccilc_&quot;, &quot;&quot;, f))
names(lulc) &lt;- nms
topo &lt;- raster(&quot;lbr_srtm_topo_100m.tif&quot;)
slope &lt;- raster(&quot;lbr_srtm_slope_100m.tif&quot;)
ntl &lt;- raster(&quot;lbr_viirs_100m_2015.tif&quot;)
lulc &lt;- addLayer(lulc, topo, slope, ntl)
names(lulc)[c(1,10:12)] &lt;- c(&quot;water&quot;,&quot;topo&quot;,&quot;slope&quot;, &quot;ntl&quot;)

lbr_adm0  &lt;- read_sf(&quot;gadm36_LBR_0.shp&quot;)

lulc &lt;- crop(lulc, lbr_adm0)
lulc &lt;- mask(lulc, lbr_adm0)

writeRaster(lulc, filename = &quot;lulc.tif&quot;, overwrite = TRUE)
# lulc &lt;- stack(&quot;lulc.tif&quot;)
lulc &lt;- brick(&quot;lulc.tif&quot;)

names(lulc) &lt;- c(&quot;water&quot;, &quot;dst011&quot; , &quot;dst040&quot;, &quot;dst130&quot;, &quot;dst140&quot;, &quot;dst150&quot;, 
                 &quot;dst160&quot;, &quot;dst190&quot;, &quot;dst200&quot;, &quot;topo&quot;, &quot;slope&quot;, &quot;ntl&quot;)
</code></pre>
<p>Obtain the 2015 WorldPop persons per pixel file for your LMIC.  Make sure your adm <code>sf</code> object has the total population per subdivision as well as its area and density.  Summarize all twelve geospatial covariates in adm groups by <code>sum</code> and by <code>mean</code>.  Modify the following code to create your adm2 or adm3 object (you only have to select one, in the following example I have selected adm3 for Liberia).</p>
<pre><code class="language-r">lbr_pop15 &lt;- raster(&quot;lbr_ppp_2015.tif&quot;)
# lbr_adm1  &lt;- read_sf(&quot;gadm36_LBR_1.shp&quot;)
# lbr_adm2  &lt;- read_sf(&quot;gadm36_LBR_2.shp&quot;)
lbr_adm3  &lt;- read_sf(&quot;gadm36_LBR_3.shp&quot;)

# ncores &lt;- detectCores() - 1
# beginCluster(ncores)
# pop_vals_adm1 &lt;- raster::extract(lbr_pop15, lbr_adm1, df = TRUE)
# pop_vals_adm2 &lt;- raster::extract(lbr_pop15, lbr_adm2, df = TRUE)
# pop_vals_adm3 &lt;- raster::extract(lbr_pop15, lbr_adm3, df = TRUE)
# endCluster()
# save(pop_vals_adm1, pop_vals_adm2, pop_vals_adm3, file = &quot;lbr_pop_vals.RData&quot;)

load(&quot;lbr_pop_vals.RData&quot;)

# totals_adm1 &lt;- pop_vals_adm1 %&gt;%
#   group_by(ID) %&gt;%
#   summarize(pop15 = sum(lbr_ppp_2015, na.rm = TRUE))
# 
# lbr_adm1 &lt;- lbr_adm1 %&gt;%
#   add_column(pop15 = totals_adm1$pop15)
# 
# lbr_adm1 &lt;- lbr_adm1 %&gt;%
#   mutate(area = st_area(lbr_adm1) %&gt;%
#            set_units(km^2)) %&gt;%
#   mutate(density = pop15 / area)

# totals_adm2 &lt;- pop_vals_adm2 %&gt;%
#   group_by(ID) %&gt;%
#   summarize(pop15 = sum(lbr_ppp_2015, na.rm = TRUE))
# 
# lbr_adm2 &lt;- lbr_adm2 %&gt;%
#   add_column(pop15 = totals_adm2$pop15)
# 
# lbr_adm2 &lt;- lbr_adm2 %&gt;%
#   mutate(area = st_area(lbr_adm2) %&gt;%
#            set_units(km^2)) %&gt;%
#   mutate(density = pop15 / area)

totals_adm3 &lt;- pop_vals_adm3 %&gt;%
  group_by(ID) %&gt;%
  summarize(pop15 = sum(lbr_ppp_2015, na.rm = TRUE))

lbr_adm3 &lt;- lbr_adm3 %&gt;%
  add_column(pop15 = totals_adm3$pop15)

lbr_adm3 &lt;- lbr_adm3 %&gt;%
  mutate(area = st_area(lbr_adm3) %&gt;% 
           set_units(km^2)) %&gt;%
  mutate(density = pop15 / area)

#save(lbr_adm1, lbr_adm2, lbr_adm3, file = &quot;lbr_adms.RData&quot;)

# lulc &lt;- brick(&quot;lulc.tif&quot;)

# names(lulc) &lt;- c(&quot;water&quot;, &quot;dst011&quot; , &quot;dst040&quot;, &quot;dst130&quot;, &quot;dst140&quot;, &quot;dst150&quot;, 
#                 &quot;dst160&quot;, &quot;dst190&quot;, &quot;dst200&quot;, &quot;topo&quot;, &quot;slope&quot;, &quot;ntl&quot;)

# ncores &lt;- detectCores() - 1
# beginCluster(ncores)
# lulc_vals_adm1 &lt;- raster::extract(lulc, lbr_adm1, df = TRUE)
# lulc_vals_adm2 &lt;- raster::extract(lulc, lbr_adm2, df = TRUE)
# lulc_vals_adm3 &lt;- raster::extract(lulc, lbr_adm3, df = TRUE)
# endCluster()
# save(lulc_vals_adm1, lulc_vals_adm2, lulc_vals_adm3, file = &quot;lulc_vals_adms.RData&quot;)

load(&quot;lulc_vals_adms.RData&quot;)

# lulc_ttls_adm1 &lt;- lulc_vals_adm1 %&gt;%
#   group_by(ID) %&gt;%
#   summarize_all(sum, na.rm = TRUE)

# lulc_ttls_adm2 &lt;- lulc_vals_adm2 %&gt;%
#   group_by(ID) %&gt;%
#   summarize_all(sum, na.rm = TRUE)

lulc_ttls_adm3 &lt;- lulc_vals_adm3 %&gt;%
  group_by(ID) %&gt;%
  summarize_all(sum, na.rm = TRUE)

lulc_means_adm3 &lt;- lulc_vals_adm3 %&gt;%
  group_by(ID) %&gt;%
  summarize_all(mean, na.rm = TRUE)

# lbr_adm1 &lt;- bind_cols(lbr_adm1, lulc_ttls_adm1)
# lbr_adm2 &lt;- bind_cols(lbr_adm2, lulc_ttls_adm2)

lbr_adm3 &lt;- bind_cols(lbr_adm3, lulc_ttls_adm3, lulc_means_adm3)

save(lbr_adm3, file = &quot;lbr_adm3.RData&quot;)
</code></pre>
<p>Load your geospatial covariate <code>RasterBrick</code> of land use and land cover <code>lulc</code>, your 2015 WorldPop <code>raster</code> and  your adm <code>sf</code> object.  View your adm <code>sf</code> object and notice that you now have two summary sets of columns that describe each of your twelve geospatial covariates.  The first set of columns describes the sum of all values per adm while the second set describes the mean of all values per adm.  Also notice that in the second set, each variable  has had the number 1 added to its name to differentiate it from the first series.</p>
<p>Use the <code>lm()</code> function to estimate three models.  First use <code>pop15</code> as the response variable and the <code>sum</code> of each geospatial covariate per adm as the predictors.  Second, again use <code>pop15</code> as the response variable but this time instead use the <code>mean</code> of each geospatial covariate per adm as the predictors.  Third, use the logarithm of 2015 population <code>log(pop15)</code> as the response and the <code>mean</code> of each geospatial covariate per adm as the predictors.  Notice I created a new variable named <code>logpop15</code> but you could just as easily have specified <code>log(pop15)</code> within the call of your model.</p>
<pre><code class="language-r">model.sums &lt;- lm(pop15 ~ water + dst011 + dst040 + dst130 + dst140 + dst150 + dst160 + dst190 + dst200 + topo + slope + ntl, data=lbr_adm3)
model.means &lt;- lm(pop15 ~ water1 + dst0111 + dst0401 + dst1301 + dst1401 + dst1501 + dst1601 + dst1901 + dst2001 + topo1 + slope1 + ntl1, data=lbr_adm3)

lbr_adm3$logpop15 &lt;- log(lbr_adm3$pop15)
model.logpop15 &lt;- lm(logpop15 ~ water1 + dst0111 + dst0401 + dst1301 + dst1401 + dst1501 + dst1601 + dst1901 + dst2001 + topo1 + slope1 + ntl1, data=lbr_adm3)
</code></pre>
<p>Check the summary output from each model.</p>
<pre><code class="language-r">summary(model.sums)
summary(model.means)
summary(model.logpop15)
</code></pre>
<p>Make sure the names of each layer in your <code>RasterBrick</code> matches the names of the independent variables in each of your models.  Notice how the second two models use the <code>mean</code> of each geospatial covarariate and the layer names are modified accordingly to match.</p>
<pre><code class="language-r">names(lulc) &lt;- c(&quot;water&quot;, &quot;dst011&quot; , &quot;dst040&quot;, &quot;dst130&quot;, &quot;dst140&quot;, &quot;dst150&quot;, &quot;dst160&quot;, &quot;dst190&quot;, &quot;dst200&quot;, &quot;topo&quot;, &quot;slope&quot;, &quot;ntl&quot;)
lulc1 &lt;- lulc
names(lulc1) &lt;- c(&quot;water1&quot;, &quot;dst0111&quot; , &quot;dst0401&quot;, &quot;dst1301&quot;, &quot;dst1401&quot;, &quot;dst1501&quot;, &quot;dst1601&quot;, &quot;dst1901&quot;, &quot;dst2001&quot;, &quot;topo1&quot;, &quot;slope1&quot;, &quot;ntl1&quot;)
</code></pre>
<p>Use the <code>predict()</code> function from the <code>raster::</code> package with the appropriate <code>RasterBrick</code> and <code>model</code> to predict each gridcells value.  Use the <code>save()</code> and then the <code>load()</code> command in order to reduce computation time after restarting your work session. </p>
<pre><code class="language-r">predicted_values_sums &lt;- raster::predict(lulc, model.sums)
predicted_values_means &lt;- raster::predict(lulc1, model.means)
predicted_values_logpop15 &lt;- raster::predict(lulc1, model.logpop15)

#save(predicted_values_sums, predicted_values_means, predicted_values_logpop15, file = &quot;predicted_values.RData&quot;)
</code></pre>
<p>Use the <code>extract()</code> function from the <code>raster::</code> package to assign the adm ID to each gridcell.  Again use the <code>save()</code> and <code>load()</code> commands to reduce computation time.</p>
<pre><code class="language-r">ncores &lt;- detectCores() - 1
beginCluster(ncores)
pred_vals_adm3_sums &lt;- raster::extract(predicted_values_sums, lbr_adm3, df=TRUE)
pred_vals_adm3_means &lt;- raster::extract(predicted_values_means, lbr_adm3, df=TRUE)
pred_vals_adm3_logpop15 &lt;- raster::extract(predicted_values_logpop15, lbr_adm3, df=TRUE)
endCluster()

#save(pred_vals_adm3_sums, pred_vals_adm3_means, pred_vals_adm3_logpop15, file = &quot;predicted_values_adm3s.RData&quot;)
</code></pre>
<p>Aggregate all values.</p>
<pre><code class="language-r">pred_ttls_adm3_sums &lt;- aggregate(. ~ ID, pred_vals_adm3_sums, sum)
pred_ttls_adm3_means &lt;- aggregate(. ~ ID, pred_vals_adm3_means, sum)
pred_ttls_adm3_logpop15 &lt;- aggregate(. ~ ID, pred_vals_adm3_logpop15, sum)
</code></pre>
<p>Create a new data frame that contains the aggregate sums from each model's predictions.</p>
<pre><code class="language-r">ttls &lt;- cbind.data.frame(preds_sums = pred_ttls_adm3_sums$layer, 
                         preds_means = pred_ttls_adm3_means$layer, 
                         resp_logpop = pred_ttls_adm3_logpop15$layer)
</code></pre>
<p>Bind the new values as columns within your adm.  Notice I assigned a name to each column.</p>
<pre><code class="language-r">lbr_adm3 &lt;- bind_cols(lbr_adm3, ttls)
</code></pre>
<p>Use the <code>rasterize()</code> command to create a new <code>RasterLayer</code> containing the predicted values from each of your models.  The second object in your <code>rasterize()</code> command is the raster that is used as the template to produce the new raster.  The values of the template raster are not used in the calculation, instead the values in the column of your adm <code>sf</code> object that identify the sum of predicted values from your model is used. </p>
<pre><code class="language-r">predicted_totals_sums &lt;- rasterize(lbr_adm3, predicted_values_sums, field = &quot;preds_sums&quot;)
predicted_totals_means &lt;- rasterize(lbr_adm3, predicted_values_sums, field = &quot;preds_means&quot;)
predicted_totals_logpop &lt;- rasterize(lbr_adm3, predicted_values_sums, field = &quot;resp_logpop&quot;)
</code></pre>
<p>Calculate the gridcell proportions for each result.</p>
<pre><code class="language-r">gridcell_proportions_sums  &lt;- predicted_values_sums / predicted_totals_sums
gridcell_proportions_means  &lt;- predicted_values_means / predicted_totals_means
gridcell_proportions_logpop  &lt;- predicted_values_logpop15 / predicted_totals_logpop
</code></pre>
<p>Check the <code>cellStats()</code> to confirm that the sum of each objects proportions is equal to the number of adms in your <code>sf</code> object.</p>
<pre><code class="language-r">cellStats(gridcell_proportions_sums, sum)
cellStats(gridcell_proportions_means, sum)
cellStats(gridcell_proportions_logpop, sum)
</code></pre>
<p>Produce a raster object that contains the WorldPop values we will use as our comparison spatial data set for validation.</p>
<pre><code class="language-r">population_adm3 &lt;- rasterize(lbr_adm3, predicted_values_sums, field = &quot;pop15&quot;)
</code></pre>
<p>Calculate the final predicted value for each gridcell according to the output from each of the three models.</p>
<pre><code class="language-r">population_sums &lt;- gridcell_proportions_sums * population_adm3
population_means &lt;- gridcell_proportions_means * population_adm3
population_logpop &lt;- gridcell_proportions_logpop * population_adm3
</code></pre>
<p>Check <code>cellStats()</code> to verify that total population matches the initial value used in this dasymmetric allocation.</p>
<pre><code class="language-text">cellStats(population_sums, sum)
cellStats(population_means, sum)
cellStats(population_logpop, sum)

sum(lbr_adm3$pop15)
</code></pre>
<p>Calculate the difference between each <code>RasterLayer</code> and the WorldPop <code>RasterLayer</code>.</p>
<pre><code class="language-r">diff_sums &lt;- population_sums - lbr_pop15
diff_means &lt;- population_means - lbr_pop15
diff_logpop &lt;- population_logpop - lbr_pop15
</code></pre>
<p>Finally, produce a raster plot of each model's predicted output as well as the differences and a 3D plot to visualize the results.</p>
<pre><code class="language-r">plot(population_sums)
plot(diff_sums)
rasterVis::plot3D(diff_sums)
cellStats(abs(diff_sums), sum)

plot(population_means)
plot(diff_means)
rasterVis::plot3D(diff_means)
cellStats(abs(diff_means), sum)

plot(population_logpop)
plot(diff_logpop)
rasterVis::plot3D(diff_logpop)
cellStats(abs(diff_logpop), sum)

plot(lbr_pop15)

rgl.snapshot(&quot;diff&quot;, fmt = &quot;png&quot;, top = TRUE )
</code></pre>
<p><img src="images/rplot%20%286%29.png" alt="Population: Predictors - Sums" /></p>
<p><img src="images/rplot10.png" alt="Difference: Predictors - Sums" /></p>
<p><img src="images/diff1.png" alt="3D Difference: Predictors - Sums" /></p>
<p><img src="images/rplot11.png" alt="Population: Predictors - Means" /></p>
<p><img src="images/rplot12.png" alt="Difference: Predictors - Means" /></p>
<p><img src="images/diff2.png" alt="3D Difference: Predictors - Means" /></p>
<p><img src="images/rplot13.png" alt="Population: Response - Log of Population" /></p>
<p><img src="images/rplot14.png" alt="Difference: Response - Log of Population " /></p>
<p><img src="images/diff.png" alt="3D Difference: Response - Log of Population " /></p>
<h2><a class="header" href="#project-2-individual-deliverable" id="project-2-individual-deliverable">Project 2. Individual Deliverable</a></h2>
<p>Upload three sets of spatial plots that describe the predicted population of your selected LMIC using each of the three models.</p>
<ol>
<li>Response variable is population and the predictors are sum of covariates</li>
<li>Response variable is population and the predictors are mean of covariates</li>
<li>Reponse variable is log of population and the predictors are mean of covariates</li>
</ol>
<p>Each of the three sets of plots should also have three plots.</p>
<ol>
<li>A plot that describes the predicted population of your LMIC using the model</li>
<li>A plot that describes the difference between your predicted results and the WorldPop estimates for 2015</li>
<li>A three dimension plot that visualizes the population or difference</li>
</ol>
<p>Accompany your series of plots with a written statement that identifies which of the three models produced the best results.  Justify your assessment. </p>
<p>Upload your deliverable to the slack channel #data100_project2 no later than 11:59PM on Sunday, October 20th.</p>
<h2><a class="header" href="#individual-stretch-goal-1-4" id="individual-stretch-goal-1-4">Individual Stretch Goal 1</a></h2>
<p>Conduct the same analysis as above at an increased scale, analyzing one of your LMIC's largest or most significant urban areas or cities.  Subset your adm using the <code>%&gt;%</code> operator and the <code>|</code> as needed.</p>
<pre><code class="language-r">mts_bomi &lt;- lbr_adm3 %&gt;%
 filter(NAME_1 == &quot;Montserrado&quot; | NAME_1 == &quot;Bomi&quot;)
</code></pre>
<p>Use the <code>mapview()</code> command to identify trends and provide further support for your assessment of each model as you did in the previous execise.</p>
<pre><code class="language-r">mapview::mapview(gmonrovia_diff, alpha = .5)
</code></pre>
<p>Again compare the results.  Are you able to identify any trends?</p>
<h2><a class="header" href="#individual-stretch-goal-2-3" id="individual-stretch-goal-2-3">Individual Stretch Goal 2</a></h2>
<p>Estimate a random forest model using the same data you previously used.  Use the mean values of all grid cells within each adm as the predictors (independent variable) and the log of population as the response (dependent variable).  Start by loading the World Pop raster you will use to validate your resuts against first.  Then load your adm0 to use in your <code>crop()</code> and <code>mask()</code> commands.  Load your adm3 that has all of your variables needed to estimate your random forest model.  Also be sure to load the land use and land cover variables you will use to predict the population of each individual grid cell.</p>
<pre><code class="language-text">rm(list=ls(all=TRUE))

# install.packages(&quot;raster&quot;, dependencies = TRUE)
# install.packages(&quot;sf&quot;, dependencies = TRUE)
# install.packages(&quot;tidyverse&quot;, dependencies = TRUE)
# install.packages(&quot;doParallel&quot;, dependencies = TRUE)
# install.packages(&quot;snow&quot;, dependencies = TRUE)
# install.packages(&quot;randomForest&quot;, dependencies = TRUE)

#library(sp)
library(sf)
library(raster)
library(tidyverse)
library(doParallel)
library(snow)
library(randomForest)

### Import Administrative Boundaries ###

setwd(&quot;~/Tresors/teaching/project_folder/data/&quot;)

lbr_pop15 &lt;- raster(&quot;lbr_ppp_2015.tif&quot;)

lbr_adm0  &lt;- read_sf(&quot;gadm36_LBR_0.shp&quot;)
load(&quot;lbr_adm3.RData&quot;)

lulc &lt;- brick(&quot;lulc.tif&quot;)

lulc &lt;- crop(lulc, lbr_adm0)
lulc &lt;- mask(lulc, lbr_adm0)
</code></pre>
<p>Simplify your adm3 by extracting only the needed columns.  Remove the geometry from the object by using the <code>st_geometry()</code> command and assigning it as <code>NULL</code>.  Add the log of population as a variable to your newly created data set.  Simply the class of your data set by rewriting it as a <code>data.frame</code>.</p>
<pre><code class="language-text">model_data &lt;- lbr_adm3[ ,c(18:20, 35:46)]
st_geometry(model_data) &lt;- NULL
model_data$logpop15 &lt;- as.numeric(log(model_data$pop15))
model_data &lt;- as.data.frame(model_data)
</code></pre>
<p>Your object <code>model_data</code> should have the following structure.</p>
<p><img src="images/screen-shot-2019-10-21-at-11.23.53-pm.png" alt="" /></p>
<p>Simplify the objects you will use as the predictors and response by creating two new objects.  The <code>x_data</code> object are your predictors and coorespond to the mean values of each <code>lulc</code> variable at each adm.  The <code>y_data</code> is your response variable, in this case log of population.</p>
<pre><code class="language-text">x_data &lt;- model_data[ ,4:15]
y_data &lt;- model_data[ ,16]
</code></pre>
<p>First, tune your random forest model in order to determine which of the variables are important.  The <code>ntreeTry =</code>  argument specifies how many trees the model will estimate at the tuning step.  The <code>mtryStart =</code>  argument specifies how many variables will be tried at each split.  Other arguments are also important, but you can simply follow the following chunk of code to start.</p>
<pre><code class="language-text">init_fit &lt;- tuneRF(x = x_data, 
                   y = y_data,
                   plot = TRUE,
                   mtryStart = length(x_data)/3,
                   ntreeTry = length(y_data)/20,
                   imrpove = 0.0001,
                   stepFactor = 1.20,
                   trace = TRUE,
                   doBest = TRUE,
                   nodesize = length(y_data)/1000,
                   na.action = na.omit,
                   importance = TRUE,
                   proximity = TRUE,
                   sampsize = min(c(length(y_data), 1000)),
                   replace = TRUE)
</code></pre>
<p>After you get a result from your tuning step, check the importance scores from your model.  Use <code>importance(init_fit)</code> to have RStudio return measures for each variable.  Assign those scores to a vector and then subset using subscripting operators all variables that have a positive value.  Retain only those variables that have a positive importance score. </p>
<pre><code class="language-text">importance_scores &lt;- importance(init_fit)
pos_importance &lt;- rownames(importance_scores)[importance_scores[ ,1] &gt; 0]
pos_importance

x_data &lt;- x_data[pos_importance]
</code></pre>
<p>After respecifying your random forest model, estimate it again.</p>
<pre><code class="language-text">pop_fit &lt;- tuneRF(x = x_data,
                  y = y_data,
                  plot = TRUE,
                  mtryStart = length(x_data)/3,
                  ntreeTry = length(y_data)/20,
                  imrpove = 0.0001,
                  stepFactor = 1.20,
                  trace = TRUE,
                  doBest = TRUE,
                  nodesize = length(y_data)/1000,
                  na.action = na.omit,
                  importance = TRUE,
                  proximity = TRUE,
                  sampsize = min(c(length(y_data), 1000)),
                  replace = TRUE)
</code></pre>
<p>Finally, use several of the parameters from <code>pop_fit</code> in the arguments of your final model.</p>
<pre><code class="language-text">model &lt;- randomForest(x = x_data,
                      y = y_data,
                      mtry=pop_fit$mtry,
                      ntree = pop_fit$ntree,
                      nodesize = length(y_data)/1000,
                      importance = TRUE,
                      proximity = TRUE,
                      do.trace = FALSE)
</code></pre>
<p>Check the output from your model.</p>
<pre><code class="language-text">print(model)
plot(model)
varImpPlot(model)
</code></pre>
<p><img src="images/screen-shot-2019-10-21-at-11.40.59-pm.png" alt="Capacity of RF model to explain variance with its 500 trees" /></p>
<p><img src="images/rplot.png" alt="Number of trees needed before Out of Bag Error stabilized" /></p>
<p><img src="images/rplot01.png" alt="Two measures of importance for each of the predictor variables" /></p>
<p>Confirm that the names in your random forest model match those found in your <code>rasterBrick</code>.</p>
<pre><code class="language-text">names(lulc) &lt;- c(&quot;water1&quot;, &quot;dst0111&quot; , &quot;dst0401&quot;, &quot;dst1301&quot;, &quot;dst1401&quot;, &quot;dst1501&quot;, &quot;dst1601&quot;, &quot;dst1901&quot;, &quot;dst2001&quot;, &quot;topo1&quot;, &quot;slope1&quot;, &quot;ntl1&quot;)
</code></pre>
<p>Now predict your population values using the model with the 12 different geospatial covariate layers.</p>
<pre><code class="language-text">preds_rf &lt;- raster::predict(lulc, model)
</code></pre>
<p>After you have predicted your population values for each gridcell, back transform the log of population to its original estimate.</p>
<pre><code class="language-text">preds_rf_exp &lt;- exp(preds_rf)
</code></pre>
<p>Next, extract all of the predicted values by assigning the ID for each adm unit where it is located.</p>
<pre><code class="language-text">ncores &lt;- detectCores() - 1
beginCluster(ncores)
preds_ttls_rf &lt;- raster::extract(preds_rf_exp, lbr_adm3, df=TRUE)
endCluster()
</code></pre>
<p>Aggregate all of the values by adm ID and sum.</p>
<pre><code class="language-text">preds_area_totals_rf &lt;- aggregate(. ~ ID, preds_ttls_rf, sum)
</code></pre>
<p>Bind the columns.</p>
<pre><code class="language-text">lbr_adm3 &lt;- bind_cols(lbr_adm3, preds_area_totals_rf)
</code></pre>
<p>Finally, <code>rasterize()</code> the value of the total estimates per adm and then calculate the gridcell proportionate share across the entire LMIC.  Confirm that <code>cellStats()</code> returns a value equal to the number of adms in your LMIC.</p>
<pre><code class="language-text">preds_ttls &lt;- rasterize(lbr_adm3, preds_rf, field = &quot;layer&quot;)
props  &lt;- preds_rf_exp / preds_ttls
cellStats(props, sum)
</code></pre>
<p>Again, <code>rasterize()</code> population values and then multiply the gridcell proportions by the population values to estimate each gridcells proportion of the total population per gridcell.</p>
<pre><code class="language-text">pops &lt;- rasterize(lbr_adm3, preds_rf, field = &quot;pop15&quot;)
gridcell_pops &lt;- props * pops
cellStats(gridcell_pops, sum)
</code></pre>
<p>Check <code>cellStats()</code> to confirm your totals match population values calculated from the WorldPop persons per pixel raster layer.</p>
<p>Finally, subtract the raster layer with predicted values from your random forest model from the WorldPop ppp raster layer.  Calculate the sum of absolute value of differences between the two rasters.</p>
<pre><code class="language-text">diff &lt;- gridcell_pops - lbr_pop15
cellStats(abs(diff), sum)

rasterVis::plot3D(gridcell_pops)
rasterVis::plot3D(diff)
</code></pre>
<p>What can you surmise?  Have you improved your predictive power by applying a machine learning approach?</p>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                        

                        

                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                

                
            </nav>

        </div>

        

        

        
        
        
        <script type="text/javascript">
            window.playpen_copyable = true;
        </script>
        

        

        
        <script src="elasticlunr.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="mark.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="searcher.js" type="text/javascript" charset="utf-8"></script>
        

        <script src="clipboard.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="highlight.js" type="text/javascript" charset="utf-8"></script>
        <script src="book.js" type="text/javascript" charset="utf-8"></script>

        <!-- Custom JS scripts -->
        

        
        
        <script type="text/javascript">
        window.addEventListener('load', function() {
            window.setTimeout(window.print, 100);
        });
        </script>
        
        

    </body>
</html>
